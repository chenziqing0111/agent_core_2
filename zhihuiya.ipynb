{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:53:11] INFO: ==================================================</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:53:11] INFO: ğŸš€ Step 1: æœç´¢CAR-Tè‡ªèº«å…ç–«ç–¾ç—…ç›¸å…³ä¸“åˆ©</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:53:11] INFO: æ‰§è¡Œæœç´¢: (\"CAR-T\" OR \"CAR T\" OR \"chimeric antigen receptor\") AND (\"autoimmune\" OR \"autoimmunity\" OR \"lupus\" OR \"rheumatoid\" OR \"multiple sclerosis\")</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:53:17] INFO: æ‰§è¡Œæœç´¢: CAR-T autoimmune disease</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:53:25] INFO: æ‰§è¡Œæœç´¢: chimeric antigen receptor autoimmune</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red;\">[23:53:28] ERROR: æœªæ‰¾åˆ°ç›¸å…³ä¸“åˆ©</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©æ™ºèƒ½åˆ†æç³»ç»Ÿ\n",
    "åŸºäºæ™ºæ…§èŠ½APIçš„CAR-Tè‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©æ·±åº¦åˆ†æ\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# ==================== åŸºç¡€é…ç½® ====================\n",
    "\n",
    "class PatentAnalysisSystem:\n",
    "    \"\"\"ä¸“åˆ©åˆ†æç³»ç»Ÿä¸»ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, search_topic: str = None):\n",
    "        # æ™ºæ…§èŠ½APIé…ç½®\n",
    "        self.base_url = \"https://connect.zhihuiya.com\"\n",
    "        self.api_key = \"fh10ixx8marmhm9kbl3cx5676qn8nshcuwtktz0b05ebl7qf\"\n",
    "        self.client_credentials = \"74z26dxne81bnmrbd8vjwt7r8fc6tr6cxxdvapslbz4knycxknv3dnjprap6igjy\"\n",
    "        self.token = None\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # LLMé…ç½®\n",
    "        self.llm_client = OpenAI(\n",
    "            api_key='sk-9b3ad78d6d51431c90091b575072e62f',\n",
    "            base_url=\"https://api.deepseek.com\"\n",
    "        )\n",
    "        \n",
    "        # åˆ†æé…ç½®\n",
    "        self.search_topic = search_topic or \"CAR-T autoimmune\"\n",
    "        self.initial_patents = 100\n",
    "        self.top_patents = 10\n",
    "        \n",
    "    def set_search_topic(self, topic: str):\n",
    "        \"\"\"è®¾ç½®æœç´¢ä¸»é¢˜\"\"\"\n",
    "        self.search_topic = topic\n",
    "        self.log(f\"æœç´¢ä¸»é¢˜è®¾ç½®ä¸º: {topic}\", \"INFO\")\n",
    "        \n",
    "    def log(self, message: str, level: str = \"INFO\"):\n",
    "        \"\"\"æ—¥å¿—è¾“å‡º\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        color_map = {\"INFO\": \"blue\", \"SUCCESS\": \"green\", \"ERROR\": \"red\", \"WARN\": \"orange\"}\n",
    "        color = color_map.get(level, \"blue\")\n",
    "        display(HTML(f'<span style=\"color:{color};\">[{timestamp}] {level}: {message}</span>'))\n",
    "    \n",
    "    def llm_call(self, prompt: str) -> str:\n",
    "        \"\"\"è°ƒç”¨LLM\"\"\"\n",
    "        try:\n",
    "            response = self.llm_client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional patent analyst specializing in CAR-T cell therapy and autoimmune diseases.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                stream=False\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            self.log(f\"LLMè°ƒç”¨å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return \"\"\n",
    "\n",
    "# ==================== Step 1: æ™ºæ…§èŠ½APIæ¥å£ ====================\n",
    "\n",
    "class ZhihuiyaAPI:\n",
    "    \"\"\"æ™ºæ…§èŠ½APIæ¥å£ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, system: PatentAnalysisSystem):\n",
    "        self.system = system\n",
    "        \n",
    "    def authenticate(self) -> bool:\n",
    "        \"\"\"è·å–è®¿é—®token\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/oauth/token\"\n",
    "            headers = {\"content-type\": \"application/x-www-form-urlencoded\"}\n",
    "            data = f\"grant_type=client_credentials&client_id={self.system.api_key}&client_secret={self.system.client_credentials}\"\n",
    "            \n",
    "            response = self.system.session.post(url, data=data, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            if result.get(\"status\") and \"data\" in result:\n",
    "                self.system.token = result[\"data\"][\"token\"]\n",
    "                self.system.log(\"âœ… Tokenè·å–æˆåŠŸ\", \"SUCCESS\")\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"è®¤è¯å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return False\n",
    "    \n",
    "    def search_patents(self, query: str, limit: int = 100) -> List[Dict]:\n",
    "        \"\"\"P002 - ä¸“åˆ©æ£€ç´¢\"\"\"\n",
    "        if not self.system.token and not self.authenticate():\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/search/patent/query-search-patent/v2\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\"apikey\": self.system.api_key}\n",
    "            \n",
    "            payload = {\n",
    "                \"sort\": [{\"field\": \"SCORE\", \"order\": \"DESC\"}],\n",
    "                \"limit\": limit,\n",
    "                \"offset\": 0,\n",
    "                \"query_text\": query,\n",
    "                \"collapse_by\": \"PBD\",\n",
    "                \"collapse_type\": \"ALL\"\n",
    "            }\n",
    "            \n",
    "            self.system.log(f\"ğŸ” æ£€ç´¢ä¸“åˆ©: {query} (é™åˆ¶{limit}ä»¶)\")\n",
    "            response = self.system.session.post(url, params=params, json=payload, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            if result.get(\"status\") and \"data\" in result:\n",
    "                patents = result[\"data\"].get(\"results\", [])\n",
    "                self.system.log(f\"âœ… æ‰¾åˆ° {len(patents)} ä»¶ä¸“åˆ©\", \"SUCCESS\")\n",
    "                return patents\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æ£€ç´¢å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return []\n",
    "    \n",
    "    def get_simple_bibliography(self, patent_id: str, patent_number: str) -> Optional[Dict]:\n",
    "        \"\"\"P011 - è·å–ç®€è¦è‘—å½•é¡¹ç›®ï¼ˆå«æ‘˜è¦ï¼‰\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/simple-bibliography\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                return result[\"data\"][0] if isinstance(result[\"data\"], list) else result[\"data\"]\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"P011è·å–å¤±è´¥ {patent_number}: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_legal_status(self, patent_id: str, patent_number: str) -> Optional[Dict]:\n",
    "        \"\"\"è·å–æ³•å¾‹çŠ¶æ€\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/legal-status\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            return result.get(\"data\") if result.get(\"status\") else None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æ³•å¾‹çŠ¶æ€è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_claims(self, patent_id: str, patent_number: str) -> Optional[str]:\n",
    "        \"\"\"è·å–æƒåˆ©è¦æ±‚ä¹¦\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/claim-data\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key,\n",
    "                \"replace_by_related\": \"0\"\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                claims_data = result[\"data\"]\n",
    "                if isinstance(claims_data, list) and claims_data:\n",
    "                    claims = claims_data[0].get(\"claims\", [])\n",
    "                    claims_text = \"\\n\\n\".join([\n",
    "                        f\"Claim {c.get('claim_num', '')}: {c.get('claim_text', '')}\"\n",
    "                        for c in claims\n",
    "                    ])\n",
    "                    return claims_text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æƒåˆ©è¦æ±‚è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_description(self, patent_id: str, patent_number: str) -> Optional[str]:\n",
    "        \"\"\"è·å–è¯´æ˜ä¹¦\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/description-data\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key,\n",
    "                \"replace_by_related\": \"0\"\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                desc_data = result[\"data\"]\n",
    "                if isinstance(desc_data, list) and desc_data:\n",
    "                    desc_text = desc_data[0].get(\"description\", [{}])[0].get(\"text\", \"\")\n",
    "                    # é™åˆ¶é•¿åº¦\n",
    "                    if len(desc_text) > 50000:\n",
    "                        desc_text = desc_text[:50000] + \"\\n...[å†…å®¹å·²æˆªæ–­]\"\n",
    "                    return desc_text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"è¯´æ˜ä¹¦è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "\n",
    "# ==================== Step 2: CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©ç­›é€‰ä¸åˆ†æ ====================\n",
    "\n",
    "class CARTAutoImmuneScreener:\n",
    "    \"\"\"CAR-Tè‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©ç­›é€‰ä¸è¯„åˆ†\"\"\"\n",
    "    \n",
    "    def __init__(self, system: PatentAnalysisSystem):\n",
    "        self.system = system\n",
    "        \n",
    "        # CAR-Tç›¸å…³å…³é”®è¯\n",
    "        self.cart_keywords = [\n",
    "            \"car-t\", \"cart\", \"car t\", \"chimeric antigen receptor\",\n",
    "            \"car cell\", \"car therapy\", \"engineered t cell\", \"engineered tcell\",\n",
    "            \"t cell therapy\", \"tcell therapy\", \"adoptive cell\", \"cellular immunotherapy\"\n",
    "        ]\n",
    "        \n",
    "        # è‡ªèº«å…ç–«ç–¾ç—…å…³é”®è¯\n",
    "        self.autoimmune_keywords = [\n",
    "            # ä¸€èˆ¬æœ¯è¯­\n",
    "            \"autoimmune\", \"auto-immune\", \"autoimmunity\", \"self-reactive\",\n",
    "            \"tolerance\", \"immune tolerance\", \"autoreactive\",\n",
    "            \n",
    "            # å…·ä½“ç–¾ç—…\n",
    "            \"lupus\", \"sle\", \"systemic lupus erythematosus\",\n",
    "            \"rheumatoid arthritis\", \"ra arthritis\",\n",
    "            \"multiple sclerosis\", \"ms disease\",\n",
    "            \"type 1 diabetes\", \"t1d\", \"iddm\",\n",
    "            \"inflammatory bowel\", \"ibd\", \"crohn\", \"ulcerative colitis\",\n",
    "            \"psoriasis\", \"psoriatic\",\n",
    "            \"sjogren\", \"sjÃ¶gren\",\n",
    "            \"scleroderma\", \"systemic sclerosis\",\n",
    "            \"myasthenia gravis\",\n",
    "            \"hashimoto\", \"thyroiditis\",\n",
    "            \"pemphigus\", \"pemphigoid\",\n",
    "            \"vasculitis\", \"anca\",\n",
    "            \"dermatomyositis\", \"polymyositis\",\n",
    "            \"antiphospholipid\", \"aps syndrome\"\n",
    "        ]\n",
    "        \n",
    "        # ç›¸å…³é¶ç‚¹\n",
    "        self.target_keywords = [\n",
    "            \"cd19\", \"cd20\", \"bcma\", \"cd5\", \"baff\", \"april\",\n",
    "            \"cd38\", \"cd138\", \"plasmablast\", \"plasma cell\",\n",
    "            \"b cell\", \"bcell\", \"b-cell\", \"b lymphocyte\",\n",
    "            \"memory b\", \"autoreactive b\",\n",
    "            \"treg\", \"regulatory t\", \"t regulatory\",\n",
    "            \"cd4\", \"cd8\", \"cd3\", \"cd25\", \"foxp3\",\n",
    "            \"il-17\", \"il17\", \"th17\", \"il-23\", \"il23\"\n",
    "        ]\n",
    "        \n",
    "    def process_initial_patents(self, patents: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"å¤„ç†åˆå§‹ä¸“åˆ©æ•°æ®\"\"\"\n",
    "        processed = []\n",
    "        \n",
    "        for i, patent in enumerate(patents, 1):\n",
    "            if i % 20 == 0:\n",
    "                self.system.log(f\"å¤„ç†è¿›åº¦: {i}/{len(patents)}\")\n",
    "            \n",
    "            # æå–åŸºç¡€ä¿¡æ¯\n",
    "            patent_info = {\n",
    "                \"patent_id\": patent.get(\"patent_id\"),\n",
    "                \"patent_number\": patent.get(\"pn\"),\n",
    "                \"title\": self._extract_title(patent),\n",
    "                \"assignee\": patent.get(\"current_assignee\", \"\"),\n",
    "                \"application_date\": str(patent.get(\"apdt\", \"\")),\n",
    "                \"publication_date\": str(patent.get(\"pbdt\", \"\")),\n",
    "                \"abstract\": \"\",\n",
    "                \"legal_status\": \"\",\n",
    "                \"score\": patent.get(\"score\", 0),\n",
    "                \"is_cart_related\": False,\n",
    "                \"is_autoimmune_related\": False,\n",
    "                \"cart_score\": 0,\n",
    "                \"autoimmune_score\": 0\n",
    "            }\n",
    "            \n",
    "            # åˆæ­¥åˆ¤æ–­ç›¸å…³æ€§\n",
    "            title_abstract = str(patent_info[\"title\"]).lower()\n",
    "            patent_info[\"is_cart_related\"] = any(kw in title_abstract for kw in self.cart_keywords)\n",
    "            patent_info[\"is_autoimmune_related\"] = any(kw in title_abstract for kw in self.autoimmune_keywords)\n",
    "            \n",
    "            processed.append(patent_info)\n",
    "            time.sleep(0.1)  # APIé™æµ\n",
    "        \n",
    "        return pd.DataFrame(processed)\n",
    "    \n",
    "    def _extract_title(self, patent: Dict) -> str:\n",
    "        \"\"\"æå–æ ‡é¢˜\"\"\"\n",
    "        title = patent.get(\"title\", \"\")\n",
    "        if isinstance(title, dict):\n",
    "            title = title.get(\"en\") or title.get(\"zh\", \"\")\n",
    "        return str(title)\n",
    "    \n",
    "    def enrich_with_abstracts(self, df: pd.DataFrame, api: ZhihuiyaAPI) -> pd.DataFrame:\n",
    "        \"\"\"è¡¥å……æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€ï¼Œå¹¶é‡æ–°è¯„ä¼°ç›¸å…³æ€§\"\"\"\n",
    "        self.system.log(\"ğŸ“„ è·å–æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€...\")\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if idx % 10 == 0:\n",
    "                self.system.log(f\"è¿›åº¦: {idx}/{len(df)}\")\n",
    "            \n",
    "            # è·å–æ‘˜è¦\n",
    "            biblio = api.get_simple_bibliography(row[\"patent_id\"], row[\"patent_number\"])\n",
    "            if biblio:\n",
    "                abstracts = biblio.get(\"bibliographic_data\", {}).get(\"abstracts\", [])\n",
    "                if abstracts:\n",
    "                    abstract_text = abstracts[0].get(\"text\", \"\")[:1000]\n",
    "                    df.at[idx, \"abstract\"] = abstract_text\n",
    "                    \n",
    "                    # é‡æ–°è¯„ä¼°ç›¸å…³æ€§ï¼ˆåŒ…å«æ‘˜è¦ï¼‰\n",
    "                    full_text = (str(row[\"title\"]) + \" \" + abstract_text).lower()\n",
    "                    \n",
    "                    # CAR-Tç›¸å…³æ€§è¯„åˆ†\n",
    "                    cart_score = sum(2 for kw in self.cart_keywords if kw in full_text)\n",
    "                    cart_score += sum(1 for kw in self.target_keywords if kw in full_text)\n",
    "                    df.at[idx, \"cart_score\"] = cart_score\n",
    "                    df.at[idx, \"is_cart_related\"] = cart_score > 0\n",
    "                    \n",
    "                    # è‡ªèº«å…ç–«ç›¸å…³æ€§è¯„åˆ†\n",
    "                    autoimmune_score = sum(2 for kw in self.autoimmune_keywords if kw in full_text)\n",
    "                    df.at[idx, \"autoimmune_score\"] = autoimmune_score\n",
    "                    df.at[idx, \"is_autoimmune_related\"] = autoimmune_score > 0\n",
    "            \n",
    "            # è·å–æ³•å¾‹çŠ¶æ€\n",
    "            legal = api.get_legal_status(row[\"patent_id\"], row[\"patent_number\"])\n",
    "            if legal and isinstance(legal, list) and legal:\n",
    "                legal_info = legal[0].get(\"patent_legal\", {})\n",
    "                status = legal_info.get(\"simple_legal_status\", [])\n",
    "                df.at[idx, \"legal_status\"] = \", \".join(status) if status else \"Unknown\"\n",
    "            \n",
    "            time.sleep(0.2)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def filter_cart_autoimmune_patents(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"ç­›é€‰CAR-T+è‡ªèº«å…ç–«ç›¸å…³ä¸“åˆ©\"\"\"\n",
    "        # ç­›é€‰åŒæ—¶åŒ…å«CAR-Tå’Œè‡ªèº«å…ç–«å…³é”®è¯çš„ä¸“åˆ©\n",
    "        filtered = df[(df[\"is_cart_related\"] == True) & (df[\"is_autoimmune_related\"] == True)]\n",
    "        \n",
    "        if len(filtered) == 0:\n",
    "            # å¦‚æœæ²¡æœ‰ä¸¥æ ¼ç¬¦åˆçš„ï¼Œæ”¾å®½æ¡ä»¶\n",
    "            self.system.log(\"æœªæ‰¾åˆ°ä¸¥æ ¼ç¬¦åˆCAR-T+è‡ªèº«å…ç–«çš„ä¸“åˆ©ï¼Œå°è¯•æ”¾å®½æ¡ä»¶...\", \"WARN\")\n",
    "            filtered = df[(df[\"cart_score\"] > 0) | (df[\"autoimmune_score\"] > 0)]\n",
    "        \n",
    "        self.system.log(f\"ç­›é€‰å‡º {len(filtered)} ä»¶ç›¸å…³ä¸“åˆ©\", \"SUCCESS\")\n",
    "        return filtered\n",
    "    \n",
    "    def analyze_patent_statistics(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"ç»Ÿè®¡åˆ†æCAR-Tè‡ªèº«å…ç–«ä¸“åˆ©\"\"\"\n",
    "        stats = {\n",
    "            \"total_patents\": len(df),\n",
    "            \"cart_autoimmune_patents\": len(df[(df[\"is_cart_related\"] == True) & (df[\"is_autoimmune_related\"] == True)]),\n",
    "            \"cart_only\": len(df[(df[\"is_cart_related\"] == True) & (df[\"is_autoimmune_related\"] == False)]),\n",
    "            \"autoimmune_only\": len(df[(df[\"is_cart_related\"] == False) & (df[\"is_autoimmune_related\"] == True)]),\n",
    "            \"assignee_distribution\": df[\"assignee\"].value_counts().to_dict(),\n",
    "            \"year_distribution\": df[\"application_date\"].str[:4].value_counts().to_dict(),\n",
    "            \"legal_status_distribution\": df[\"legal_status\"].value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        # åˆ†æå…·ä½“ç–¾ç—…ç±»å‹\n",
    "        disease_types = {\n",
    "            \"Lupus/SLE\": 0,\n",
    "            \"Rheumatoid Arthritis\": 0,\n",
    "            \"Multiple Sclerosis\": 0,\n",
    "            \"Type 1 Diabetes\": 0,\n",
    "            \"IBD/Crohn's/UC\": 0,\n",
    "            \"Psoriasis\": 0,\n",
    "            \"Other Autoimmune\": 0,\n",
    "            \"Not Specified\": 0\n",
    "        }\n",
    "        \n",
    "        # åˆ†æé¶ç‚¹åˆ†å¸ƒ\n",
    "        target_distribution = {\n",
    "            \"CD19\": 0,\n",
    "            \"CD20\": 0,\n",
    "            \"BCMA\": 0,\n",
    "            \"CD5\": 0,\n",
    "            \"Other B cell\": 0,\n",
    "            \"T cell targets\": 0,\n",
    "            \"Other/Unknown\": 0\n",
    "        }\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            text = (str(row[\"title\"]) + \" \" + str(row[\"abstract\"])).lower()\n",
    "            \n",
    "            # ç–¾ç—…åˆ†ç±»\n",
    "            disease_found = False\n",
    "            if any(kw in text for kw in [\"lupus\", \"sle\", \"systemic lupus\"]):\n",
    "                disease_types[\"Lupus/SLE\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"rheumatoid\", \"ra arthritis\"]):\n",
    "                disease_types[\"Rheumatoid Arthritis\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"multiple sclerosis\", \"ms disease\"]):\n",
    "                disease_types[\"Multiple Sclerosis\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"type 1 diabetes\", \"t1d\", \"iddm\"]):\n",
    "                disease_types[\"Type 1 Diabetes\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"inflammatory bowel\", \"ibd\", \"crohn\", \"ulcerative colitis\"]):\n",
    "                disease_types[\"IBD/Crohn's/UC\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"psoriasis\", \"psoriatic\"]):\n",
    "                disease_types[\"Psoriasis\"] += 1\n",
    "                disease_found = True\n",
    "            if not disease_found and row[\"is_autoimmune_related\"]:\n",
    "                disease_types[\"Other Autoimmune\"] += 1\n",
    "            elif not disease_found:\n",
    "                disease_types[\"Not Specified\"] += 1\n",
    "            \n",
    "            # é¶ç‚¹åˆ†ç±»\n",
    "            if \"cd19\" in text:\n",
    "                target_distribution[\"CD19\"] += 1\n",
    "            elif \"cd20\" in text:\n",
    "                target_distribution[\"CD20\"] += 1\n",
    "            elif \"bcma\" in text:\n",
    "                target_distribution[\"BCMA\"] += 1\n",
    "            elif \"cd5\" in text:\n",
    "                target_distribution[\"CD5\"] += 1\n",
    "            elif any(kw in text for kw in [\"b cell\", \"bcell\", \"b-cell\"]):\n",
    "                target_distribution[\"Other B cell\"] += 1\n",
    "            elif any(kw in text for kw in [\"cd4\", \"cd8\", \"cd3\", \"treg\"]):\n",
    "                target_distribution[\"T cell targets\"] += 1\n",
    "            else:\n",
    "                target_distribution[\"Other/Unknown\"] += 1\n",
    "        \n",
    "        stats[\"disease_distribution\"] = disease_types\n",
    "        stats[\"target_distribution\"] = target_distribution\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def score_and_rank_patents(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"è¯„åˆ†å¹¶æ’åºCAR-Tè‡ªèº«å…ç–«ä¸“åˆ©\"\"\"\n",
    "        self.system.log(\"âš–ï¸ ä¸“åˆ©è¯„åˆ†ä¸­...\")\n",
    "        \n",
    "        # é¡¶çº§åˆ¶è¯å’Œç»†èƒæ²»ç–—å…¬å¸\n",
    "        top_companies = [\n",
    "            \"NOVARTIS\", \"KITE\", \"JUNO\", \"CELGENE\", \"BRISTOL\", \"BMS\",\n",
    "            \"GILEAD\", \"JANSSEN\", \"JOHNSON\", \"PFIZER\", \"ROCHE\",\n",
    "            \"SANGAMO\", \"BLUEBIRD\", \"CRISPR\", \"EDITAS\", \"INTELLIA\",\n",
    "            \"CABALETTA\", \"CARTESIAN\", \"KYVERNA\", \"SONOMA\", \"TREGS\"\n",
    "        ]\n",
    "        \n",
    "        # é¡¶çº§ç ”ç©¶æœºæ„\n",
    "        top_institutions = [\n",
    "            \"UNIVERSITY\", \"PENN\", \"UPENN\", \"STANFORD\", \"MIT\", \"HARVARD\",\n",
    "            \"YALE\", \"UCLA\", \"UCSF\", \"JOHNS HOPKINS\", \"MEMORIAL SLOAN\",\n",
    "            \"FRED HUTCH\", \"DANA FARBER\", \"MD ANDERSON\", \"NIH\", \"NCI\"\n",
    "        ]\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            score = 0\n",
    "            \n",
    "            # 1. CAR-Tç›¸å…³åº¦ï¼ˆ0-30åˆ†ï¼‰\n",
    "            score += min(row[\"cart_score\"] * 3, 30)\n",
    "            \n",
    "            # 2. è‡ªèº«å…ç–«ç›¸å…³åº¦ï¼ˆ0-30åˆ†ï¼‰\n",
    "            score += min(row[\"autoimmune_score\"] * 3, 30)\n",
    "            \n",
    "            # 3. ç”³è¯·äººæƒé‡ï¼ˆ0-20åˆ†ï¼‰\n",
    "            assignee = str(row[\"assignee\"]).upper()\n",
    "            if any(comp in assignee for comp in top_companies):\n",
    "                score += 20\n",
    "            elif any(inst in assignee for inst in top_institutions):\n",
    "                score += 15\n",
    "            elif assignee:\n",
    "                score += 5\n",
    "            \n",
    "            # 4. æ—¶é—´æ–°é²œåº¦ï¼ˆ0-10åˆ†ï¼‰\n",
    "            pub_date = str(row[\"publication_date\"])\n",
    "            if pub_date >= \"20240000\":\n",
    "                score += 10\n",
    "            elif pub_date >= \"20230000\":\n",
    "                score += 8\n",
    "            elif pub_date >= \"20220000\":\n",
    "                score += 6\n",
    "            elif pub_date >= \"20200000\":\n",
    "                score += 4\n",
    "            \n",
    "            # 5. æ³•å¾‹çŠ¶æ€ï¼ˆ0-10åˆ†ï¼‰\n",
    "            legal = str(row[\"legal_status\"]).lower()\n",
    "            if \"grant\" in legal or \"æˆæƒ\" in legal:\n",
    "                score += 10\n",
    "            elif \"pending\" in legal or \"å®¡æŸ¥\" in legal:\n",
    "                score += 5\n",
    "            \n",
    "            df.at[idx, \"final_score\"] = score\n",
    "        \n",
    "        # æ’åº\n",
    "        df_sorted = df.sort_values(\"final_score\", ascending=False)\n",
    "        \n",
    "        return df_sorted\n",
    "\n",
    "# ==================== Step 3: æ·±åº¦åˆ†æPrompts ====================\n",
    "\n",
    "class CARTAutoImmuneAnalysisPrompts:\n",
    "    \"\"\"CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©åˆ†æPromptæ¨¡æ¿\"\"\"\n",
    "    \n",
    "    def description_analysis_prompt(self, description_text: str, patent_info: Dict) -> str:\n",
    "        \"\"\"è¯´æ˜ä¹¦åˆ†æprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½œä¸ºCAR-Tç»†èƒæ²»ç–—å’Œè‡ªèº«å…ç–«ç–¾ç—…é¢†åŸŸçš„ä¸“åˆ©æŠ€æœ¯ä¸“å®¶ï¼Œè¯·æ·±åº¦åˆ†æä»¥ä¸‹ä¸“åˆ©çš„è¯´æ˜ä¹¦ï¼Œå¹¶ä»¥è¿è´¯çš„æ®µè½å½¢å¼è¾“å‡ºåˆ†æç»“æœã€‚\n",
    "\n",
    "ä¸“åˆ©å·ï¼š{patent_info['patent_number']}\n",
    "ç”³è¯·äººï¼š{patent_info['assignee']}\n",
    "ç”³è¯·æ—¥ï¼š{patent_info['application_date']}\n",
    "\n",
    "è¯´æ˜ä¹¦å†…å®¹ï¼š\n",
    "{description_text}\n",
    "\n",
    "è¯·æŒ‰ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ¯éƒ¨åˆ†ç”¨2-3ä¸ªå®Œæ•´æ®µè½è¡¨è¿°ï¼‰ï¼š\n",
    "\n",
    "## 1. æŠ€æœ¯æ¦‚è¿°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæè¿°è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„CAR-TæŠ€æœ¯ï¼Œé’ˆå¯¹ä»€ä¹ˆè‡ªèº«å…ç–«ç–¾ç—…ï¼Œè¦è§£å†³ä»€ä¹ˆå…·ä½“é—®é¢˜ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯´æ˜æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼Œç‰¹åˆ«æ˜¯ç›¸æ¯”ä¼ ç»ŸCAR-Tè‚¿ç˜¤æ²»ç–—çš„é€‚åº”æ€§æ”¹è¿›ã€‚\n",
    "\n",
    "## 2. CARç»“æ„ä¸è®¾è®¡ï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯¦ç»†æè¿°CARçš„ç»“æ„è®¾è®¡ï¼ŒåŒ…æ‹¬æŠ—åŸè¯†åˆ«åŸŸ(scFv)ã€é“°é“¾åŒºã€è·¨è†œåŸŸã€ä¿¡å·è½¬å¯¼åŸŸçš„å…·ä½“é€‰æ‹©ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æé¶ç‚¹é€‰æ‹©çš„ç§‘å­¦ä¾æ®ï¼Œä¸ºä»€ä¹ˆé€‰æ‹©è¯¥é¶ç‚¹æ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šå®‰å…¨æ€§è®¾è®¡ï¼Œå¦‚è‡ªæ€å¼€å…³ã€å¯è°ƒæ§ç³»ç»Ÿã€é¿å…è¿‡åº¦å…ç–«æŠ‘åˆ¶çš„ç­–ç•¥ã€‚\n",
    "\n",
    "## 3. åˆ¶å¤‡å·¥è‰ºä¸è´¨æ§ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šTç»†èƒæ¥æºã€è½¬å¯¼æ–¹æ³•ï¼ˆæ…¢ç—…æ¯’/é€†è½¬å½•ç—…æ¯’/ç”µç©¿å­”ï¼‰ã€æ‰©å¢åŸ¹å…»æ¡ä»¶ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè´¨é‡æ§åˆ¶æ ‡å‡†ï¼ŒåŒ…æ‹¬CARè¡¨è¾¾ç‡ã€ç»†èƒçº¯åº¦ã€åŠŸèƒ½æ£€æµ‹ç­‰ã€‚\n",
    "\n",
    "## 4. å®éªŒéªŒè¯ï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šä½“å¤–å®éªŒè®¾è®¡ï¼ŒåŒ…æ‹¬ç»†èƒæ¯’æ€§ã€ç»†èƒå› å­é‡Šæ”¾ã€é¶ç»†èƒæ¸…é™¤ç­‰ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåŠ¨ç‰©æ¨¡å‹å®éªŒï¼Œä½¿ç”¨ä»€ä¹ˆè‡ªèº«å…ç–«ç–¾ç—…æ¨¡å‹ï¼Œç–—æ•ˆè¯„ä¼°æŒ‡æ ‡ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šä¸´åºŠå‰å®‰å…¨æ€§è¯„ä¼°ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹è‡ªèº«å…ç–«æ²»ç–—çš„ç‰¹æ®Šå®‰å…¨æ€§è€ƒè™‘ã€‚\n",
    "\n",
    "## 5. ä¸´åºŠè½¬åŒ–æ½œåŠ›ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šç›®æ ‡é€‚åº”ç—‡çš„å¸‚åœºè§„æ¨¡ï¼Œä¸ç°æœ‰ç–—æ³•ï¼ˆç”Ÿç‰©åˆ¶å‰‚ã€å°åˆ†å­è¯ç‰©ï¼‰çš„æ¯”è¾ƒä¼˜åŠ¿ã€‚\n",
    "ç¬¬äºŒæ®µï¼šä¸´åºŠå¼€å‘ç­–ç•¥ï¼Œé¢„æœŸçš„ä¸´åºŠè¯•éªŒè®¾è®¡ï¼Œå‰‚é‡é€‰æ‹©ï¼Œç–—æ•ˆç»ˆç‚¹ã€‚\n",
    "\n",
    "## 6. å…³é”®æŠ€æœ¯å‚æ•°æå–\n",
    "- CARç»“æ„ï¼šå…·ä½“çš„scFvã€ä¿¡å·åŸŸç»„åˆ\n",
    "- é¶ç‚¹ï¼šå…·ä½“çš„æŠ—åŸé¶ç‚¹\n",
    "- é€‚åº”ç—‡ï¼šç›®æ ‡è‡ªèº«å…ç–«ç–¾ç—…\n",
    "- åˆ¶å¤‡å‚æ•°ï¼šè½¬å¯¼æ•ˆç‡ã€æ‰©å¢å€æ•°\n",
    "- ç–—æ•ˆæ•°æ®ï¼šå…³é”®çš„ä½“å†…å¤–å®éªŒæ•°æ®\n",
    "- å®‰å…¨æ€§ç‰¹å¾ï¼šç‰¹æ®Šçš„å®‰å…¨æ€§è®¾è®¡\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- ä½¿ç”¨å®Œæ•´æµç•…çš„æ®µè½ï¼Œé¿å…ç¢ç‰‡åŒ–åˆ—è¡¨\n",
    "- çªå‡ºCAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…çš„ç‰¹æ®Šæ€§\n",
    "- ä¿æŒä¸“ä¸šä½†æ˜“è¯»çš„æ–‡é£\n",
    "- æ€»å­—æ•°æ§åˆ¶åœ¨1000-1500å­—\n",
    "\"\"\"\n",
    "    \n",
    "    def claims_analysis_prompt(self, claims_text: str, patent_info: Dict) -> str:\n",
    "        \"\"\"æƒåˆ©è¦æ±‚åˆ†æprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½œä¸ºä¸“åˆ©æ³•å¾‹ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹CAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©çš„æƒåˆ©è¦æ±‚ä¹¦ï¼Œå¹¶ä»¥é€‚åˆä¸“ä¸šæŠ¥å‘Šçš„æ®µè½å½¢å¼è¾“å‡ºã€‚\n",
    "\n",
    "ä¸“åˆ©å·ï¼š{patent_info['patent_number']}\n",
    "ç”³è¯·äººï¼š{patent_info['assignee']}\n",
    "\n",
    "æƒåˆ©è¦æ±‚ä¹¦ï¼š\n",
    "{claims_text}\n",
    "\n",
    "è¯·æŒ‰ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ¯éƒ¨åˆ†ç”¨2-3ä¸ªå®Œæ•´æ®µè½è¡¨è¿°ï¼‰ï¼š\n",
    "\n",
    "## 1. æƒåˆ©è¦æ±‚æ¶æ„æ¦‚è¿°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæè¿°æƒåˆ©è¦æ±‚çš„æ•´ä½“ç»“æ„ï¼Œäº§å“æƒåˆ©è¦æ±‚ä¸æ–¹æ³•æƒåˆ©è¦æ±‚çš„åˆ†å¸ƒã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æCAR-Tç›¸å…³æƒåˆ©è¦æ±‚çš„å±‚æ¬¡è®¾è®¡ç­–ç•¥ã€‚\n",
    "\n",
    "## 2. æ ¸å¿ƒä¿æŠ¤èŒƒå›´åˆ†æï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šåˆ†æCARç»“æ„ç›¸å…³çš„æƒåˆ©è¦æ±‚ä¿æŠ¤èŒƒå›´ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†ææ²»ç–—æ–¹æ³•ç›¸å…³çš„æƒåˆ©è¦æ±‚ï¼Œç‰¹åˆ«æ˜¯è‡ªèº«å…ç–«é€‚åº”ç—‡çš„é™å®šã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šè¯„ä¼°åˆ¶å¤‡æ–¹æ³•æƒåˆ©è¦æ±‚çš„ä¿æŠ¤ä»·å€¼ã€‚\n",
    "\n",
    "## 3. æŠ€æœ¯ç‰¹å¾é€’è¿›ç­–ç•¥ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šåˆ†æä»å±æƒåˆ©è¦æ±‚å¦‚ä½•é€æ­¥é™å®šCARç»“æ„ã€é¶ç‚¹ã€ç–¾ç—…ç±»å‹ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯„ä»·å…³é”®ä»å±æƒåˆ©è¦æ±‚å¯¹å•†ä¸šåŒ–çš„å½±å“ã€‚\n",
    "\n",
    "## 4. æ³•å¾‹ç¨³å®šæ€§ä¸ä¾µæƒåˆ†æï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯„ä¼°æƒåˆ©è¦æ±‚ç›¸å¯¹äºç°æœ‰CAR-TæŠ€æœ¯çš„åˆ›é€ æ€§ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†ææ½œåœ¨çš„è®¾è®¡è§„é¿è·¯å¾„å’Œé˜²å¾¡ç­–ç•¥ã€‚\n",
    "\n",
    "## 5. ä¸å…¶ä»–CAR-Tä¸“åˆ©çš„å…³ç³»ï¼ˆ1æ®µï¼‰\n",
    "åˆ†æè¯¥ä¸“åˆ©ä¸Novartisã€Kiteç­‰ä¸»è¦CAR-Tä¸“åˆ©çš„åŒºåˆ«å’Œæ½œåœ¨å†²çªã€‚\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- ä½¿ç”¨è¿è´¯çš„ä¸“ä¸šæ®µè½\n",
    "- çªå‡ºè‡ªèº«å…ç–«é¢†åŸŸçš„ç‰¹æ®Šæ€§\n",
    "- æ€»å­—æ•°æ§åˆ¶åœ¨800-1200å­—\n",
    "\"\"\"\n",
    "    \n",
    "    def final_report_prompt(self, statistics: Dict, detailed_analyses: List[Dict]) -> str:\n",
    "        \"\"\"æœ€ç»ˆç»¼åˆæŠ¥å‘Šprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½ æ˜¯ä¸“ä¸šçš„ä¸“åˆ©åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®æ’°å†™ä¸€ä»½è¯¦ç»†çš„CAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©æŠ€æœ¯ç»¼è¿°æŠ¥å‘Šã€‚\n",
    "\n",
    "ã€ä¸“åˆ©ç»Ÿè®¡æ•°æ®ã€‘\n",
    "{json.dumps(statistics, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ã€æ ¸å¿ƒä¸“åˆ©è¯¦ç»†åˆ†æã€‘\n",
    "{json.dumps(detailed_analyses, ensure_ascii=False, indent=2)}\n",
    "\n",
    "è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ä¸“åˆ©æŠ€æœ¯ç»¼è¿°æŠ¥å‘Šï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "# CAR-Tç»†èƒç–—æ³•æ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…å…¨çƒä¸“åˆ©æ€åŠ¿åˆ†æ\n",
    "\n",
    "## æ‰§è¡Œæ‘˜è¦\n",
    "ç®€è¦æ¦‚è¿°CAR-Tåœ¨è‡ªèº«å…ç–«é¢†åŸŸçš„ä¸“åˆ©ç°çŠ¶å’Œä¸»è¦å‘ç°ï¼ˆ300å­—ï¼‰ã€‚\n",
    "\n",
    "## ä¸€ã€æŠ€æœ¯èƒŒæ™¯ä¸å¸‚åœºæœºé‡\n",
    "\n",
    "### CAR-Tä»è‚¿ç˜¤åˆ°è‡ªèº«å…ç–«çš„è½¬åŒ–ï¼ˆ400å­—ï¼‰\n",
    "- CAR-Tåœ¨è¡€æ¶²è‚¿ç˜¤çš„æˆåŠŸç»éªŒ\n",
    "- è‡ªèº«å…ç–«ç–¾ç—…çš„æœªæ»¡è¶³éœ€æ±‚\n",
    "- CAR-Tæ²»ç–—è‡ªèº«å…ç–«çš„ç§‘å­¦åŸºç¡€\n",
    "\n",
    "### ä¸“åˆ©ç”³è¯·è¶‹åŠ¿åˆ†æï¼ˆ300å­—ï¼‰\n",
    "åŸºäºç»Ÿè®¡æ•°æ®ï¼Œåˆ†æï¼š\n",
    "- å¹´åº¦ç”³è¯·é‡å˜åŒ–\n",
    "- æŠ€æœ¯æˆç†Ÿåº¦è¯„ä¼°\n",
    "- ä¸CAR-Tè‚¿ç˜¤ä¸“åˆ©çš„å¯¹æ¯”\n",
    "\n",
    "## äºŒã€ä¸»è¦ä¸“åˆ©æƒåˆ©äººç«äº‰æ ¼å±€\n",
    "\n",
    "### é¢†å…ˆä¼ä¸šåˆ†æï¼ˆå„300å­—ï¼‰\n",
    "åŸºäºæ ¸å¿ƒä¸“åˆ©åˆ†æï¼Œè¯¦è¿°ä¸»è¦ç”³è¯·äººçš„ï¼š\n",
    "- æŠ€æœ¯è·¯çº¿ç‰¹ç‚¹\n",
    "- ä¸“åˆ©å¸ƒå±€ç­–ç•¥\n",
    "- ä¸´åºŠå¼€å‘è¿›å±•\n",
    "\n",
    "### å­¦æœ¯æœºæ„è´¡çŒ®ï¼ˆ300å­—ï¼‰\n",
    "åˆ†æå¤§å­¦å’Œç ”ç©¶æœºæ„çš„ä¸“åˆ©ç‰¹ç‚¹ã€‚\n",
    "\n",
    "## ä¸‰ã€å…³é”®æŠ€æœ¯åˆ›æ–°åˆ†æ\n",
    "\n",
    "### é¶ç‚¹é€‰æ‹©ç­–ç•¥ï¼ˆ400å­—ï¼‰\n",
    "- CD19 Bç»†èƒæ¸…é™¤ç­–ç•¥\n",
    "- å…¶ä»–Bç»†èƒé¶ç‚¹ï¼ˆCD20ã€BCMAç­‰ï¼‰\n",
    "- Tç»†èƒé¶ç‚¹æ¢ç´¢\n",
    "- åŒé¶ç‚¹CARè®¾è®¡\n",
    "\n",
    "### CARç»“æ„ä¼˜åŒ–ï¼ˆ400å­—ï¼‰\n",
    "- é’ˆå¯¹è‡ªèº«å…ç–«çš„ç‰¹æ®Šè®¾è®¡\n",
    "- å®‰å…¨æ€§æ”¹è¿›ï¼ˆè‡ªæ€å¼€å…³ã€å¯è°ƒæ§ç³»ç»Ÿï¼‰\n",
    "- æŒä¹…æ€§ä¸è®°å¿†æ€§ä¼˜åŒ–\n",
    "\n",
    "### é€‚åº”ç—‡è¦†ç›–ï¼ˆ400å­—ï¼‰\n",
    "åŸºäºä¸“åˆ©åˆ†æçš„ç–¾ç—…åˆ†å¸ƒï¼š\n",
    "- ç‹¼ç–®ç­‰Bç»†èƒä»‹å¯¼ç–¾ç—…\n",
    "- ç±»é£æ¹¿å…³èŠ‚ç‚\n",
    "- å…¶ä»–è‡ªèº«å…ç–«ç–¾ç—…\n",
    "\n",
    "## å››ã€ä¸“åˆ©ä¿æŠ¤ç­–ç•¥åˆ†æ\n",
    "\n",
    "### æƒåˆ©è¦æ±‚è®¾è®¡ç‰¹ç‚¹ï¼ˆ300å­—ï¼‰\n",
    "- äº§å“vsæ–¹æ³•æƒåˆ©è¦æ±‚\n",
    "- ä¿æŠ¤èŒƒå›´çš„å¹³è¡¡\n",
    "- ä¸è‚¿ç˜¤CAR-Tä¸“åˆ©çš„åŒºåˆ†\n",
    "\n",
    "### æ½œåœ¨çš„ä¸“åˆ©çº çº·ï¼ˆ300å­—ï¼‰\n",
    "- åŸºç¡€CAR-Tä¸“åˆ©çš„å½±å“\n",
    "- äº¤å‰è®¸å¯å¯èƒ½æ€§\n",
    "\n",
    "## äº”ã€ä¸´åºŠè½¬åŒ–ä¸å•†ä¸šåŒ–å‰æ™¯\n",
    "\n",
    "### ä¸´åºŠè¯•éªŒç°çŠ¶ï¼ˆ300å­—ï¼‰\n",
    "åŸºäºä¸“åˆ©ä¸­çš„ä¸´åºŠè®¾è®¡ä¿¡æ¯ã€‚\n",
    "\n",
    "### å¸‚åœºé¢„æµ‹ï¼ˆ300å­—ï¼‰\n",
    "- ç›®æ ‡æ‚£è€…ç¾¤ä½“\n",
    "- å®šä»·ç­–ç•¥è€ƒè™‘\n",
    "- ä¸ç°æœ‰ç–—æ³•çš„ç«äº‰\n",
    "\n",
    "## å…­ã€æŠ€æœ¯å‘å±•è¶‹åŠ¿ä¸æŠ•èµ„æœºä¼š\n",
    "\n",
    "### æœªæ¥æŠ€æœ¯æ–¹å‘ï¼ˆ400å­—ï¼‰\n",
    "- é€šç”¨å‹CAR-T\n",
    "- åŸºå› ç¼–è¾‘å¢å¼º\n",
    "- è”åˆæ²»ç–—ç­–ç•¥\n",
    "\n",
    "### æŠ•èµ„å»ºè®®ï¼ˆ300å­—ï¼‰\n",
    "- æœ€å…·æ½œåŠ›çš„æŠ€æœ¯è·¯çº¿\n",
    "- å…³æ³¨çš„ä¼ä¸šå’Œæœºæ„\n",
    "- åˆä½œä¸è®¸å¯æœºä¼š\n",
    "\n",
    "## ä¸ƒã€ç»“è®º\n",
    "æ€»ç»“CAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…çš„ä¸“åˆ©ç°çŠ¶ã€æœºé‡ä¸æŒ‘æˆ˜ï¼ˆ300å­—ï¼‰ã€‚\n",
    "\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "1. åŸºäºå®é™…æ•°æ®ï¼Œä¸ç¼–é€ ä¿¡æ¯\n",
    "2. çªå‡ºCAR-Tæ²»ç–—è‡ªèº«å…ç–«çš„ç‰¹æ®Šæ€§\n",
    "3. åŒ…å«å…·ä½“ä¸“åˆ©å·å’Œç”³è¯·äººä¿¡æ¯\n",
    "4. ä¿æŒå®¢è§‚ä¸“ä¸šçš„åˆ†æè§†è§’\n",
    "5. æ€»å­—æ•°3500-4500å­—\n",
    "\"\"\"\n",
    "\n",
    "# ==================== Step 4: ä¸»æµç¨‹æ‰§è¡Œ ====================\n",
    "\n",
    "class CARTAutoImmuneAnalysisPipeline:\n",
    "    \"\"\"CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©åˆ†æä¸»æµç¨‹\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.system = PatentAnalysisSystem()\n",
    "        self.api = ZhihuiyaAPI(self.system)\n",
    "        self.screener = CARTAutoImmuneScreener(self.system)\n",
    "        self.prompts = CARTAutoImmuneAnalysisPrompts()\n",
    "        \n",
    "    def run_complete_analysis(self) -> Dict:\n",
    "        \"\"\"è¿è¡Œå®Œæ•´åˆ†ææµç¨‹\"\"\"\n",
    "        \n",
    "        # ========== Step 1: æ„å»ºæœç´¢æŸ¥è¯¢ ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸš€ Step 1: æœç´¢CAR-Tè‡ªèº«å…ç–«ç–¾ç—…ç›¸å…³ä¸“åˆ©\", \"INFO\")\n",
    "        \n",
    "        # æ„å»ºå¤åˆæœç´¢æŸ¥è¯¢\n",
    "        search_queries = [\n",
    "            '(\"CAR-T\" OR \"CAR T\" OR \"chimeric antigen receptor\") AND (\"autoimmune\" OR \"autoimmunity\" OR \"lupus\" OR \"rheumatoid\" OR \"multiple sclerosis\")',\n",
    "            'CAR-T autoimmune disease',\n",
    "            'chimeric antigen receptor autoimmune',\n",
    "            'CAR T cell therapy lupus SLE',\n",
    "            'CAR-T rheumatoid arthritis',\n",
    "            'engineered T cell autoimmune'\n",
    "        ]\n",
    "        \n",
    "        all_patents = []\n",
    "        seen_ids = set()\n",
    "        \n",
    "        # æ‰§è¡Œå¤šä¸ªæœç´¢æŸ¥è¯¢ä»¥è·å¾—æ›´å…¨é¢çš„ç»“æœ\n",
    "        for query in search_queries[:3]:  # ä½¿ç”¨å‰3ä¸ªæŸ¥è¯¢\n",
    "            self.system.log(f\"æ‰§è¡Œæœç´¢: {query}\")\n",
    "            results = self.api.search_patents(query, limit=50)\n",
    "            \n",
    "            for patent in results:\n",
    "                patent_id = patent.get(\"patent_id\")\n",
    "                if patent_id not in seen_ids:\n",
    "                    all_patents.append(patent)\n",
    "                    seen_ids.add(patent_id)\n",
    "            \n",
    "            time.sleep(2)  # é¿å…APIé™åˆ¶\n",
    "        \n",
    "        if not all_patents:\n",
    "            self.system.log(\"æœªæ‰¾åˆ°ç›¸å…³ä¸“åˆ©\", \"ERROR\")\n",
    "            return {}\n",
    "        \n",
    "        self.system.log(f\"âœ… å…±æ‰¾åˆ° {len(all_patents)} ä»¶å”¯ä¸€ä¸“åˆ©\", \"SUCCESS\")\n",
    "        \n",
    "        # ========== Step 2: åˆæ­¥å¤„ç†å’Œç­›é€‰ ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ” Step 2: å¤„ç†ä¸“åˆ©æ•°æ®å¹¶ç­›é€‰ç›¸å…³ä¸“åˆ©\", \"INFO\")\n",
    "        \n",
    "        # 2.1 å¤„ç†åŸºç¡€æ•°æ®\n",
    "        df_patents = self.screener.process_initial_patents(all_patents)\n",
    "        \n",
    "        # 2.2 è¡¥å……æ‘˜è¦å¹¶é‡æ–°è¯„ä¼°ç›¸å…³æ€§\n",
    "        df_patents = self.screener.enrich_with_abstracts(df_patents, self.api)\n",
    "        \n",
    "        # 2.3 ç­›é€‰CAR-T+è‡ªèº«å…ç–«ç›¸å…³ä¸“åˆ©\n",
    "        df_filtered = self.screener.filter_cart_autoimmune_patents(df_patents)\n",
    "        \n",
    "        if len(df_filtered) == 0:\n",
    "            self.system.log(\"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¸“åˆ©\", \"ERROR\")\n",
    "            return {}\n",
    "        \n",
    "        # 2.4 ç»Ÿè®¡åˆ†æ\n",
    "        statistics = self.screener.analyze_patent_statistics(df_filtered)\n",
    "        self.system.log(\"ğŸ“Š ä¸“åˆ©ç»Ÿè®¡åˆ†æå®Œæˆ\", \"SUCCESS\")\n",
    "        \n",
    "        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ\n",
    "        print(\"\\nCAR-Tè‡ªèº«å…ç–«ä¸“åˆ©ç»Ÿè®¡:\")\n",
    "        print(f\"  æ€»ä¸“åˆ©æ•°: {statistics['total_patents']}\")\n",
    "        print(f\"  CAR-T+è‡ªèº«å…ç–«: {statistics['cart_autoimmune_patents']}\")\n",
    "        \n",
    "        print(\"\\nç–¾ç—…ç±»å‹åˆ†å¸ƒ:\")\n",
    "        for disease, count in statistics[\"disease_distribution\"].items():\n",
    "            if count > 0:\n",
    "                print(f\"  {disease}: {count}ä»¶\")\n",
    "        \n",
    "        print(\"\\né¶ç‚¹åˆ†å¸ƒ:\")\n",
    "        for target, count in statistics[\"target_distribution\"].items():\n",
    "            if count > 0:\n",
    "                print(f\"  {target}: {count}ä»¶\")\n",
    "        \n",
    "        # 2.5 è¯„åˆ†å’Œæ’åº\n",
    "        df_filtered = self.screener.score_and_rank_patents(df_filtered)\n",
    "        \n",
    "        # ========== Step 3: é€‰æ‹©Topä¸“åˆ© ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ¯ Step 3: é€‰æ‹©Topä¸“åˆ©è¿›è¡Œæ·±åº¦åˆ†æ\", \"INFO\")\n",
    "        \n",
    "        # é€‰æ‹©å‰10ä¸ªæˆ–æ‰€æœ‰ï¼ˆå¦‚æœå°‘äº10ä¸ªï¼‰\n",
    "        num_top = min(10, len(df_filtered))\n",
    "        top_patents = df_filtered.head(num_top)\n",
    "        \n",
    "        print(f\"\\nTop {num_top} CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©:\")\n",
    "        for i, (idx, row) in enumerate(top_patents.iterrows(), 1):\n",
    "            print(f\"{i}. {row['patent_number']} - {row['assignee'][:40]} (Score: {row['final_score']})\")\n",
    "        \n",
    "        # ========== Step 4: æ·±åº¦åˆ†æTopä¸“åˆ© ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ”¬ Step 4: æ·±åº¦åˆ†ææ ¸å¿ƒä¸“åˆ©\", \"INFO\")\n",
    "        \n",
    "        detailed_analyses = []\n",
    "        \n",
    "        for i, (idx, patent) in enumerate(top_patents.iterrows(), 1):\n",
    "            self.system.log(f\"åˆ†æä¸“åˆ© {i}/{num_top}: {patent['patent_number']}\")\n",
    "            \n",
    "            # 4.1 è·å–è¯´æ˜ä¹¦\n",
    "            description = self.api.get_description(patent[\"patent_id\"], patent[\"patent_number\"])\n",
    "            \n",
    "            # 4.2 è·å–æƒåˆ©è¦æ±‚\n",
    "            claims = self.api.get_claims(patent[\"patent_id\"], patent[\"patent_number\"])\n",
    "            \n",
    "            if description and claims:\n",
    "                # 4.3 LLMåˆ†æè¯´æ˜ä¹¦\n",
    "                desc_prompt = self.prompts.description_analysis_prompt(description, patent.to_dict())\n",
    "                desc_analysis = self.system.llm_call(desc_prompt)\n",
    "                \n",
    "                # 4.4 LLMåˆ†ææƒåˆ©è¦æ±‚\n",
    "                claims_prompt = self.prompts.claims_analysis_prompt(claims, patent.to_dict())\n",
    "                claims_analysis = self.system.llm_call(claims_prompt)\n",
    "                \n",
    "                detailed_analyses.append({\n",
    "                    \"patent_number\": patent[\"patent_number\"],\n",
    "                    \"assignee\": patent[\"assignee\"],\n",
    "                    \"application_date\": patent[\"application_date\"],\n",
    "                    \"title\": patent[\"title\"],\n",
    "                    \"cart_score\": patent[\"cart_score\"],\n",
    "                    \"autoimmune_score\": patent[\"autoimmune_score\"],\n",
    "                    \"technical_analysis\": desc_analysis,\n",
    "                    \"legal_analysis\": claims_analysis\n",
    "                })\n",
    "                \n",
    "                self.system.log(f\"âœ… å®Œæˆåˆ†æ: {patent['patent_number']}\", \"SUCCESS\")\n",
    "            else:\n",
    "                self.system.log(f\"âš ï¸ æ— æ³•è·å–å®Œæ•´å†…å®¹: {patent['patent_number']}\", \"WARN\")\n",
    "            \n",
    "            time.sleep(2)  # APIé™æµ\n",
    "        \n",
    "        # ========== Step 5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ“ Step 5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š\", \"INFO\")\n",
    "        \n",
    "        # 5.1 å‡†å¤‡æ•°æ®\n",
    "        statistics[\"top_patents\"] = top_patents[[\"patent_number\", \"assignee\", \"final_score\"]].to_dict(\"records\")\n",
    "        \n",
    "        # 5.2 ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š\n",
    "        final_prompt = self.prompts.final_report_prompt(statistics, detailed_analyses)\n",
    "        final_report = self.system.llm_call(final_prompt)\n",
    "        \n",
    "        # ========== ä¿å­˜ç»“æœ ==========\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # ä¿å­˜ä¸“åˆ©åˆ—è¡¨\n",
    "        df_filtered.to_csv(f\"cart_autoimmune_patents_{timestamp}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        self.system.log(f\"âœ… ä¸“åˆ©åˆ—è¡¨å·²ä¿å­˜è‡³: cart_autoimmune_patents_{timestamp}.csv\", \"SUCCESS\")\n",
    "        \n",
    "        # ä¿å­˜è¯¦ç»†åˆ†æ\n",
    "        with open(f\"cart_autoimmune_detailed_analysis_{timestamp}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\n",
    "                \"statistics\": statistics,\n",
    "                \"detailed_analyses\": detailed_analyses\n",
    "            }, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š\n",
    "        with open(f\"cart_autoimmune_report_{timestamp}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_report)\n",
    "        \n",
    "        self.system.log(f\"âœ… CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©åˆ†æå®Œæˆï¼\", \"SUCCESS\")\n",
    "        self.system.log(f\"âœ… æŠ¥å‘Šå·²ä¿å­˜è‡³: cart_autoimmune_report_{timestamp}.md\", \"SUCCESS\")\n",
    "        \n",
    "        return {\n",
    "            \"statistics\": statistics,\n",
    "            \"detailed_analyses\": detailed_analyses,\n",
    "            \"final_report\": final_report,\n",
    "            \"patents_df\": df_filtered\n",
    "        }\n",
    "\n",
    "# ==================== è¿è¡Œåˆ†æ ====================\n",
    "\n",
    "# åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ\n",
    "pipeline = CARTAutoImmuneAnalysisPipeline()\n",
    "results = pipeline.run_complete_analysis()\n",
    "\n",
    "# æ˜¾ç¤ºæŠ¥å‘Šé¢„è§ˆ\n",
    "if results and \"final_report\" in results:\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ğŸ“„ CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©åˆ†ææŠ¥å‘Šé¢„è§ˆï¼ˆå‰1500å­—ï¼‰:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(results[\"final_report\"][:1500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ecd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "é€šç”¨åŸºå› ä¸“åˆ©æ™ºèƒ½åˆ†æç³»ç»Ÿ - Universal Gene Patent Analysis System\n",
    "åŸºäºæ™ºæ…§èŠ½APIçš„ä»»æ„åŸºå› ä¸“åˆ©æ·±åº¦åˆ†æ\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# ==================== åŸºç¡€é…ç½® ====================\n",
    "\n",
    "class PatentAnalysisSystem:\n",
    "    \"\"\"ä¸“åˆ©åˆ†æç³»ç»Ÿä¸»ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, target_gene: str = None):\n",
    "        # æ™ºæ…§èŠ½APIé…ç½®\n",
    "        self.base_url = \"https://connect.zhihuiya.com\"\n",
    "        self.api_key = \"fh10ixx8marmhm9kbl3cx5676qn8nshcuwtktz0b05ebl7qf\"\n",
    "        self.client_credentials = \"74z26dxne81bnmrbd8vjwt7r8fc6tr6cxxdvapslbz4knycxknv3dnjprap6igjy\"\n",
    "        self.token = None\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # LLMé…ç½®\n",
    "        self.llm_client = OpenAI(\n",
    "            api_key='sk-9b3ad78d6d51431c90091b575072e62f',\n",
    "            base_url=\"https://api.deepseek.com\"\n",
    "        )\n",
    "        \n",
    "        # åˆ†æé…ç½®\n",
    "        self.target_gene = target_gene or \"GENE\"  # é»˜è®¤åŸºå› å\n",
    "        self.initial_patents = 100\n",
    "        self.top_patents = 10\n",
    "        \n",
    "    def set_target_gene(self, gene_name: str):\n",
    "        \"\"\"è®¾ç½®ç›®æ ‡åŸºå› \"\"\"\n",
    "        self.target_gene = gene_name\n",
    "        self.log(f\"ç›®æ ‡åŸºå› è®¾ç½®ä¸º: {gene_name}\", \"INFO\")\n",
    "        \n",
    "    def log(self, message: str, level: str = \"INFO\"):\n",
    "        \"\"\"æ—¥å¿—è¾“å‡º\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        color_map = {\"INFO\": \"blue\", \"SUCCESS\": \"green\", \"ERROR\": \"red\", \"WARN\": \"orange\"}\n",
    "        color = color_map.get(level, \"blue\")\n",
    "        display(HTML(f'<span style=\"color:{color};\">[{timestamp}] {level}: {message}</span>'))\n",
    "    \n",
    "    def llm_call(self, prompt: str) -> str:\n",
    "        \"\"\"è°ƒç”¨LLM\"\"\"\n",
    "        try:\n",
    "            response = self.llm_client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional patent analyst specializing in biotechnology and pharmaceutical patents.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                stream=False\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            self.log(f\"LLMè°ƒç”¨å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return \"\"\n",
    "\n",
    "# ==================== Step 1: æ™ºæ…§èŠ½APIæ¥å£ ====================\n",
    "\n",
    "class ZhihuiyaAPI:\n",
    "    \"\"\"æ™ºæ…§èŠ½APIæ¥å£ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, system: PatentAnalysisSystem):\n",
    "        self.system = system\n",
    "        \n",
    "    def authenticate(self) -> bool:\n",
    "        \"\"\"è·å–è®¿é—®token\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/oauth/token\"\n",
    "            headers = {\"content-type\": \"application/x-www-form-urlencoded\"}\n",
    "            data = f\"grant_type=client_credentials&client_id={self.system.api_key}&client_secret={self.system.client_credentials}\"\n",
    "            \n",
    "            response = self.system.session.post(url, data=data, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            if result.get(\"status\") and \"data\" in result:\n",
    "                self.system.token = result[\"data\"][\"token\"]\n",
    "                self.system.log(\"âœ… Tokenè·å–æˆåŠŸ\", \"SUCCESS\")\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"è®¤è¯å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return False\n",
    "    \n",
    "    def search_patents(self, query: str, limit: int = 100) -> List[Dict]:\n",
    "        \"\"\"P002 - ä¸“åˆ©æ£€ç´¢\"\"\"\n",
    "        if not self.system.token and not self.authenticate():\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/search/patent/query-search-patent/v2\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\"apikey\": self.system.api_key}\n",
    "            \n",
    "            payload = {\n",
    "                \"sort\": [{\"field\": \"SCORE\", \"order\": \"DESC\"}],\n",
    "                \"limit\": limit,\n",
    "                \"offset\": 0,\n",
    "                \"query_text\": query,\n",
    "                \"collapse_by\": \"PBD\",\n",
    "                \"collapse_type\": \"ALL\"\n",
    "            }\n",
    "            \n",
    "            self.system.log(f\"ğŸ” æ£€ç´¢ä¸“åˆ©: {query} (é™åˆ¶{limit}ä»¶)\")\n",
    "            response = self.system.session.post(url, params=params, json=payload, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            if result.get(\"status\") and \"data\" in result:\n",
    "                patents = result[\"data\"].get(\"results\", [])\n",
    "                self.system.log(f\"âœ… æ‰¾åˆ° {len(patents)} ä»¶ä¸“åˆ©\", \"SUCCESS\")\n",
    "                return patents\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æ£€ç´¢å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return []\n",
    "    \n",
    "    def get_simple_bibliography(self, patent_id: str, patent_number: str) -> Optional[Dict]:\n",
    "        \"\"\"P011 - è·å–ç®€è¦è‘—å½•é¡¹ç›®ï¼ˆå«æ‘˜è¦ï¼‰\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/simple-bibliography\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                return result[\"data\"][0] if isinstance(result[\"data\"], list) else result[\"data\"]\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"P011è·å–å¤±è´¥ {patent_number}: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_legal_status(self, patent_id: str, patent_number: str) -> Optional[Dict]:\n",
    "        \"\"\"è·å–æ³•å¾‹çŠ¶æ€\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/legal-status\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            return result.get(\"data\") if result.get(\"status\") else None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æ³•å¾‹çŠ¶æ€è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_claims(self, patent_id: str, patent_number: str) -> Optional[str]:\n",
    "        \"\"\"è·å–æƒåˆ©è¦æ±‚ä¹¦\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/claim-data\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key,\n",
    "                \"replace_by_related\": \"0\"\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                claims_data = result[\"data\"]\n",
    "                if isinstance(claims_data, list) and claims_data:\n",
    "                    claims = claims_data[0].get(\"claims\", [])\n",
    "                    claims_text = \"\\n\\n\".join([\n",
    "                        f\"Claim {c.get('claim_num', '')}: {c.get('claim_text', '')}\"\n",
    "                        for c in claims\n",
    "                    ])\n",
    "                    return claims_text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æƒåˆ©è¦æ±‚è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_description(self, patent_id: str, patent_number: str) -> Optional[str]:\n",
    "        \"\"\"è·å–è¯´æ˜ä¹¦\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/description-data\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key,\n",
    "                \"replace_by_related\": \"0\"\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                desc_data = result[\"data\"]\n",
    "                if isinstance(desc_data, list) and desc_data:\n",
    "                    desc_text = desc_data[0].get(\"description\", [{}])[0].get(\"text\", \"\")\n",
    "                    # é™åˆ¶é•¿åº¦\n",
    "                    if len(desc_text) > 50000:\n",
    "                        desc_text = desc_text[:50000] + \"\\n...[å†…å®¹å·²æˆªæ–­]\"\n",
    "                    return desc_text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"è¯´æ˜ä¹¦è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "\n",
    "# ==================== Step 2: ä¸“åˆ©åˆæ­¥åˆ†æä¸ç­›é€‰ ====================\n",
    "\n",
    "class PatentScreener:\n",
    "    \"\"\"ä¸“åˆ©ç­›é€‰ä¸è¯„åˆ†\"\"\"\n",
    "    \n",
    "    def __init__(self, system: PatentAnalysisSystem):\n",
    "        self.system = system\n",
    "        \n",
    "    def process_initial_patents(self, patents: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"å¤„ç†åˆå§‹ä¸“åˆ©æ•°æ®\"\"\"\n",
    "        processed = []\n",
    "        \n",
    "        for i, patent in enumerate(patents, 1):\n",
    "            if i % 20 == 0:\n",
    "                self.system.log(f\"å¤„ç†è¿›åº¦: {i}/{len(patents)}\")\n",
    "            \n",
    "            # æå–åŸºç¡€ä¿¡æ¯\n",
    "            patent_info = {\n",
    "                \"patent_id\": patent.get(\"patent_id\"),\n",
    "                \"patent_number\": patent.get(\"pn\"),\n",
    "                \"title\": self._extract_title(patent),\n",
    "                \"assignee\": patent.get(\"current_assignee\", \"\"),\n",
    "                \"application_date\": str(patent.get(\"apdt\", \"\")),\n",
    "                \"publication_date\": str(patent.get(\"pbdt\", \"\")),\n",
    "                \"abstract\": \"\",\n",
    "                \"legal_status\": \"\",\n",
    "                \"score\": patent.get(\"score\", 0)\n",
    "            }\n",
    "            \n",
    "            processed.append(patent_info)\n",
    "            time.sleep(0.1)  # APIé™æµ\n",
    "        \n",
    "        return pd.DataFrame(processed)\n",
    "    \n",
    "    def _extract_title(self, patent: Dict) -> str:\n",
    "        \"\"\"æå–æ ‡é¢˜\"\"\"\n",
    "        title = patent.get(\"title\", \"\")\n",
    "        if isinstance(title, dict):\n",
    "            title = title.get(\"en\") or title.get(\"zh\", \"\")\n",
    "        return str(title)\n",
    "    \n",
    "    def enrich_with_abstracts(self, df: pd.DataFrame, api: ZhihuiyaAPI) -> pd.DataFrame:\n",
    "        \"\"\"è¡¥å……æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€\"\"\"\n",
    "        self.system.log(\"ğŸ“„ è·å–æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€...\")\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if idx % 10 == 0:\n",
    "                self.system.log(f\"è¿›åº¦: {idx}/{len(df)}\")\n",
    "            \n",
    "            # è·å–æ‘˜è¦\n",
    "            biblio = api.get_simple_bibliography(row[\"patent_id\"], row[\"patent_number\"])\n",
    "            if biblio:\n",
    "                abstracts = biblio.get(\"bibliographic_data\", {}).get(\"abstracts\", [])\n",
    "                if abstracts:\n",
    "                    df.at[idx, \"abstract\"] = abstracts[0].get(\"text\", \"\")[:500]\n",
    "            \n",
    "            # è·å–æ³•å¾‹çŠ¶æ€\n",
    "            legal = api.get_legal_status(row[\"patent_id\"], row[\"patent_number\"])\n",
    "            if legal and isinstance(legal, list) and legal:\n",
    "                legal_info = legal[0].get(\"patent_legal\", {})\n",
    "                status = legal_info.get(\"simple_legal_status\", [])\n",
    "                df.at[idx, \"legal_status\"] = \", \".join(status) if status else \"Unknown\"\n",
    "            \n",
    "            time.sleep(0.2)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def analyze_patent_statistics(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"ç»Ÿè®¡åˆ†æä¸“åˆ© - é€šç”¨ç‰ˆæœ¬\"\"\"\n",
    "        stats = {\n",
    "            \"total_patents\": len(df),\n",
    "            \"assignee_distribution\": df[\"assignee\"].value_counts().to_dict(),\n",
    "            \"year_distribution\": df[\"application_date\"].str[:4].value_counts().to_dict(),\n",
    "            \"legal_status_distribution\": df[\"legal_status\"].value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        # åŸºäºåŸºå› åçš„åŠ¨æ€æŠ€æœ¯ç±»å‹è¯†åˆ«\n",
    "        tech_types = {\n",
    "            \"RNAi/siRNA\": 0,\n",
    "            \"Antibody/mAb\": 0,\n",
    "            \"Small Molecule\": 0,\n",
    "            \"CRISPR/Gene Editing\": 0,\n",
    "            \"Cell Therapy\": 0,\n",
    "            \"Protein/Peptide\": 0,\n",
    "            \"Gene Therapy\": 0,\n",
    "            \"Other\": 0\n",
    "        }\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            text = (str(row[\"title\"]) + \" \" + str(row[\"abstract\"])).lower()\n",
    "            \n",
    "            # æ£€æµ‹æŠ€æœ¯ç±»å‹\n",
    "            if any(kw in text for kw in [\"rnai\", \"sirna\", \"interference\", \"oligonucleotide\", \"antisense\"]):\n",
    "                tech_types[\"RNAi/siRNA\"] += 1\n",
    "            elif any(kw in text for kw in [\"antibody\", \"mab\", \"immunoglobulin\", \"monoclonal\"]):\n",
    "                tech_types[\"Antibody/mAb\"] += 1\n",
    "            elif any(kw in text for kw in [\"compound\", \"inhibitor\", \"small molecule\", \"chemical\"]):\n",
    "                tech_types[\"Small Molecule\"] += 1\n",
    "            elif any(kw in text for kw in [\"crispr\", \"cas9\", \"gene editing\", \"genome editing\"]):\n",
    "                tech_types[\"CRISPR/Gene Editing\"] += 1\n",
    "            elif any(kw in text for kw in [\"car-t\", \"cell therapy\", \"tcr\", \"nk cell\"]):\n",
    "                tech_types[\"Cell Therapy\"] += 1\n",
    "            elif any(kw in text for kw in [\"protein\", \"peptide\", \"fusion protein\", \"recombinant\"]):\n",
    "                tech_types[\"Protein/Peptide\"] += 1\n",
    "            elif any(kw in text for kw in [\"gene therapy\", \"aav\", \"viral vector\", \"lentivirus\"]):\n",
    "                tech_types[\"Gene Therapy\"] += 1\n",
    "            else:\n",
    "                tech_types[\"Other\"] += 1\n",
    "        \n",
    "        stats[\"technology_distribution\"] = tech_types\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def score_and_rank_patents(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"è¯„åˆ†å¹¶æ’åºä¸“åˆ© - é€šç”¨ç‰ˆæœ¬\"\"\"\n",
    "        self.system.log(\"âš–ï¸ ä¸“åˆ©è¯„åˆ†ä¸­...\")\n",
    "        \n",
    "        # æ„å»ºä¸ç›®æ ‡åŸºå› ç›¸å…³çš„å…³é”®è¯åˆ—è¡¨\n",
    "        gene_lower = self.system.target_gene.lower()\n",
    "        gene_keywords = [\n",
    "            gene_lower,\n",
    "            self.system.target_gene.upper(),\n",
    "            # æ·»åŠ å¸¸è§çš„ç–¾ç—…ç›¸å…³å…³é”®è¯\n",
    "            \"therapeutic\", \"treatment\", \"inhibitor\", \"agonist\", \"antagonist\",\n",
    "            \"disease\", \"disorder\", \"cancer\", \"tumor\", \"diabetes\", \"obesity\",\n",
    "            \"inflammation\", \"metabolic\", \"cardiovascular\", \"neurological\"\n",
    "        ]\n",
    "        \n",
    "        # é¡¶çº§åˆ¶è¯å…¬å¸åˆ—è¡¨\n",
    "        top_pharma_companies = [\n",
    "            \"ROCHE\", \"NOVARTIS\", \"PFIZER\", \"MERCK\", \"JOHNSON\", \"SANOFI\", \n",
    "            \"GLAXOSMITHKLINE\", \"GSK\", \"ASTRAZENECA\", \"ABBVIE\", \"BRISTOL\",\n",
    "            \"LILLY\", \"AMGEN\", \"GILEAD\", \"REGENERON\", \"VERTEX\", \"BIOGEN\",\n",
    "            \"ARROWHEAD\", \"ALNYLAM\", \"MODERNA\", \"BIONTECH\", \"WAVE\"\n",
    "        ]\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            score = 0\n",
    "            \n",
    "            # 1. æ‘˜è¦å’Œæ ‡é¢˜ç›¸å…³åº¦ï¼ˆ0-35åˆ†ï¼‰\n",
    "            text = (str(row[\"title\"]) + \" \" + str(row[\"abstract\"])).lower()\n",
    "            \n",
    "            # åŸºå› åç§°å‡ºç°å¾—åˆ†\n",
    "            gene_count = text.count(gene_lower)\n",
    "            score += min(gene_count * 5, 20)\n",
    "            \n",
    "            # å…¶ä»–å…³é”®è¯å¾—åˆ†\n",
    "            keyword_score = sum(2 for kw in gene_keywords[2:] if kw in text)\n",
    "            score += min(keyword_score, 15)\n",
    "            \n",
    "            # 2. ç”³è¯·äººæƒé‡ï¼ˆ0-20åˆ†ï¼‰\n",
    "            assignee = str(row[\"assignee\"]).upper()\n",
    "            if any(comp in assignee for comp in top_pharma_companies):\n",
    "                score += 20\n",
    "            elif assignee and \"UNIVERSITY\" in assignee:\n",
    "                score += 10\n",
    "            elif assignee:\n",
    "                score += 5\n",
    "            \n",
    "            # 3. æ—¶é—´æ–°é²œåº¦ï¼ˆ0-15åˆ†ï¼‰\n",
    "            pub_date = str(row[\"publication_date\"])\n",
    "            if pub_date >= \"20240000\":\n",
    "                score += 15\n",
    "            elif pub_date >= \"20230000\":\n",
    "                score += 12\n",
    "            elif pub_date >= \"20220000\":\n",
    "                score += 8\n",
    "            elif pub_date >= \"20200000\":\n",
    "                score += 5\n",
    "            \n",
    "            # 4. æ³•å¾‹çŠ¶æ€ï¼ˆ0-10åˆ†ï¼‰\n",
    "            legal = str(row[\"legal_status\"]).lower()\n",
    "            if \"grant\" in legal or \"æˆæƒ\" in legal:\n",
    "                score += 10\n",
    "            elif \"pending\" in legal or \"å®¡æŸ¥\" in legal:\n",
    "                score += 5\n",
    "            \n",
    "            # 5. åŸå§‹ç›¸å…³åº¦åˆ†æ•°ï¼ˆ0-20åˆ†ï¼‰\n",
    "            original_score = row[\"score\"]\n",
    "            if original_score > 80:\n",
    "                score += 20\n",
    "            elif original_score > 60:\n",
    "                score += 15\n",
    "            elif original_score > 40:\n",
    "                score += 10\n",
    "            elif original_score > 20:\n",
    "                score += 5\n",
    "            \n",
    "            df.at[idx, \"final_score\"] = score\n",
    "        \n",
    "        # æ’åº\n",
    "        df_sorted = df.sort_values(\"final_score\", ascending=False)\n",
    "        \n",
    "        return df_sorted\n",
    "\n",
    "# ==================== Step 3: æ·±åº¦åˆ†æPrompts ====================\n",
    "\n",
    "class PatentAnalysisPrompts:\n",
    "    \"\"\"ä¸“åˆ©åˆ†æPromptæ¨¡æ¿ - é€šç”¨ç‰ˆæœ¬\"\"\"\n",
    "    \n",
    "    def __init__(self, target_gene: str):\n",
    "        self.target_gene = target_gene\n",
    "    \n",
    "    def description_analysis_prompt(self, description_text: str, patent_info: Dict) -> str:\n",
    "        \"\"\"è¯´æ˜ä¹¦åˆ†æprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½œä¸ºä¸“åˆ©æŠ€æœ¯ä¸“å®¶ï¼Œè¯·æ·±åº¦åˆ†æä»¥ä¸‹{self.target_gene}åŸºå› ç›¸å…³ä¸“åˆ©çš„è¯´æ˜ä¹¦ï¼Œå¹¶ä»¥è¿è´¯çš„æ®µè½å½¢å¼è¾“å‡ºåˆ†æç»“æœã€‚\n",
    "\n",
    "ä¸“åˆ©å·ï¼š{patent_info['patent_number']}\n",
    "ç”³è¯·äººï¼š{patent_info['assignee']}\n",
    "ç”³è¯·æ—¥ï¼š{patent_info['application_date']}\n",
    "\n",
    "è¯´æ˜ä¹¦å†…å®¹ï¼š\n",
    "{description_text}\n",
    "\n",
    "è¯·æŒ‰ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ¯éƒ¨åˆ†ç”¨2-3ä¸ªå®Œæ•´æ®µè½è¡¨è¿°ï¼‰ï¼š\n",
    "\n",
    "## 1. æŠ€æœ¯æ¦‚è¿°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šç®€è¦æè¿°è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„æŠ€æœ¯ï¼ˆRNAi/æŠ—ä½“/å°åˆ†å­/åŸºå› ç¼–è¾‘/ç»†èƒæ²»ç–—ç­‰ï¼‰ï¼Œé’ˆå¯¹{self.target_gene}é¶ç‚¹è¦è§£å†³ä»€ä¹ˆå…·ä½“é—®é¢˜ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯´æ˜æ ¸å¿ƒåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Œä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”çš„ä¸»è¦æ”¹è¿›åœ¨å“ªé‡Œã€‚\n",
    "\n",
    "## 2. æŠ€æœ¯æ–¹æ¡ˆåˆ†æï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯¦ç»†æè¿°å…·ä½“çš„æŠ€æœ¯æ–¹æ¡ˆã€‚æ ¹æ®æŠ€æœ¯ç±»å‹åˆ†æå…³é”®è¦ç´ ï¼ˆåºåˆ—è®¾è®¡ã€åŒ–åˆç‰©ç»“æ„ã€è½½ä½“æ„å»ºç­‰ï¼‰ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æä¼˜åŒ–æˆ–æ”¹è¿›ç­–ç•¥ï¼ˆåŒ–å­¦ä¿®é¥°ã€ç»“æ„ä¼˜åŒ–ã€é€’é€ç³»ç»Ÿç­‰ï¼‰ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šä¸åŒé¢†åŸŸå…¶ä»–ä¸“åˆ©æŠ€æœ¯çš„å¯¹æ¯”ï¼Œçªå‡ºæœ¬ä¸“åˆ©çš„ç‹¬ç‰¹æ€§ã€‚\n",
    "\n",
    "## 3. å®éªŒéªŒè¯ï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæ¦‚è¿°å®éªŒè®¾è®¡çš„æ•´ä½“æ€è·¯ï¼ŒåŒ…æ‹¬ä½“å¤–ã€ä½“å†…å®éªŒçš„å±‚æ¬¡å®‰æ’ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯¦ç»†æè¿°æœ€å…³é”®çš„å®éªŒç»“æœï¼ŒåŒ…æ‹¬å…·ä½“æ•°æ®ï¼ˆIC50ã€EC50ã€æŠ‘åˆ¶ç‡ã€æŒç»­æ—¶é—´ç­‰ï¼‰ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šå®‰å…¨æ€§è¯„ä¼°å’Œä¸´åºŠè½¬åŒ–è€ƒè™‘ã€‚å¦‚æœæœ‰ä¸´åºŠè¯•éªŒè®¾è®¡ï¼Œè¯´æ˜ä¸»è¦ç»ˆç‚¹å’Œç»™è¯æ–¹æ¡ˆã€‚\n",
    "\n",
    "## 4. å•†ä¸šä»·å€¼è¯„ä¼°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯„ä¼°{self.target_gene}ç›¸å…³ç–¾ç—…çš„å¸‚åœºè§„æ¨¡å’Œç«äº‰æ ¼å±€ã€‚è¯¥æŠ€æœ¯çš„ç›®æ ‡é€‚åº”ç—‡æ˜¯ä»€ä¹ˆï¼Ÿå¸‚åœºæ½œåŠ›å¦‚ä½•ï¼Ÿ\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æä¸“åˆ©æŠ€æœ¯çš„å¯å®æ–½æ€§å’Œå•†ä¸šåŒ–å‰æ™¯ã€‚ç”Ÿäº§å·¥è‰ºæ˜¯å¦æˆç†Ÿï¼Ÿæˆæœ¬æ˜¯å¦å¯æ§ï¼Ÿä¸´åºŠå¼€å‘è·¯å¾„æ˜¯å¦æ¸…æ™°ï¼Ÿ\n",
    "\n",
    "## 5. å…³é”®æŠ€æœ¯å‚æ•°æå–\n",
    "è¯·ç‰¹åˆ«æå–ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼š\n",
    "- æ ¸å¿ƒåºåˆ—/åŒ–åˆç‰©ï¼šå…·ä½“åºåˆ—å·æˆ–åŒ–å­¦ç»“æ„\n",
    "- é¶å‘æœºåˆ¶ï¼š{self.target_gene}çš„ä½œç”¨ä½ç‚¹æˆ–æœºåˆ¶\n",
    "- å®éªŒæ•°æ®ï¼šå…³é”®çš„é‡åŒ–æŒ‡æ ‡\n",
    "- æŠ€æœ¯ç‰¹å¾ï¼šç‹¬ç‰¹çš„æŠ€æœ¯ç‰¹ç‚¹\n",
    "- ä¸´åºŠæ–¹æ¡ˆï¼šå‰‚é‡ã€ç»™è¯é€”å¾„ã€é¢‘ç‡ï¼ˆå¦‚æœ‰ï¼‰\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- ä½¿ç”¨å®Œæ•´æµç•…çš„æ®µè½ï¼Œé¿å…ç¢ç‰‡åŒ–åˆ—è¡¨\n",
    "- æ•°æ®è‡ªç„¶èå…¥å™è¿°ä¸­\n",
    "- ä¿æŒä¸“ä¸šä½†æ˜“è¯»çš„æ–‡é£\n",
    "- æ€»å­—æ•°æ§åˆ¶åœ¨1000-1500å­—\n",
    "\"\"\"\n",
    "    \n",
    "    def claims_analysis_prompt(self, claims_text: str, patent_info: Dict) -> str:\n",
    "        \"\"\"æƒåˆ©è¦æ±‚åˆ†æprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½œä¸ºä¸“åˆ©æ³•å¾‹ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹{self.target_gene}åŸºå› ç›¸å…³ä¸“åˆ©çš„æƒåˆ©è¦æ±‚ä¹¦ï¼Œå¹¶ä»¥é€‚åˆä¸“ä¸šæŠ¥å‘Šçš„æ®µè½å½¢å¼è¾“å‡ºã€‚\n",
    "\n",
    "ä¸“åˆ©å·ï¼š{patent_info['patent_number']}\n",
    "ç”³è¯·äººï¼š{patent_info['assignee']}\n",
    "\n",
    "æƒåˆ©è¦æ±‚ä¹¦ï¼š\n",
    "{claims_text}\n",
    "\n",
    "è¯·æŒ‰ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ¯éƒ¨åˆ†ç”¨2-3ä¸ªå®Œæ•´æ®µè½è¡¨è¿°ï¼‰ï¼š\n",
    "\n",
    "## 1. æƒåˆ©è¦æ±‚æ¶æ„æ¦‚è¿°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæè¿°æƒåˆ©è¦æ±‚çš„æ•´ä½“ç»“æ„ï¼ŒåŒ…æ‹¬æƒåˆ©è¦æ±‚æ•°é‡ã€ç‹¬ç«‹æƒåˆ©è¦æ±‚çš„ç±»å‹åˆ†å¸ƒã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†ææƒåˆ©è¦æ±‚ä¹‹é—´çš„é€»è¾‘å…³ç³»å’Œä¿æŠ¤ç­–ç•¥ã€‚\n",
    "\n",
    "## 2. æ ¸å¿ƒä¿æŠ¤èŒƒå›´åˆ†æï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæ·±å…¥åˆ†æç‹¬ç«‹æƒåˆ©è¦æ±‚çš„ä¿æŠ¤èŒƒå›´ï¼Œç‰¹åˆ«æ˜¯ä¸{self.target_gene}ç›¸å…³çš„å¿…è¦æŠ€æœ¯ç‰¹å¾ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æå…³é”®é™å®šæ¡ä»¶å¯¹ä¿æŠ¤èŒƒå›´çš„å½±å“ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šè¯„ä¼°å…¶ä»–ç‹¬ç«‹æƒåˆ©è¦æ±‚çš„è¡¥å……ä½œç”¨ã€‚\n",
    "\n",
    "## 3. æŠ€æœ¯ç‰¹å¾é€’è¿›ç­–ç•¥ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šåˆ†æä»å±æƒåˆ©è¦æ±‚çš„é€’è¿›é€»è¾‘å’Œå±‚æ¬¡ç»“æ„ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯„ä»·å…³é”®ä»å±æƒåˆ©è¦æ±‚çš„ä»·å€¼å’Œå•†ä¸šæ„ä¹‰ã€‚\n",
    "\n",
    "## 4. æ³•å¾‹ç¨³å®šæ€§ä¸ä¾µæƒåˆ†æï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯„ä¼°æƒåˆ©è¦æ±‚çš„æ³•å¾‹ç¨³å®šæ€§ï¼ˆæ¸…æ¥šæ€§ã€æ”¯æŒæ€§ã€åˆ›é€ æ€§ï¼‰ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æä¾µæƒåˆ¤å®šçš„å…³é”®è¦ç´ å’Œæ½œåœ¨è§„é¿è·¯å¾„ã€‚\n",
    "\n",
    "## 5. ä¸å…¶ä»–{self.target_gene}ä¸“åˆ©çš„å…³ç³»ï¼ˆ1æ®µï¼‰\n",
    "åˆ†æè¯¥ä¸“åˆ©æƒåˆ©è¦æ±‚ä¸å…¶ä»–ä¸»è¦ç”³è¯·äºº{self.target_gene}ä¸“åˆ©çš„æ½œåœ¨å†²çªæˆ–äº’è¡¥å…³ç³»ã€‚\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- ä½¿ç”¨è¿è´¯çš„ä¸“ä¸šæ®µè½\n",
    "- æ³•å¾‹åˆ†æç»“åˆå•†ä¸šè€ƒè™‘\n",
    "- æ€»å­—æ•°æ§åˆ¶åœ¨800-1200å­—\n",
    "\"\"\"\n",
    "    \n",
    "    def final_report_prompt(self, statistics: Dict, detailed_analyses: List[Dict]) -> str:\n",
    "        \"\"\"æœ€ç»ˆç»¼åˆæŠ¥å‘Šprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½ æ˜¯ä¸“ä¸šçš„ä¸“åˆ©åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®æ’°å†™ä¸€ä»½è¯¦ç»†çš„{self.target_gene}åŸºå› ç›¸å…³ä¸“åˆ©æŠ€æœ¯ç»¼è¿°æŠ¥å‘Šã€‚\n",
    "\n",
    "ã€100ç¯‡ä¸“åˆ©ç»Ÿè®¡æ•°æ®ã€‘\n",
    "{json.dumps(statistics, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ã€10ç¯‡æ ¸å¿ƒä¸“åˆ©è¯¦ç»†åˆ†æã€‘\n",
    "{json.dumps(detailed_analyses, ensure_ascii=False, indent=2)}\n",
    "\n",
    "è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ä¸“åˆ©æŠ€æœ¯ç»¼è¿°æŠ¥å‘Šï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "# {self.target_gene}åŸºå› ç›¸å…³å…¨çƒä¸“åˆ©ç«äº‰æ ¼å±€åˆ†æ\n",
    "\n",
    "## ä¸€ã€ä¸“åˆ©æ•°é‡ã€ç±»å‹ä¸åœ°åŸŸåˆ†å¸ƒ\n",
    "\n",
    "### å…¨çƒä¸“åˆ©å…¬å¼€æ•°é‡ä¸ç±»å‹ï¼ˆ400å­—ï¼‰\n",
    "åŸºäºåˆ†æçš„100ç¯‡{self.target_gene}ç›¸å…³ä¸“åˆ©ï¼Œè¯¦ç»†è¯´æ˜ï¼š\n",
    "- ä¸“åˆ©æ€»æ•°å’Œæ—¶é—´åˆ†å¸ƒè¶‹åŠ¿\n",
    "- æŠ€æœ¯ç±»å‹åˆ†å¸ƒï¼ˆå„ç±»æŠ€æœ¯å æ¯”ï¼‰\n",
    "- ä¸»è¦ç”³è¯·äººåˆ†å¸ƒ\n",
    "- æ³•å¾‹çŠ¶æ€ç»Ÿè®¡\n",
    "\n",
    "### åœ°åŸŸåˆ†å¸ƒï¼ˆ300å­—ï¼‰\n",
    "åˆ†æä¸“åˆ©çš„åœ°åŸŸå¸ƒå±€ç‰¹ç‚¹ã€‚\n",
    "\n",
    "## äºŒã€æ ¸å¿ƒä¸“åˆ©æƒåˆ©äººåŠå¸ƒå±€ç­–ç•¥\n",
    "\n",
    "åŸºäº10ç¯‡æ ¸å¿ƒä¸“åˆ©çš„æ·±åº¦åˆ†æï¼Œè¯¦ç»†æè¿°å„ä¸»è¦ç©å®¶çš„æŠ€æœ¯ç­–ç•¥ã€‚\n",
    "[æ ¹æ®å®é™…ç”³è¯·äººæƒ…å†µåŠ¨æ€ç”Ÿæˆå„å…¬å¸åˆ†æ]\n",
    "\n",
    "## ä¸‰ã€æŠ€æœ¯å‘å±•è¶‹åŠ¿ä¸å…³é”®åˆ›æ–°\n",
    "\n",
    "### æŠ€æœ¯è·¯çº¿å¯¹æ¯”ï¼ˆ500å­—ï¼‰\n",
    "è¯¦ç»†å¯¹æ¯”ä¸åŒå…¬å¸é’ˆå¯¹{self.target_gene}çš„æŠ€æœ¯æ–¹æ¡ˆå·®å¼‚ã€‚\n",
    "\n",
    "### å…³é”®æŠ€æœ¯å‚æ•°æ±‡æ€»\n",
    "æ•´ç†æ‰€æœ‰æ ¸å¿ƒä¸“åˆ©çš„å…³é”®å‚æ•°ã€‚\n",
    "\n",
    "## å››ã€ä¸“åˆ©ä¿æŠ¤èŒƒå›´ä¸æ³•å¾‹é£é™©\n",
    "\n",
    "### æƒåˆ©è¦æ±‚ä¿æŠ¤èŒƒå›´å¯¹æ¯”ï¼ˆ400å­—ï¼‰\n",
    "å¯¹æ¯”ä¸åŒä¸“åˆ©çš„ä¿æŠ¤ç­–ç•¥ã€‚\n",
    "\n",
    "### æ½œåœ¨å†²çªåˆ†æï¼ˆ300å­—ï¼‰\n",
    "è¯†åˆ«å¯èƒ½çš„ä¸“åˆ©å†²çªç‚¹ã€‚\n",
    "\n",
    "## äº”ã€å•†ä¸šæœºä¼šä¸æŠ•èµ„å»ºè®®\n",
    "\n",
    "### æŠ€æœ¯ç©ºç™½ä¸æœºä¼šï¼ˆ300å­—ï¼‰\n",
    "åŸºäºä¸“åˆ©åˆ†æè¯†åˆ«çš„{self.target_gene}é¢†åŸŸæœºä¼šã€‚\n",
    "\n",
    "### æŠ•èµ„ä¸ç ”å‘å»ºè®®ï¼ˆ300å­—ï¼‰\n",
    "- æœ€æœ‰å‰æ™¯çš„æŠ€æœ¯è·¯çº¿\n",
    "- éœ€è¦è§„é¿çš„ä¸“åˆ©å£å’\n",
    "- æ½œåœ¨çš„åˆä½œæœºä¼š\n",
    "\n",
    "## å…­ã€ç»“è®ºä¸å±•æœ›\n",
    "\n",
    "æ€»ç»“{self.target_gene}ä¸“åˆ©é¢†åŸŸçš„å‘å±•ç°çŠ¶å’Œæœªæ¥è¶‹åŠ¿ï¼ˆ300å­—ï¼‰ã€‚\n",
    "\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "1. å¿…é¡»åŸºäºæä¾›çš„æ•°æ®ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯\n",
    "2. åŒ…å«å…·ä½“çš„ä¸“åˆ©å·ã€ç”³è¯·äººã€æŠ€æœ¯ç»†èŠ‚\n",
    "3. æ•°æ®å’Œåˆ†æè¦ç›¸äº’å°è¯\n",
    "4. ä¿æŒå®¢è§‚ä¸“ä¸šçš„è¯­æ°”\n",
    "5. æ€»å­—æ•°3000-4000å­—\n",
    "\"\"\"\n",
    "# ==================== Step 4: ä¸»æµç¨‹æ‰§è¡Œ ====================\n",
    "\n",
    "class PatentAnalysisPipeline:\n",
    "    \"\"\"ä¸“åˆ©åˆ†æä¸»æµç¨‹ - é€šç”¨ç‰ˆæœ¬\"\"\"\n",
    "    \n",
    "    def __init__(self, target_gene: str = None):\n",
    "        self.target_gene = target_gene\n",
    "        self.system = PatentAnalysisSystem(target_gene)\n",
    "        self.api = ZhihuiyaAPI(self.system)\n",
    "        self.screener = PatentScreener(self.system)\n",
    "        self.prompts = None  # å°†åœ¨è¿è¡Œæ—¶åˆå§‹åŒ–\n",
    "        \n",
    "    def run_complete_analysis(self, target_gene: str = None) -> Dict:\n",
    "        \"\"\"è¿è¡Œå®Œæ•´åˆ†ææµç¨‹\n",
    "        \n",
    "        Args:\n",
    "            target_gene: ç›®æ ‡åŸºå› åç§°ï¼ˆå¦‚ \"PCSK9\", \"PD-1\", \"EGFR\" ç­‰ï¼‰\n",
    "        \n",
    "        Returns:\n",
    "            åŒ…å«ç»Ÿè®¡æ•°æ®ã€è¯¦ç»†åˆ†æå’Œæœ€ç»ˆæŠ¥å‘Šçš„å­—å…¸\n",
    "        \"\"\"\n",
    "        \n",
    "        # è®¾ç½®ç›®æ ‡åŸºå› \n",
    "        if target_gene:\n",
    "            self.target_gene = target_gene\n",
    "            self.system.set_target_gene(target_gene)\n",
    "        elif not self.target_gene:\n",
    "            raise ValueError(\"è¯·æä¾›ç›®æ ‡åŸºå› åç§°\")\n",
    "        \n",
    "        # åˆå§‹åŒ–Prompts\n",
    "        self.prompts = PatentAnalysisPrompts(self.target_gene)\n",
    "        \n",
    "        # ========== Step 1: è·å–ä¸“åˆ©æ•°æ® ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(f\"ğŸš€ Step 1: è·å–{self.target_gene}ç›¸å…³ä¸“åˆ©æ•°æ®\", \"INFO\")\n",
    "        \n",
    "        # 1.1 æœç´¢ä¸“åˆ©\n",
    "        search_results = self.api.search_patents(self.target_gene, limit=100)\n",
    "        if not search_results:\n",
    "            self.system.log(f\"æœªæ‰¾åˆ°{self.target_gene}ç›¸å…³ä¸“åˆ©\", \"ERROR\")\n",
    "            return {}\n",
    "        \n",
    "        # 1.2 å¤„ç†åŸºç¡€æ•°æ®\n",
    "        df_patents = self.screener.process_initial_patents(search_results)\n",
    "        self.system.log(f\"âœ… å¤„ç†äº† {len(df_patents)} ç¯‡ä¸“åˆ©\", \"SUCCESS\")\n",
    "        \n",
    "        # ========== Step 2: è·å–æ‘˜è¦å’Œç»Ÿè®¡åˆ†æ ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ” Step 2: è·å–æ‘˜è¦å¹¶è¿›è¡Œç»Ÿè®¡åˆ†æ\", \"INFO\")\n",
    "        \n",
    "        # 2.1 è¡¥å……æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€\n",
    "        df_patents = self.screener.enrich_with_abstracts(df_patents, self.api)\n",
    "        \n",
    "        # 2.2 ç»Ÿè®¡åˆ†æ\n",
    "        statistics = self.screener.analyze_patent_statistics(df_patents)\n",
    "        statistics[\"target_gene\"] = self.target_gene\n",
    "        self.system.log(\"ğŸ“Š ä¸“åˆ©ç»Ÿè®¡åˆ†æå®Œæˆ\", \"SUCCESS\")\n",
    "        \n",
    "        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ\n",
    "        print(f\"\\n{self.target_gene}ç›¸å…³æŠ€æœ¯ç±»å‹åˆ†å¸ƒ:\")\n",
    "        for tech, count in statistics[\"technology_distribution\"].items():\n",
    "            print(f\"  {tech}: {count}ä»¶\")\n",
    "        \n",
    "        print(f\"\\n{self.target_gene}ä¸“åˆ©ä¸»è¦ç”³è¯·äººï¼ˆå‰5ï¼‰:\")\n",
    "        assignee_dist = dict(list(statistics[\"assignee_distribution\"].items())[:5])\n",
    "        for assignee, count in assignee_dist.items():\n",
    "            print(f\"  {assignee}: {count}ä»¶\")\n",
    "        \n",
    "        # 2.3 è¯„åˆ†å’Œæ’åº\n",
    "        df_patents = self.screener.score_and_rank_patents(df_patents)\n",
    "        \n",
    "        # ========== Step 3: é€‰æ‹©Top 10ä¸“åˆ© ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ¯ Step 3: é€‰æ‹©Top 10ä¸“åˆ©è¿›è¡Œæ·±åº¦åˆ†æ\", \"INFO\")\n",
    "        \n",
    "        top10_patents = df_patents.head(10)\n",
    "        \n",
    "        # æ˜¾ç¤ºTop 10\n",
    "        print(f\"\\n{self.target_gene}ç›¸å…³Top 10ä¸“åˆ©:\")\n",
    "        for idx, row in top10_patents.iterrows():\n",
    "            print(f\"{idx+1}. {row['patent_number']} - {row['assignee'][:30]} (Score: {row['final_score']})\")\n",
    "        \n",
    "        # ========== Step 4: æ·±åº¦åˆ†æTop 10ä¸“åˆ© ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ”¬ Step 4: æ·±åº¦åˆ†ææ ¸å¿ƒä¸“åˆ©\", \"INFO\")\n",
    "        \n",
    "        detailed_analyses = []\n",
    "        \n",
    "        for idx, patent in top10_patents.iterrows():\n",
    "            self.system.log(f\"åˆ†æä¸“åˆ© {idx+1}/10: {patent['patent_number']}\")\n",
    "            \n",
    "            # 4.1 è·å–è¯´æ˜ä¹¦\n",
    "            description = self.api.get_description(patent[\"patent_id\"], patent[\"patent_number\"])\n",
    "            \n",
    "            # 4.2 è·å–æƒåˆ©è¦æ±‚\n",
    "            claims = self.api.get_claims(patent[\"patent_id\"], patent[\"patent_number\"])\n",
    "            \n",
    "            if description and claims:\n",
    "                # 4.3 LLMåˆ†æè¯´æ˜ä¹¦\n",
    "                desc_prompt = self.prompts.description_analysis_prompt(description, patent.to_dict())\n",
    "                desc_analysis = self.system.llm_call(desc_prompt)\n",
    "                \n",
    "                # 4.4 LLMåˆ†ææƒåˆ©è¦æ±‚\n",
    "                claims_prompt = self.prompts.claims_analysis_prompt(claims, patent.to_dict())\n",
    "                claims_analysis = self.system.llm_call(claims_prompt)\n",
    "                \n",
    "                detailed_analyses.append({\n",
    "                    \"patent_number\": patent[\"patent_number\"],\n",
    "                    \"assignee\": patent[\"assignee\"],\n",
    "                    \"application_date\": patent[\"application_date\"],\n",
    "                    \"title\": patent[\"title\"],\n",
    "                    \"technical_analysis\": desc_analysis,\n",
    "                    \"legal_analysis\": claims_analysis\n",
    "                })\n",
    "                \n",
    "                self.system.log(f\"âœ… å®Œæˆåˆ†æ: {patent['patent_number']}\", \"SUCCESS\")\n",
    "            else:\n",
    "                self.system.log(f\"âš ï¸ æ— æ³•è·å–å®Œæ•´å†…å®¹: {patent['patent_number']}\", \"WARN\")\n",
    "            \n",
    "            time.sleep(2)  # APIé™æµ\n",
    "        \n",
    "        # ========== Step 5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ“ Step 5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š\", \"INFO\")\n",
    "        \n",
    "        # 5.1 å‡†å¤‡æ•°æ®\n",
    "        statistics[\"top_patents\"] = top10_patents[[\"patent_number\", \"assignee\", \"final_score\"]].to_dict(\"records\")\n",
    "        \n",
    "        # 5.2 ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š\n",
    "        final_prompt = self.prompts.final_report_prompt(statistics, detailed_analyses)\n",
    "        final_report = self.system.llm_call(final_prompt)\n",
    "        \n",
    "        # ========== ä¿å­˜ç»“æœ ==========\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # ä¿å­˜è¯¦ç»†åˆ†æ\n",
    "        with open(f\"patent_detailed_analysis_{self.target_gene}_{timestamp}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\n",
    "                \"target_gene\": self.target_gene,\n",
    "                \"statistics\": statistics,\n",
    "                \"detailed_analyses\": detailed_analyses\n",
    "            }, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š\n",
    "        with open(f\"patent_report_{self.target_gene}_{timestamp}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_report)\n",
    "        \n",
    "        self.system.log(f\"âœ… {self.target_gene}ä¸“åˆ©åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜\", \"SUCCESS\")\n",
    "        \n",
    "        return {\n",
    "            \"target_gene\": self.target_gene,\n",
    "            \"statistics\": statistics,\n",
    "            \"detailed_analyses\": detailed_analyses,\n",
    "            \"final_report\": final_report\n",
    "        }\n",
    "\n",
    "# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================\n",
    "\n",
    "# ç¤ºä¾‹1ï¼šåˆ†æPCSK9åŸºå› \n",
    "def analyze_gene_patents(gene_name: str):\n",
    "    \"\"\"åˆ†ææŒ‡å®šåŸºå› çš„ä¸“åˆ©\"\"\"\n",
    "    pipeline = PatentAnalysisPipeline()\n",
    "    results = pipeline.run_complete_analysis(gene_name)\n",
    "    \n",
    "    if results and \"final_report\" in results:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"ğŸ“„ {gene_name}ä¸“åˆ©æŠ¥å‘Šé¢„è§ˆï¼ˆå‰1000å­—ï¼‰:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(results[\"final_report\"][:1000] + \"...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# è¿è¡Œåˆ†æ - å¯ä»¥æ›¿æ¢ä¸ºä»»ä½•åŸºå› \n",
    "# ç¤ºä¾‹åŸºå› åˆ—è¡¨ï¼š\n",
    "# - \"PCSK9\" (é™è„‚é¶ç‚¹)\n",
    "# - \"PD-1\" æˆ– \"PD-L1\" (å…ç–«æ£€æŸ¥ç‚¹)\n",
    "# - \"EGFR\" (è‚¿ç˜¤é¶ç‚¹)\n",
    "# - \"TNF\" æˆ– \"TNF-alpha\" (ç‚ç—‡é¶ç‚¹)\n",
    "# - \"HER2\" (ä¹³è…ºç™Œé¶ç‚¹)\n",
    "# - \"VEGF\" (è¡€ç®¡ç”Ÿæˆ)\n",
    "# - \"CD19\" (è¡€æ¶²è‚¿ç˜¤CAR-Té¶ç‚¹)\n",
    "# - \"BCMA\" (å¤šå‘æ€§éª¨é«“ç˜¤)\n",
    "# - \"GLP-1\" (ç³–å°¿ç—…/è‚¥èƒ–)\n",
    "# - \"INHBE\" (ä»£è°¢ç–¾ç—…æ–°é¶ç‚¹)\n",
    "\n",
    "# è¿è¡Œåˆ†æ\n",
    "gene_to_analyze = \"PCSK9\"  # ä¿®æ”¹è¿™é‡Œæ¥åˆ†æä¸åŒçš„åŸºå› \n",
    "results = analyze_gene_patents(gene_to_analyze)\n",
    "# æ‰¹é‡åˆ†æå¤šä¸ªåŸºå› ï¼ˆå¯é€‰ï¼‰\n",
    "def batch_analyze_genes(gene_list: List[str]):\n",
    "    \"\"\"æ‰¹é‡åˆ†æå¤šä¸ªåŸºå› \"\"\"\n",
    "    all_results = {}\n",
    "    \n",
    "    for gene in gene_list:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"å¼€å§‹åˆ†æåŸºå› : {gene}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            pipeline = PatentAnalysisPipeline()\n",
    "            results = pipeline.run_complete_analysis(gene)\n",
    "            all_results[gene] = results\n",
    "            \n",
    "            # ä¼‘æ¯ä¸€ä¸‹ï¼Œé¿å…APIé™åˆ¶\n",
    "            time.sleep(30)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"åˆ†æ{gene}æ—¶å‡ºé”™: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# æ‰¹é‡åˆ†æç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥ä½¿ç”¨ï¼‰\n",
    "# genes_to_analyze = [\"PCSK9\", \"PD-1\", \"EGFR\"]\n",
    "# batch_results = batch_analyze_genes(genes_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a741cd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:57:32] INFO: ==================================================</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:57:32] INFO: ğŸš€ Step 1: æœç´¢CAR-Tè‡ªèº«å…ç–«ç–¾ç—…ç›¸å…³ä¸“åˆ©</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:57:32] INFO: æ‰§è¡Œæœç´¢: (\"CAR-T\" OR \"CAR T\" OR \"chimeric antigen receptor\") AND (\"autoimmune\" OR \"autoimmunity\" OR \"lupus\" OR \"rheumatoid\" OR \"multiple sclerosis\")</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:57:36] INFO: æ‰§è¡Œæœç´¢: CAR-T autoimmune disease</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue;\">[23:57:40] INFO: æ‰§è¡Œæœç´¢: chimeric antigen receptor autoimmune</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red;\">[23:57:42] ERROR: æœªæ‰¾åˆ°ç›¸å…³ä¸“åˆ©</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©æ™ºèƒ½åˆ†æç³»ç»Ÿ\n",
    "åŸºäºæ™ºæ…§èŠ½APIçš„CAR-Tè‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©æ·±åº¦åˆ†æ\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# ==================== åŸºç¡€é…ç½® ====================\n",
    "\n",
    "class PatentAnalysisSystem:\n",
    "    \"\"\"ä¸“åˆ©åˆ†æç³»ç»Ÿä¸»ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, search_topic: str = None):\n",
    "        # æ™ºæ…§èŠ½APIé…ç½®\n",
    "        self.base_url = \"https://connect.zhihuiya.com\"\n",
    "        self.api_key = \"fh10ixx8marmhm9kbl3cx5676qn8nshcuwtktz0b05ebl7qf\"\n",
    "        self.client_credentials = \"74z26dxne81bnmrbd8vjwt7r8fc6tr6cxxdvapslbz4knycxknv3dnjprap6igjy\"\n",
    "        self.token = None\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # LLMé…ç½®\n",
    "        self.llm_client = OpenAI(\n",
    "            api_key='sk-9b3ad78d6d51431c90091b575072e62f',\n",
    "            base_url=\"https://api.deepseek.com\"\n",
    "        )\n",
    "        \n",
    "        # åˆ†æé…ç½®\n",
    "        self.search_topic = search_topic or \"CAR-T autoimmune\"\n",
    "        self.initial_patents = 100\n",
    "        self.top_patents = 10\n",
    "        \n",
    "    def set_search_topic(self, topic: str):\n",
    "        \"\"\"è®¾ç½®æœç´¢ä¸»é¢˜\"\"\"\n",
    "        self.search_topic = topic\n",
    "        self.log(f\"æœç´¢ä¸»é¢˜è®¾ç½®ä¸º: {topic}\", \"INFO\")\n",
    "        \n",
    "    def log(self, message: str, level: str = \"INFO\"):\n",
    "        \"\"\"æ—¥å¿—è¾“å‡º\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        color_map = {\"INFO\": \"blue\", \"SUCCESS\": \"green\", \"ERROR\": \"red\", \"WARN\": \"orange\"}\n",
    "        color = color_map.get(level, \"blue\")\n",
    "        display(HTML(f'<span style=\"color:{color};\">[{timestamp}] {level}: {message}</span>'))\n",
    "    \n",
    "    def llm_call(self, prompt: str) -> str:\n",
    "        \"\"\"è°ƒç”¨LLM\"\"\"\n",
    "        try:\n",
    "            response = self.llm_client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional patent analyst specializing in CAR-T cell therapy and autoimmune diseases.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                stream=False\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            self.log(f\"LLMè°ƒç”¨å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return \"\"\n",
    "\n",
    "# ==================== Step 1: æ™ºæ…§èŠ½APIæ¥å£ ====================\n",
    "\n",
    "class ZhihuiyaAPI:\n",
    "    \"\"\"æ™ºæ…§èŠ½APIæ¥å£ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, system: PatentAnalysisSystem):\n",
    "        self.system = system\n",
    "        \n",
    "    def authenticate(self) -> bool:\n",
    "        \"\"\"è·å–è®¿é—®token\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/oauth/token\"\n",
    "            headers = {\"content-type\": \"application/x-www-form-urlencoded\"}\n",
    "            data = f\"grant_type=client_credentials&client_id={self.system.api_key}&client_secret={self.system.client_credentials}\"\n",
    "            \n",
    "            response = self.system.session.post(url, data=data, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            if result.get(\"status\") and \"data\" in result:\n",
    "                self.system.token = result[\"data\"][\"token\"]\n",
    "                self.system.log(\"âœ… Tokenè·å–æˆåŠŸ\", \"SUCCESS\")\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"è®¤è¯å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return False\n",
    "    \n",
    "    def search_patents(self, query: str, limit: int = 100) -> List[Dict]:\n",
    "        \"\"\"P002 - ä¸“åˆ©æ£€ç´¢\"\"\"\n",
    "        if not self.system.token and not self.authenticate():\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/search/patent/query-search-patent/v2\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\"apikey\": self.system.api_key}\n",
    "            \n",
    "            payload = {\n",
    "                \"sort\": [{\"field\": \"SCORE\", \"order\": \"DESC\"}],\n",
    "                \"limit\": limit,\n",
    "                \"offset\": 0,\n",
    "                \"query_text\": query,\n",
    "                \"collapse_by\": \"PBD\",\n",
    "                \"collapse_type\": \"ALL\"\n",
    "            }\n",
    "            \n",
    "            self.system.log(f\"ğŸ” æ£€ç´¢ä¸“åˆ©: {query} (é™åˆ¶{limit}ä»¶)\")\n",
    "            response = self.system.session.post(url, params=params, json=payload, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            if result.get(\"status\") and \"data\" in result:\n",
    "                patents = result[\"data\"].get(\"results\", [])\n",
    "                self.system.log(f\"âœ… æ‰¾åˆ° {len(patents)} ä»¶ä¸“åˆ©\", \"SUCCESS\")\n",
    "                return patents\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æ£€ç´¢å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return []\n",
    "    \n",
    "    def get_simple_bibliography(self, patent_id: str, patent_number: str) -> Optional[Dict]:\n",
    "        \"\"\"P011 - è·å–ç®€è¦è‘—å½•é¡¹ç›®ï¼ˆå«æ‘˜è¦ï¼‰\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/simple-bibliography\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                return result[\"data\"][0] if isinstance(result[\"data\"], list) else result[\"data\"]\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"P011è·å–å¤±è´¥ {patent_number}: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_legal_status(self, patent_id: str, patent_number: str) -> Optional[Dict]:\n",
    "        \"\"\"è·å–æ³•å¾‹çŠ¶æ€\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/legal-status\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            return result.get(\"data\") if result.get(\"status\") else None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æ³•å¾‹çŠ¶æ€è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_claims(self, patent_id: str, patent_number: str) -> Optional[str]:\n",
    "        \"\"\"è·å–æƒåˆ©è¦æ±‚ä¹¦\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/claim-data\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key,\n",
    "                \"replace_by_related\": \"0\"\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                claims_data = result[\"data\"]\n",
    "                if isinstance(claims_data, list) and claims_data:\n",
    "                    claims = claims_data[0].get(\"claims\", [])\n",
    "                    claims_text = \"\\n\\n\".join([\n",
    "                        f\"Claim {c.get('claim_num', '')}: {c.get('claim_text', '')}\"\n",
    "                        for c in claims\n",
    "                    ])\n",
    "                    return claims_text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æƒåˆ©è¦æ±‚è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_description(self, patent_id: str, patent_number: str) -> Optional[str]:\n",
    "        \"\"\"è·å–è¯´æ˜ä¹¦\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/description-data\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key,\n",
    "                \"replace_by_related\": \"0\"\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                desc_data = result[\"data\"]\n",
    "                if isinstance(desc_data, list) and desc_data:\n",
    "                    desc_text = desc_data[0].get(\"description\", [{}])[0].get(\"text\", \"\")\n",
    "                    # é™åˆ¶é•¿åº¦\n",
    "                    if len(desc_text) > 50000:\n",
    "                        desc_text = desc_text[:50000] + \"\\n...[å†…å®¹å·²æˆªæ–­]\"\n",
    "                    return desc_text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"è¯´æ˜ä¹¦è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "\n",
    "# ==================== Step 2: CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©ç­›é€‰ä¸åˆ†æ ====================\n",
    "\n",
    "class CARTAutoImmuneScreener:\n",
    "    \"\"\"CAR-Tè‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©ç­›é€‰ä¸è¯„åˆ†\"\"\"\n",
    "    \n",
    "    def __init__(self, system: PatentAnalysisSystem):\n",
    "        self.system = system\n",
    "        \n",
    "        # CAR-Tç›¸å…³å…³é”®è¯\n",
    "        self.cart_keywords = [\n",
    "            \"car-t\", \"cart\", \"car t\", \"chimeric antigen receptor\",\n",
    "            \"car cell\", \"car therapy\", \"engineered t cell\", \"engineered tcell\",\n",
    "            \"t cell therapy\", \"tcell therapy\", \"adoptive cell\", \"cellular immunotherapy\"\n",
    "        ]\n",
    "        \n",
    "        # è‡ªèº«å…ç–«ç–¾ç—…å…³é”®è¯\n",
    "        self.autoimmune_keywords = [\n",
    "            # ä¸€èˆ¬æœ¯è¯­\n",
    "            \"autoimmune\", \"auto-immune\", \"autoimmunity\", \"self-reactive\",\n",
    "            \"tolerance\", \"immune tolerance\", \"autoreactive\",\n",
    "            \n",
    "            # å…·ä½“ç–¾ç—…\n",
    "            \"lupus\", \"sle\", \"systemic lupus erythematosus\",\n",
    "            \"rheumatoid arthritis\", \"ra arthritis\",\n",
    "            \"multiple sclerosis\", \"ms disease\",\n",
    "            \"type 1 diabetes\", \"t1d\", \"iddm\",\n",
    "            \"inflammatory bowel\", \"ibd\", \"crohn\", \"ulcerative colitis\",\n",
    "            \"psoriasis\", \"psoriatic\",\n",
    "            \"sjogren\", \"sjÃ¶gren\",\n",
    "            \"scleroderma\", \"systemic sclerosis\",\n",
    "            \"myasthenia gravis\",\n",
    "            \"hashimoto\", \"thyroiditis\",\n",
    "            \"pemphigus\", \"pemphigoid\",\n",
    "            \"vasculitis\", \"anca\",\n",
    "            \"dermatomyositis\", \"polymyositis\",\n",
    "            \"antiphospholipid\", \"aps syndrome\"\n",
    "        ]\n",
    "        \n",
    "        # ç›¸å…³é¶ç‚¹\n",
    "        self.target_keywords = [\n",
    "            \"cd19\", \"cd20\", \"bcma\", \"cd5\", \"baff\", \"april\",\n",
    "            \"cd38\", \"cd138\", \"plasmablast\", \"plasma cell\",\n",
    "            \"b cell\", \"bcell\", \"b-cell\", \"b lymphocyte\",\n",
    "            \"memory b\", \"autoreactive b\",\n",
    "            \"treg\", \"regulatory t\", \"t regulatory\",\n",
    "            \"cd4\", \"cd8\", \"cd3\", \"cd25\", \"foxp3\",\n",
    "            \"il-17\", \"il17\", \"th17\", \"il-23\", \"il23\"\n",
    "        ]\n",
    "        \n",
    "    def process_initial_patents(self, patents: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"å¤„ç†åˆå§‹ä¸“åˆ©æ•°æ®\"\"\"\n",
    "        processed = []\n",
    "        \n",
    "        for i, patent in enumerate(patents, 1):\n",
    "            if i % 20 == 0:\n",
    "                self.system.log(f\"å¤„ç†è¿›åº¦: {i}/{len(patents)}\")\n",
    "            \n",
    "            # æå–åŸºç¡€ä¿¡æ¯\n",
    "            patent_info = {\n",
    "                \"patent_id\": patent.get(\"patent_id\"),\n",
    "                \"patent_number\": patent.get(\"pn\"),\n",
    "                \"title\": self._extract_title(patent),\n",
    "                \"assignee\": patent.get(\"current_assignee\", \"\"),\n",
    "                \"application_date\": str(patent.get(\"apdt\", \"\")),\n",
    "                \"publication_date\": str(patent.get(\"pbdt\", \"\")),\n",
    "                \"abstract\": \"\",\n",
    "                \"legal_status\": \"\",\n",
    "                \"score\": patent.get(\"score\", 0),\n",
    "                \"is_cart_related\": False,\n",
    "                \"is_autoimmune_related\": False,\n",
    "                \"cart_score\": 0,\n",
    "                \"autoimmune_score\": 0\n",
    "            }\n",
    "            \n",
    "            # åˆæ­¥åˆ¤æ–­ç›¸å…³æ€§\n",
    "            title_abstract = str(patent_info[\"title\"]).lower()\n",
    "            patent_info[\"is_cart_related\"] = any(kw in title_abstract for kw in self.cart_keywords)\n",
    "            patent_info[\"is_autoimmune_related\"] = any(kw in title_abstract for kw in self.autoimmune_keywords)\n",
    "            \n",
    "            processed.append(patent_info)\n",
    "            time.sleep(0.1)  # APIé™æµ\n",
    "        \n",
    "        return pd.DataFrame(processed)\n",
    "    \n",
    "    def _extract_title(self, patent: Dict) -> str:\n",
    "        \"\"\"æå–æ ‡é¢˜\"\"\"\n",
    "        title = patent.get(\"title\", \"\")\n",
    "        if isinstance(title, dict):\n",
    "            title = title.get(\"en\") or title.get(\"zh\", \"\")\n",
    "        return str(title)\n",
    "    \n",
    "    def enrich_with_abstracts(self, df: pd.DataFrame, api: ZhihuiyaAPI) -> pd.DataFrame:\n",
    "        \"\"\"è¡¥å……æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€ï¼Œå¹¶é‡æ–°è¯„ä¼°ç›¸å…³æ€§\"\"\"\n",
    "        self.system.log(\"ğŸ“„ è·å–æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€...\")\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if idx % 10 == 0:\n",
    "                self.system.log(f\"è¿›åº¦: {idx}/{len(df)}\")\n",
    "            \n",
    "            # è·å–æ‘˜è¦\n",
    "            biblio = api.get_simple_bibliography(row[\"patent_id\"], row[\"patent_number\"])\n",
    "            if biblio:\n",
    "                abstracts = biblio.get(\"bibliographic_data\", {}).get(\"abstracts\", [])\n",
    "                if abstracts:\n",
    "                    abstract_text = abstracts[0].get(\"text\", \"\")[:1000]\n",
    "                    df.at[idx, \"abstract\"] = abstract_text\n",
    "                    \n",
    "                    # é‡æ–°è¯„ä¼°ç›¸å…³æ€§ï¼ˆåŒ…å«æ‘˜è¦ï¼‰\n",
    "                    full_text = (str(row[\"title\"]) + \" \" + abstract_text).lower()\n",
    "                    \n",
    "                    # CAR-Tç›¸å…³æ€§è¯„åˆ†\n",
    "                    cart_score = sum(2 for kw in self.cart_keywords if kw in full_text)\n",
    "                    cart_score += sum(1 for kw in self.target_keywords if kw in full_text)\n",
    "                    df.at[idx, \"cart_score\"] = cart_score\n",
    "                    df.at[idx, \"is_cart_related\"] = cart_score > 0\n",
    "                    \n",
    "                    # è‡ªèº«å…ç–«ç›¸å…³æ€§è¯„åˆ†\n",
    "                    autoimmune_score = sum(2 for kw in self.autoimmune_keywords if kw in full_text)\n",
    "                    df.at[idx, \"autoimmune_score\"] = autoimmune_score\n",
    "                    df.at[idx, \"is_autoimmune_related\"] = autoimmune_score > 0\n",
    "            \n",
    "            # è·å–æ³•å¾‹çŠ¶æ€\n",
    "            legal = api.get_legal_status(row[\"patent_id\"], row[\"patent_number\"])\n",
    "            if legal and isinstance(legal, list) and legal:\n",
    "                legal_info = legal[0].get(\"patent_legal\", {})\n",
    "                status = legal_info.get(\"simple_legal_status\", [])\n",
    "                df.at[idx, \"legal_status\"] = \", \".join(status) if status else \"Unknown\"\n",
    "            \n",
    "            time.sleep(0.2)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def filter_cart_autoimmune_patents(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"ç­›é€‰CAR-T+è‡ªèº«å…ç–«ç›¸å…³ä¸“åˆ©\"\"\"\n",
    "        # é¦–å…ˆå°è¯•ç­›é€‰åŒæ—¶åŒ…å«CAR-Tå’Œè‡ªèº«å…ç–«å…³é”®è¯çš„ä¸“åˆ©\n",
    "        filtered = df[(df[\"is_cart_related\"] == True) & (df[\"is_autoimmune_related\"] == True)]\n",
    "        \n",
    "        if len(filtered) > 0:\n",
    "            self.system.log(f\"âœ… æ‰¾åˆ° {len(filtered)} ä»¶CAR-T+è‡ªèº«å…ç–«ä¸“åˆ©\", \"SUCCESS\")\n",
    "            return filtered\n",
    "        \n",
    "        # å¦‚æœæ²¡æœ‰ä¸¥æ ¼ç¬¦åˆçš„ï¼Œå°è¯•åªæœ‰CAR-Tå…³é”®è¯çš„\n",
    "        self.system.log(\"æœªæ‰¾åˆ°ä¸¥æ ¼ç¬¦åˆCAR-T+è‡ªèº«å…ç–«çš„ä¸“åˆ©ï¼Œæ£€æŸ¥CAR-Tç›¸å…³ä¸“åˆ©...\", \"WARN\")\n",
    "        cart_only = df[df[\"cart_score\"] > 0]\n",
    "        if len(cart_only) > 0:\n",
    "            self.system.log(f\"æ‰¾åˆ° {len(cart_only)} ä»¶CAR-Tç›¸å…³ä¸“åˆ©\", \"INFO\")\n",
    "            # åœ¨è¿™äº›ä¸“åˆ©ä¸­å†æ¬¡æœç´¢å¯èƒ½çš„è‡ªèº«å…ç–«ç›¸å…³æ€§\n",
    "            return cart_only\n",
    "        \n",
    "        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œæ£€æŸ¥è‡ªèº«å…ç–«ç›¸å…³çš„\n",
    "        self.system.log(\"æ£€æŸ¥è‡ªèº«å…ç–«ç›¸å…³ä¸“åˆ©...\", \"WARN\")\n",
    "        autoimmune_only = df[df[\"autoimmune_score\"] > 0]\n",
    "        if len(autoimmune_only) > 0:\n",
    "            self.system.log(f\"æ‰¾åˆ° {len(autoimmune_only)} ä»¶è‡ªèº«å…ç–«ç›¸å…³ä¸“åˆ©\", \"INFO\")\n",
    "            return autoimmune_only\n",
    "        \n",
    "        # æœ€åè¿”å›æ‰€æœ‰ä¸“åˆ©\n",
    "        self.system.log(f\"è¿”å›æ‰€æœ‰ {len(df)} ä»¶ä¸“åˆ©è¿›è¡Œåˆ†æ\", \"WARN\")\n",
    "        return df\n",
    "    \n",
    "    def analyze_patent_statistics(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"ç»Ÿè®¡åˆ†æCAR-Tè‡ªèº«å…ç–«ä¸“åˆ©\"\"\"\n",
    "        stats = {\n",
    "            \"total_patents\": len(df),\n",
    "            \"cart_autoimmune_patents\": len(df[(df[\"is_cart_related\"] == True) & (df[\"is_autoimmune_related\"] == True)]),\n",
    "            \"cart_only\": len(df[(df[\"is_cart_related\"] == True) & (df[\"is_autoimmune_related\"] == False)]),\n",
    "            \"autoimmune_only\": len(df[(df[\"is_cart_related\"] == False) & (df[\"is_autoimmune_related\"] == True)]),\n",
    "            \"assignee_distribution\": df[\"assignee\"].value_counts().to_dict(),\n",
    "            \"year_distribution\": df[\"application_date\"].str[:4].value_counts().to_dict(),\n",
    "            \"legal_status_distribution\": df[\"legal_status\"].value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        # åˆ†æå…·ä½“ç–¾ç—…ç±»å‹\n",
    "        disease_types = {\n",
    "            \"Lupus/SLE\": 0,\n",
    "            \"Rheumatoid Arthritis\": 0,\n",
    "            \"Multiple Sclerosis\": 0,\n",
    "            \"Type 1 Diabetes\": 0,\n",
    "            \"IBD/Crohn's/UC\": 0,\n",
    "            \"Psoriasis\": 0,\n",
    "            \"Other Autoimmune\": 0,\n",
    "            \"Not Specified\": 0\n",
    "        }\n",
    "        \n",
    "        # åˆ†æé¶ç‚¹åˆ†å¸ƒ\n",
    "        target_distribution = {\n",
    "            \"CD19\": 0,\n",
    "            \"CD20\": 0,\n",
    "            \"BCMA\": 0,\n",
    "            \"CD5\": 0,\n",
    "            \"Other B cell\": 0,\n",
    "            \"T cell targets\": 0,\n",
    "            \"Other/Unknown\": 0\n",
    "        }\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            text = (str(row[\"title\"]) + \" \" + str(row[\"abstract\"])).lower()\n",
    "            \n",
    "            # ç–¾ç—…åˆ†ç±»\n",
    "            disease_found = False\n",
    "            if any(kw in text for kw in [\"lupus\", \"sle\", \"systemic lupus\"]):\n",
    "                disease_types[\"Lupus/SLE\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"rheumatoid\", \"ra arthritis\"]):\n",
    "                disease_types[\"Rheumatoid Arthritis\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"multiple sclerosis\", \"ms disease\"]):\n",
    "                disease_types[\"Multiple Sclerosis\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"type 1 diabetes\", \"t1d\", \"iddm\"]):\n",
    "                disease_types[\"Type 1 Diabetes\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"inflammatory bowel\", \"ibd\", \"crohn\", \"ulcerative colitis\"]):\n",
    "                disease_types[\"IBD/Crohn's/UC\"] += 1\n",
    "                disease_found = True\n",
    "            if any(kw in text for kw in [\"psoriasis\", \"psoriatic\"]):\n",
    "                disease_types[\"Psoriasis\"] += 1\n",
    "                disease_found = True\n",
    "            if not disease_found and row[\"is_autoimmune_related\"]:\n",
    "                disease_types[\"Other Autoimmune\"] += 1\n",
    "            elif not disease_found:\n",
    "                disease_types[\"Not Specified\"] += 1\n",
    "            \n",
    "            # é¶ç‚¹åˆ†ç±»\n",
    "            if \"cd19\" in text:\n",
    "                target_distribution[\"CD19\"] += 1\n",
    "            elif \"cd20\" in text:\n",
    "                target_distribution[\"CD20\"] += 1\n",
    "            elif \"bcma\" in text:\n",
    "                target_distribution[\"BCMA\"] += 1\n",
    "            elif \"cd5\" in text:\n",
    "                target_distribution[\"CD5\"] += 1\n",
    "            elif any(kw in text for kw in [\"b cell\", \"bcell\", \"b-cell\"]):\n",
    "                target_distribution[\"Other B cell\"] += 1\n",
    "            elif any(kw in text for kw in [\"cd4\", \"cd8\", \"cd3\", \"treg\"]):\n",
    "                target_distribution[\"T cell targets\"] += 1\n",
    "            else:\n",
    "                target_distribution[\"Other/Unknown\"] += 1\n",
    "        \n",
    "        stats[\"disease_distribution\"] = disease_types\n",
    "        stats[\"target_distribution\"] = target_distribution\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def score_and_rank_patents(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"è¯„åˆ†å¹¶æ’åºCAR-Tè‡ªèº«å…ç–«ä¸“åˆ©\"\"\"\n",
    "        self.system.log(\"âš–ï¸ ä¸“åˆ©è¯„åˆ†ä¸­...\")\n",
    "        \n",
    "        # é¡¶çº§åˆ¶è¯å’Œç»†èƒæ²»ç–—å…¬å¸\n",
    "        top_companies = [\n",
    "            \"NOVARTIS\", \"KITE\", \"JUNO\", \"CELGENE\", \"BRISTOL\", \"BMS\",\n",
    "            \"GILEAD\", \"JANSSEN\", \"JOHNSON\", \"PFIZER\", \"ROCHE\",\n",
    "            \"SANGAMO\", \"BLUEBIRD\", \"CRISPR\", \"EDITAS\", \"INTELLIA\",\n",
    "            \"CABALETTA\", \"CARTESIAN\", \"KYVERNA\", \"SONOMA\", \"TREGS\"\n",
    "        ]\n",
    "        \n",
    "        # é¡¶çº§ç ”ç©¶æœºæ„\n",
    "        top_institutions = [\n",
    "            \"UNIVERSITY\", \"PENN\", \"UPENN\", \"STANFORD\", \"MIT\", \"HARVARD\",\n",
    "            \"YALE\", \"UCLA\", \"UCSF\", \"JOHNS HOPKINS\", \"MEMORIAL SLOAN\",\n",
    "            \"FRED HUTCH\", \"DANA FARBER\", \"MD ANDERSON\", \"NIH\", \"NCI\"\n",
    "        ]\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            score = 0\n",
    "            \n",
    "            # 1. CAR-Tç›¸å…³åº¦ï¼ˆ0-30åˆ†ï¼‰\n",
    "            score += min(row[\"cart_score\"] * 3, 30)\n",
    "            \n",
    "            # 2. è‡ªèº«å…ç–«ç›¸å…³åº¦ï¼ˆ0-30åˆ†ï¼‰\n",
    "            score += min(row[\"autoimmune_score\"] * 3, 30)\n",
    "            \n",
    "            # 3. ç”³è¯·äººæƒé‡ï¼ˆ0-20åˆ†ï¼‰\n",
    "            assignee = str(row[\"assignee\"]).upper()\n",
    "            if any(comp in assignee for comp in top_companies):\n",
    "                score += 20\n",
    "            elif any(inst in assignee for inst in top_institutions):\n",
    "                score += 15\n",
    "            elif assignee:\n",
    "                score += 5\n",
    "            \n",
    "            # 4. æ—¶é—´æ–°é²œåº¦ï¼ˆ0-10åˆ†ï¼‰\n",
    "            pub_date = str(row[\"publication_date\"])\n",
    "            if pub_date >= \"20240000\":\n",
    "                score += 10\n",
    "            elif pub_date >= \"20230000\":\n",
    "                score += 8\n",
    "            elif pub_date >= \"20220000\":\n",
    "                score += 6\n",
    "            elif pub_date >= \"20200000\":\n",
    "                score += 4\n",
    "            \n",
    "            # 5. æ³•å¾‹çŠ¶æ€ï¼ˆ0-10åˆ†ï¼‰\n",
    "            legal = str(row[\"legal_status\"]).lower()\n",
    "            if \"grant\" in legal or \"æˆæƒ\" in legal:\n",
    "                score += 10\n",
    "            elif \"pending\" in legal or \"å®¡æŸ¥\" in legal:\n",
    "                score += 5\n",
    "            \n",
    "            df.at[idx, \"final_score\"] = score\n",
    "        \n",
    "        # æ’åº\n",
    "        df_sorted = df.sort_values(\"final_score\", ascending=False)\n",
    "        \n",
    "        return df_sorted\n",
    "\n",
    "# ==================== Step 3: æ·±åº¦åˆ†æPrompts ====================\n",
    "\n",
    "class CARTAutoImmuneAnalysisPrompts:\n",
    "    \"\"\"CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©åˆ†æPromptæ¨¡æ¿\"\"\"\n",
    "    \n",
    "    def description_analysis_prompt(self, description_text: str, patent_info: Dict) -> str:\n",
    "        \"\"\"è¯´æ˜ä¹¦åˆ†æprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½œä¸ºCAR-Tç»†èƒæ²»ç–—å’Œè‡ªèº«å…ç–«ç–¾ç—…é¢†åŸŸçš„ä¸“åˆ©æŠ€æœ¯ä¸“å®¶ï¼Œè¯·æ·±åº¦åˆ†æä»¥ä¸‹ä¸“åˆ©çš„è¯´æ˜ä¹¦ï¼Œå¹¶ä»¥è¿è´¯çš„æ®µè½å½¢å¼è¾“å‡ºåˆ†æç»“æœã€‚\n",
    "\n",
    "ä¸“åˆ©å·ï¼š{patent_info['patent_number']}\n",
    "ç”³è¯·äººï¼š{patent_info['assignee']}\n",
    "ç”³è¯·æ—¥ï¼š{patent_info['application_date']}\n",
    "\n",
    "è¯´æ˜ä¹¦å†…å®¹ï¼š\n",
    "{description_text}\n",
    "\n",
    "è¯·æŒ‰ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ¯éƒ¨åˆ†ç”¨2-3ä¸ªå®Œæ•´æ®µè½è¡¨è¿°ï¼‰ï¼š\n",
    "\n",
    "## 1. æŠ€æœ¯æ¦‚è¿°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæè¿°è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„CAR-TæŠ€æœ¯ï¼Œé’ˆå¯¹ä»€ä¹ˆè‡ªèº«å…ç–«ç–¾ç—…ï¼Œè¦è§£å†³ä»€ä¹ˆå…·ä½“é—®é¢˜ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯´æ˜æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼Œç‰¹åˆ«æ˜¯ç›¸æ¯”ä¼ ç»ŸCAR-Tè‚¿ç˜¤æ²»ç–—çš„é€‚åº”æ€§æ”¹è¿›ã€‚\n",
    "\n",
    "## 2. CARç»“æ„ä¸è®¾è®¡ï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯¦ç»†æè¿°CARçš„ç»“æ„è®¾è®¡ï¼ŒåŒ…æ‹¬æŠ—åŸè¯†åˆ«åŸŸ(scFv)ã€é“°é“¾åŒºã€è·¨è†œåŸŸã€ä¿¡å·è½¬å¯¼åŸŸçš„å…·ä½“é€‰æ‹©ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æé¶ç‚¹é€‰æ‹©çš„ç§‘å­¦ä¾æ®ï¼Œä¸ºä»€ä¹ˆé€‰æ‹©è¯¥é¶ç‚¹æ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šå®‰å…¨æ€§è®¾è®¡ï¼Œå¦‚è‡ªæ€å¼€å…³ã€å¯è°ƒæ§ç³»ç»Ÿã€é¿å…è¿‡åº¦å…ç–«æŠ‘åˆ¶çš„ç­–ç•¥ã€‚\n",
    "\n",
    "## 3. åˆ¶å¤‡å·¥è‰ºä¸è´¨æ§ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šTç»†èƒæ¥æºã€è½¬å¯¼æ–¹æ³•ï¼ˆæ…¢ç—…æ¯’/é€†è½¬å½•ç—…æ¯’/ç”µç©¿å­”ï¼‰ã€æ‰©å¢åŸ¹å…»æ¡ä»¶ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè´¨é‡æ§åˆ¶æ ‡å‡†ï¼ŒåŒ…æ‹¬CARè¡¨è¾¾ç‡ã€ç»†èƒçº¯åº¦ã€åŠŸèƒ½æ£€æµ‹ç­‰ã€‚\n",
    "\n",
    "## 4. å®éªŒéªŒè¯ï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šä½“å¤–å®éªŒè®¾è®¡ï¼ŒåŒ…æ‹¬ç»†èƒæ¯’æ€§ã€ç»†èƒå› å­é‡Šæ”¾ã€é¶ç»†èƒæ¸…é™¤ç­‰ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåŠ¨ç‰©æ¨¡å‹å®éªŒï¼Œä½¿ç”¨ä»€ä¹ˆè‡ªèº«å…ç–«ç–¾ç—…æ¨¡å‹ï¼Œç–—æ•ˆè¯„ä¼°æŒ‡æ ‡ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šä¸´åºŠå‰å®‰å…¨æ€§è¯„ä¼°ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹è‡ªèº«å…ç–«æ²»ç–—çš„ç‰¹æ®Šå®‰å…¨æ€§è€ƒè™‘ã€‚\n",
    "\n",
    "## 5. ä¸´åºŠè½¬åŒ–æ½œåŠ›ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šç›®æ ‡é€‚åº”ç—‡çš„å¸‚åœºè§„æ¨¡ï¼Œä¸ç°æœ‰ç–—æ³•ï¼ˆç”Ÿç‰©åˆ¶å‰‚ã€å°åˆ†å­è¯ç‰©ï¼‰çš„æ¯”è¾ƒä¼˜åŠ¿ã€‚\n",
    "ç¬¬äºŒæ®µï¼šä¸´åºŠå¼€å‘ç­–ç•¥ï¼Œé¢„æœŸçš„ä¸´åºŠè¯•éªŒè®¾è®¡ï¼Œå‰‚é‡é€‰æ‹©ï¼Œç–—æ•ˆç»ˆç‚¹ã€‚\n",
    "\n",
    "## 6. å…³é”®æŠ€æœ¯å‚æ•°æå–\n",
    "- CARç»“æ„ï¼šå…·ä½“çš„scFvã€ä¿¡å·åŸŸç»„åˆ\n",
    "- é¶ç‚¹ï¼šå…·ä½“çš„æŠ—åŸé¶ç‚¹\n",
    "- é€‚åº”ç—‡ï¼šç›®æ ‡è‡ªèº«å…ç–«ç–¾ç—…\n",
    "- åˆ¶å¤‡å‚æ•°ï¼šè½¬å¯¼æ•ˆç‡ã€æ‰©å¢å€æ•°\n",
    "- ç–—æ•ˆæ•°æ®ï¼šå…³é”®çš„ä½“å†…å¤–å®éªŒæ•°æ®\n",
    "- å®‰å…¨æ€§ç‰¹å¾ï¼šç‰¹æ®Šçš„å®‰å…¨æ€§è®¾è®¡\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- ä½¿ç”¨å®Œæ•´æµç•…çš„æ®µè½ï¼Œé¿å…ç¢ç‰‡åŒ–åˆ—è¡¨\n",
    "- çªå‡ºCAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…çš„ç‰¹æ®Šæ€§\n",
    "- ä¿æŒä¸“ä¸šä½†æ˜“è¯»çš„æ–‡é£\n",
    "- æ€»å­—æ•°æ§åˆ¶åœ¨1000-1500å­—\n",
    "\"\"\"\n",
    "    \n",
    "    def claims_analysis_prompt(self, claims_text: str, patent_info: Dict) -> str:\n",
    "        \"\"\"æƒåˆ©è¦æ±‚åˆ†æprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½œä¸ºä¸“åˆ©æ³•å¾‹ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹CAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©çš„æƒåˆ©è¦æ±‚ä¹¦ï¼Œå¹¶ä»¥é€‚åˆä¸“ä¸šæŠ¥å‘Šçš„æ®µè½å½¢å¼è¾“å‡ºã€‚\n",
    "\n",
    "ä¸“åˆ©å·ï¼š{patent_info['patent_number']}\n",
    "ç”³è¯·äººï¼š{patent_info['assignee']}\n",
    "\n",
    "æƒåˆ©è¦æ±‚ä¹¦ï¼š\n",
    "{claims_text}\n",
    "\n",
    "è¯·æŒ‰ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ¯éƒ¨åˆ†ç”¨2-3ä¸ªå®Œæ•´æ®µè½è¡¨è¿°ï¼‰ï¼š\n",
    "\n",
    "## 1. æƒåˆ©è¦æ±‚æ¶æ„æ¦‚è¿°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæè¿°æƒåˆ©è¦æ±‚çš„æ•´ä½“ç»“æ„ï¼Œäº§å“æƒåˆ©è¦æ±‚ä¸æ–¹æ³•æƒåˆ©è¦æ±‚çš„åˆ†å¸ƒã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æCAR-Tç›¸å…³æƒåˆ©è¦æ±‚çš„å±‚æ¬¡è®¾è®¡ç­–ç•¥ã€‚\n",
    "\n",
    "## 2. æ ¸å¿ƒä¿æŠ¤èŒƒå›´åˆ†æï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šåˆ†æCARç»“æ„ç›¸å…³çš„æƒåˆ©è¦æ±‚ä¿æŠ¤èŒƒå›´ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†ææ²»ç–—æ–¹æ³•ç›¸å…³çš„æƒåˆ©è¦æ±‚ï¼Œç‰¹åˆ«æ˜¯è‡ªèº«å…ç–«é€‚åº”ç—‡çš„é™å®šã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šè¯„ä¼°åˆ¶å¤‡æ–¹æ³•æƒåˆ©è¦æ±‚çš„ä¿æŠ¤ä»·å€¼ã€‚\n",
    "\n",
    "## 3. æŠ€æœ¯ç‰¹å¾é€’è¿›ç­–ç•¥ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šåˆ†æä»å±æƒåˆ©è¦æ±‚å¦‚ä½•é€æ­¥é™å®šCARç»“æ„ã€é¶ç‚¹ã€ç–¾ç—…ç±»å‹ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯„ä»·å…³é”®ä»å±æƒåˆ©è¦æ±‚å¯¹å•†ä¸šåŒ–çš„å½±å“ã€‚\n",
    "\n",
    "## 4. æ³•å¾‹ç¨³å®šæ€§ä¸ä¾µæƒåˆ†æï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯„ä¼°æƒåˆ©è¦æ±‚ç›¸å¯¹äºç°æœ‰CAR-TæŠ€æœ¯çš„åˆ›é€ æ€§ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†ææ½œåœ¨çš„è®¾è®¡è§„é¿è·¯å¾„å’Œé˜²å¾¡ç­–ç•¥ã€‚\n",
    "\n",
    "## 5. ä¸å…¶ä»–CAR-Tä¸“åˆ©çš„å…³ç³»ï¼ˆ1æ®µï¼‰\n",
    "åˆ†æè¯¥ä¸“åˆ©ä¸Novartisã€Kiteç­‰ä¸»è¦CAR-Tä¸“åˆ©çš„åŒºåˆ«å’Œæ½œåœ¨å†²çªã€‚\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- ä½¿ç”¨è¿è´¯çš„ä¸“ä¸šæ®µè½\n",
    "- çªå‡ºè‡ªèº«å…ç–«é¢†åŸŸçš„ç‰¹æ®Šæ€§\n",
    "- æ€»å­—æ•°æ§åˆ¶åœ¨800-1200å­—\n",
    "\"\"\"\n",
    "    \n",
    "    def final_report_prompt(self, statistics: Dict, detailed_analyses: List[Dict]) -> str:\n",
    "        \"\"\"æœ€ç»ˆç»¼åˆæŠ¥å‘Šprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½ æ˜¯ä¸“ä¸šçš„ä¸“åˆ©åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®æ’°å†™ä¸€ä»½è¯¦ç»†çš„CAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…ä¸“åˆ©æŠ€æœ¯ç»¼è¿°æŠ¥å‘Šã€‚\n",
    "\n",
    "ã€ä¸“åˆ©ç»Ÿè®¡æ•°æ®ã€‘\n",
    "{json.dumps(statistics, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ã€æ ¸å¿ƒä¸“åˆ©è¯¦ç»†åˆ†æã€‘\n",
    "{json.dumps(detailed_analyses, ensure_ascii=False, indent=2)}\n",
    "\n",
    "è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ä¸“åˆ©æŠ€æœ¯ç»¼è¿°æŠ¥å‘Šï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "# CAR-Tç»†èƒç–—æ³•æ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…å…¨çƒä¸“åˆ©æ€åŠ¿åˆ†æ\n",
    "\n",
    "## æ‰§è¡Œæ‘˜è¦\n",
    "ç®€è¦æ¦‚è¿°CAR-Tåœ¨è‡ªèº«å…ç–«é¢†åŸŸçš„ä¸“åˆ©ç°çŠ¶å’Œä¸»è¦å‘ç°ï¼ˆ300å­—ï¼‰ã€‚\n",
    "\n",
    "## ä¸€ã€æŠ€æœ¯èƒŒæ™¯ä¸å¸‚åœºæœºé‡\n",
    "\n",
    "### CAR-Tä»è‚¿ç˜¤åˆ°è‡ªèº«å…ç–«çš„è½¬åŒ–ï¼ˆ400å­—ï¼‰\n",
    "- CAR-Tåœ¨è¡€æ¶²è‚¿ç˜¤çš„æˆåŠŸç»éªŒ\n",
    "- è‡ªèº«å…ç–«ç–¾ç—…çš„æœªæ»¡è¶³éœ€æ±‚\n",
    "- CAR-Tæ²»ç–—è‡ªèº«å…ç–«çš„ç§‘å­¦åŸºç¡€\n",
    "\n",
    "### ä¸“åˆ©ç”³è¯·è¶‹åŠ¿åˆ†æï¼ˆ300å­—ï¼‰\n",
    "åŸºäºç»Ÿè®¡æ•°æ®ï¼Œåˆ†æï¼š\n",
    "- å¹´åº¦ç”³è¯·é‡å˜åŒ–\n",
    "- æŠ€æœ¯æˆç†Ÿåº¦è¯„ä¼°\n",
    "- ä¸CAR-Tè‚¿ç˜¤ä¸“åˆ©çš„å¯¹æ¯”\n",
    "\n",
    "## äºŒã€ä¸»è¦ä¸“åˆ©æƒåˆ©äººç«äº‰æ ¼å±€\n",
    "\n",
    "### é¢†å…ˆä¼ä¸šåˆ†æï¼ˆå„300å­—ï¼‰\n",
    "åŸºäºæ ¸å¿ƒä¸“åˆ©åˆ†æï¼Œè¯¦è¿°ä¸»è¦ç”³è¯·äººçš„ï¼š\n",
    "- æŠ€æœ¯è·¯çº¿ç‰¹ç‚¹\n",
    "- ä¸“åˆ©å¸ƒå±€ç­–ç•¥\n",
    "- ä¸´åºŠå¼€å‘è¿›å±•\n",
    "\n",
    "### å­¦æœ¯æœºæ„è´¡çŒ®ï¼ˆ300å­—ï¼‰\n",
    "åˆ†æå¤§å­¦å’Œç ”ç©¶æœºæ„çš„ä¸“åˆ©ç‰¹ç‚¹ã€‚\n",
    "\n",
    "## ä¸‰ã€å…³é”®æŠ€æœ¯åˆ›æ–°åˆ†æ\n",
    "\n",
    "### é¶ç‚¹é€‰æ‹©ç­–ç•¥ï¼ˆ400å­—ï¼‰\n",
    "- CD19 Bç»†èƒæ¸…é™¤ç­–ç•¥\n",
    "- å…¶ä»–Bç»†èƒé¶ç‚¹ï¼ˆCD20ã€BCMAç­‰ï¼‰\n",
    "- Tç»†èƒé¶ç‚¹æ¢ç´¢\n",
    "- åŒé¶ç‚¹CARè®¾è®¡\n",
    "\n",
    "### CARç»“æ„ä¼˜åŒ–ï¼ˆ400å­—ï¼‰\n",
    "- é’ˆå¯¹è‡ªèº«å…ç–«çš„ç‰¹æ®Šè®¾è®¡\n",
    "- å®‰å…¨æ€§æ”¹è¿›ï¼ˆè‡ªæ€å¼€å…³ã€å¯è°ƒæ§ç³»ç»Ÿï¼‰\n",
    "- æŒä¹…æ€§ä¸è®°å¿†æ€§ä¼˜åŒ–\n",
    "\n",
    "### é€‚åº”ç—‡è¦†ç›–ï¼ˆ400å­—ï¼‰\n",
    "åŸºäºä¸“åˆ©åˆ†æçš„ç–¾ç—…åˆ†å¸ƒï¼š\n",
    "- ç‹¼ç–®ç­‰Bç»†èƒä»‹å¯¼ç–¾ç—…\n",
    "- ç±»é£æ¹¿å…³èŠ‚ç‚\n",
    "- å…¶ä»–è‡ªèº«å…ç–«ç–¾ç—…\n",
    "\n",
    "## å››ã€ä¸“åˆ©ä¿æŠ¤ç­–ç•¥åˆ†æ\n",
    "\n",
    "### æƒåˆ©è¦æ±‚è®¾è®¡ç‰¹ç‚¹ï¼ˆ300å­—ï¼‰\n",
    "- äº§å“vsæ–¹æ³•æƒåˆ©è¦æ±‚\n",
    "- ä¿æŠ¤èŒƒå›´çš„å¹³è¡¡\n",
    "- ä¸è‚¿ç˜¤CAR-Tä¸“åˆ©çš„åŒºåˆ†\n",
    "\n",
    "### æ½œåœ¨çš„ä¸“åˆ©çº çº·ï¼ˆ300å­—ï¼‰\n",
    "- åŸºç¡€CAR-Tä¸“åˆ©çš„å½±å“\n",
    "- äº¤å‰è®¸å¯å¯èƒ½æ€§\n",
    "\n",
    "## äº”ã€ä¸´åºŠè½¬åŒ–ä¸å•†ä¸šåŒ–å‰æ™¯\n",
    "\n",
    "### ä¸´åºŠè¯•éªŒç°çŠ¶ï¼ˆ300å­—ï¼‰\n",
    "åŸºäºä¸“åˆ©ä¸­çš„ä¸´åºŠè®¾è®¡ä¿¡æ¯ã€‚\n",
    "\n",
    "### å¸‚åœºé¢„æµ‹ï¼ˆ300å­—ï¼‰\n",
    "- ç›®æ ‡æ‚£è€…ç¾¤ä½“\n",
    "- å®šä»·ç­–ç•¥è€ƒè™‘\n",
    "- ä¸ç°æœ‰ç–—æ³•çš„ç«äº‰\n",
    "\n",
    "## å…­ã€æŠ€æœ¯å‘å±•è¶‹åŠ¿ä¸æŠ•èµ„æœºä¼š\n",
    "\n",
    "### æœªæ¥æŠ€æœ¯æ–¹å‘ï¼ˆ400å­—ï¼‰\n",
    "- é€šç”¨å‹CAR-T\n",
    "- åŸºå› ç¼–è¾‘å¢å¼º\n",
    "- è”åˆæ²»ç–—ç­–ç•¥\n",
    "\n",
    "### æŠ•èµ„å»ºè®®ï¼ˆ300å­—ï¼‰\n",
    "- æœ€å…·æ½œåŠ›çš„æŠ€æœ¯è·¯çº¿\n",
    "- å…³æ³¨çš„ä¼ä¸šå’Œæœºæ„\n",
    "- åˆä½œä¸è®¸å¯æœºä¼š\n",
    "\n",
    "## ä¸ƒã€ç»“è®º\n",
    "æ€»ç»“CAR-Tæ²»ç–—è‡ªèº«å…ç–«ç–¾ç—…çš„ä¸“åˆ©ç°çŠ¶ã€æœºé‡ä¸æŒ‘æˆ˜ï¼ˆ300å­—ï¼‰ã€‚\n",
    "\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "1. åŸºäºå®é™…æ•°æ®ï¼Œä¸ç¼–é€ ä¿¡æ¯\n",
    "2. çªå‡ºCAR-Tæ²»ç–—è‡ªèº«å…ç–«çš„ç‰¹æ®Šæ€§\n",
    "3. åŒ…å«å…·ä½“ä¸“åˆ©å·å’Œç”³è¯·äººä¿¡æ¯\n",
    "4. ä¿æŒå®¢è§‚ä¸“ä¸šçš„åˆ†æè§†è§’\n",
    "5. æ€»å­—æ•°3500-4500å­—\n",
    "\"\"\"\n",
    "\n",
    "# ==================== Step 4: ä¸»æµç¨‹æ‰§è¡Œ ====================\n",
    "\n",
    "class CARTAutoImmuneAnalysisPipeline:\n",
    "    \"\"\"CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©åˆ†æä¸»æµç¨‹\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.system = PatentAnalysisSystem()\n",
    "        self.api = ZhihuiyaAPI(self.system)\n",
    "        self.screener = CARTAutoImmuneScreener(self.system)\n",
    "        self.prompts = CARTAutoImmuneAnalysisPrompts()\n",
    "        \n",
    "    def run_complete_analysis(self) -> Dict:\n",
    "        \"\"\"è¿è¡Œå®Œæ•´åˆ†ææµç¨‹\"\"\"\n",
    "        \n",
    "        # ========== Step 1: æ„å»ºæœç´¢æŸ¥è¯¢ ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸš€ Step 1: æœç´¢CAR-Tè‡ªèº«å…ç–«ç–¾ç—…ç›¸å…³ä¸“åˆ©\", \"INFO\")\n",
    "        \n",
    "        # æ„å»ºå¤åˆæœç´¢æŸ¥è¯¢\n",
    "        search_queries = [\n",
    "            '(\"CAR-T\" OR \"CAR T\" OR \"chimeric antigen receptor\") AND (\"autoimmune\" OR \"autoimmunity\" OR \"lupus\" OR \"rheumatoid\" OR \"multiple sclerosis\")',\n",
    "            'CAR-T autoimmune disease',\n",
    "            'chimeric antigen receptor autoimmune',\n",
    "            'CAR T cell therapy lupus SLE',\n",
    "            'CAR-T rheumatoid arthritis',\n",
    "            'engineered T cell autoimmune'\n",
    "        ]\n",
    "        \n",
    "        all_patents = []\n",
    "        seen_ids = set()\n",
    "        \n",
    "        # æ‰§è¡Œå¤šä¸ªæœç´¢æŸ¥è¯¢ä»¥è·å¾—æ›´å…¨é¢çš„ç»“æœ\n",
    "        for query in search_queries[:3]:  # ä½¿ç”¨å‰3ä¸ªæŸ¥è¯¢\n",
    "            self.system.log(f\"æ‰§è¡Œæœç´¢: {query}\")\n",
    "            results = self.api.search_patents(query, limit=50)\n",
    "            \n",
    "            for patent in results:\n",
    "                patent_id = patent.get(\"patent_id\")\n",
    "                if patent_id not in seen_ids:\n",
    "                    all_patents.append(patent)\n",
    "                    seen_ids.add(patent_id)\n",
    "            \n",
    "            time.sleep(2)  # é¿å…APIé™åˆ¶\n",
    "        \n",
    "        if not all_patents:\n",
    "            self.system.log(\"æœªæ‰¾åˆ°ç›¸å…³ä¸“åˆ©\", \"ERROR\")\n",
    "            return {}\n",
    "        \n",
    "        self.system.log(f\"âœ… å…±æ‰¾åˆ° {len(all_patents)} ä»¶å”¯ä¸€ä¸“åˆ©\", \"SUCCESS\")\n",
    "        \n",
    "        # ========== Step 2: åˆæ­¥å¤„ç†å’Œç­›é€‰ ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ” Step 2: å¤„ç†ä¸“åˆ©æ•°æ®å¹¶ç­›é€‰ç›¸å…³ä¸“åˆ©\", \"INFO\")\n",
    "        \n",
    "        # 2.1 å¤„ç†åŸºç¡€æ•°æ®\n",
    "        df_patents = self.screener.process_initial_patents(all_patents)\n",
    "        \n",
    "        # 2.2 è¡¥å……æ‘˜è¦å¹¶é‡æ–°è¯„ä¼°ç›¸å…³æ€§\n",
    "        df_patents = self.screener.enrich_with_abstracts(df_patents, self.api)\n",
    "        \n",
    "        # 2.3 ç­›é€‰CAR-T+è‡ªèº«å…ç–«ç›¸å…³ä¸“åˆ©\n",
    "        df_filtered = self.screener.filter_cart_autoimmune_patents(df_patents)\n",
    "        \n",
    "        if len(df_filtered) == 0:\n",
    "            self.system.log(\"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¸“åˆ©\", \"ERROR\")\n",
    "            return {}\n",
    "        \n",
    "        # 2.4 ç»Ÿè®¡åˆ†æ\n",
    "        statistics = self.screener.analyze_patent_statistics(df_filtered)\n",
    "        self.system.log(\"ğŸ“Š ä¸“åˆ©ç»Ÿè®¡åˆ†æå®Œæˆ\", \"SUCCESS\")\n",
    "        \n",
    "        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ\n",
    "        print(\"\\nCAR-Tè‡ªèº«å…ç–«ä¸“åˆ©ç»Ÿè®¡:\")\n",
    "        print(f\"  æ€»ä¸“åˆ©æ•°: {statistics['total_patents']}\")\n",
    "        print(f\"  CAR-T+è‡ªèº«å…ç–«: {statistics['cart_autoimmune_patents']}\")\n",
    "        \n",
    "        print(\"\\nç–¾ç—…ç±»å‹åˆ†å¸ƒ:\")\n",
    "        for disease, count in statistics[\"disease_distribution\"].items():\n",
    "            if count > 0:\n",
    "                print(f\"  {disease}: {count}ä»¶\")\n",
    "        \n",
    "        print(\"\\né¶ç‚¹åˆ†å¸ƒ:\")\n",
    "        for target, count in statistics[\"target_distribution\"].items():\n",
    "            if count > 0:\n",
    "                print(f\"  {target}: {count}ä»¶\")\n",
    "        \n",
    "        # 2.5 è¯„åˆ†å’Œæ’åº\n",
    "        df_filtered = self.screener.score_and_rank_patents(df_filtered)\n",
    "        \n",
    "        # ========== Step 3: é€‰æ‹©Topä¸“åˆ© ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ¯ Step 3: é€‰æ‹©Topä¸“åˆ©è¿›è¡Œæ·±åº¦åˆ†æ\", \"INFO\")\n",
    "        \n",
    "        # é€‰æ‹©å‰10ä¸ªæˆ–æ‰€æœ‰ï¼ˆå¦‚æœå°‘äº10ä¸ªï¼‰\n",
    "        num_top = min(10, len(df_filtered))\n",
    "        top_patents = df_filtered.head(num_top)\n",
    "        \n",
    "        print(f\"\\nTop {num_top} CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©:\")\n",
    "        for i, (idx, row) in enumerate(top_patents.iterrows(), 1):\n",
    "            print(f\"{i}. {row['patent_number']} - {row['assignee'][:40]} (Score: {row['final_score']})\")\n",
    "        \n",
    "        # ========== Step 4: æ·±åº¦åˆ†æTopä¸“åˆ© ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ”¬ Step 4: æ·±åº¦åˆ†ææ ¸å¿ƒä¸“åˆ©\", \"INFO\")\n",
    "        \n",
    "        detailed_analyses = []\n",
    "        \n",
    "        for i, (idx, patent) in enumerate(top_patents.iterrows(), 1):\n",
    "            self.system.log(f\"åˆ†æä¸“åˆ© {i}/{num_top}: {patent['patent_number']}\")\n",
    "            \n",
    "            # 4.1 è·å–è¯´æ˜ä¹¦\n",
    "            description = self.api.get_description(patent[\"patent_id\"], patent[\"patent_number\"])\n",
    "            \n",
    "            # 4.2 è·å–æƒåˆ©è¦æ±‚\n",
    "            claims = self.api.get_claims(patent[\"patent_id\"], patent[\"patent_number\"])\n",
    "            \n",
    "            if description and claims:\n",
    "                # 4.3 LLMåˆ†æè¯´æ˜ä¹¦\n",
    "                desc_prompt = self.prompts.description_analysis_prompt(description, patent.to_dict())\n",
    "                desc_analysis = self.system.llm_call(desc_prompt)\n",
    "                \n",
    "                # 4.4 LLMåˆ†ææƒåˆ©è¦æ±‚\n",
    "                claims_prompt = self.prompts.claims_analysis_prompt(claims, patent.to_dict())\n",
    "                claims_analysis = self.system.llm_call(claims_prompt)\n",
    "                \n",
    "                detailed_analyses.append({\n",
    "                    \"patent_number\": patent[\"patent_number\"],\n",
    "                    \"assignee\": patent[\"assignee\"],\n",
    "                    \"application_date\": patent[\"application_date\"],\n",
    "                    \"title\": patent[\"title\"],\n",
    "                    \"cart_score\": patent[\"cart_score\"],\n",
    "                    \"autoimmune_score\": patent[\"autoimmune_score\"],\n",
    "                    \"technical_analysis\": desc_analysis,\n",
    "                    \"legal_analysis\": claims_analysis\n",
    "                })\n",
    "                \n",
    "                self.system.log(f\"âœ… å®Œæˆåˆ†æ: {patent['patent_number']}\", \"SUCCESS\")\n",
    "            else:\n",
    "                self.system.log(f\"âš ï¸ æ— æ³•è·å–å®Œæ•´å†…å®¹: {patent['patent_number']}\", \"WARN\")\n",
    "            \n",
    "            time.sleep(2)  # APIé™æµ\n",
    "        \n",
    "        # ========== Step 5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ“ Step 5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š\", \"INFO\")\n",
    "        \n",
    "        # 5.1 å‡†å¤‡æ•°æ®\n",
    "        statistics[\"top_patents\"] = top_patents[[\"patent_number\", \"assignee\", \"final_score\"]].to_dict(\"records\")\n",
    "        \n",
    "        # 5.2 ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š\n",
    "        final_prompt = self.prompts.final_report_prompt(statistics, detailed_analyses)\n",
    "        final_report = self.system.llm_call(final_prompt)\n",
    "        \n",
    "        # ========== ä¿å­˜ç»“æœ ==========\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # ä¿å­˜ä¸“åˆ©åˆ—è¡¨\n",
    "        df_filtered.to_csv(f\"cart_autoimmune_patents_{timestamp}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        self.system.log(f\"âœ… ä¸“åˆ©åˆ—è¡¨å·²ä¿å­˜è‡³: cart_autoimmune_patents_{timestamp}.csv\", \"SUCCESS\")\n",
    "        \n",
    "        # ä¿å­˜è¯¦ç»†åˆ†æ\n",
    "        with open(f\"cart_autoimmune_detailed_analysis_{timestamp}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\n",
    "                \"statistics\": statistics,\n",
    "                \"detailed_analyses\": detailed_analyses\n",
    "            }, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š\n",
    "        with open(f\"cart_autoimmune_report_{timestamp}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_report)\n",
    "        \n",
    "        self.system.log(f\"âœ… CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©åˆ†æå®Œæˆï¼\", \"SUCCESS\")\n",
    "        self.system.log(f\"âœ… æŠ¥å‘Šå·²ä¿å­˜è‡³: cart_autoimmune_report_{timestamp}.md\", \"SUCCESS\")\n",
    "        \n",
    "        return {\n",
    "            \"statistics\": statistics,\n",
    "            \"detailed_analyses\": detailed_analyses,\n",
    "            \"final_report\": final_report,\n",
    "            \"patents_df\": df_filtered\n",
    "        }\n",
    "\n",
    "# ==================== è¿è¡Œåˆ†æ ====================\n",
    "\n",
    "# åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ\n",
    "pipeline = CARTAutoImmuneAnalysisPipeline()\n",
    "results = pipeline.run_complete_analysis()\n",
    "\n",
    "# æ˜¾ç¤ºæŠ¥å‘Šé¢„è§ˆ\n",
    "if results and \"final_report\" in results:\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ğŸ“„ CAR-Tè‡ªèº«å…ç–«ä¸“åˆ©åˆ†ææŠ¥å‘Šé¢„è§ˆï¼ˆå‰1500å­—ï¼‰:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(results[\"final_report\"][:1500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ef801",
   "metadata": {
    "vscode": {
     "languageId": "groovy"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "é€šç”¨åŸºå› ä¸“åˆ©æ™ºèƒ½åˆ†æç³»ç»Ÿ - Universal Gene Patent Analysis System\n",
    "åŸºäºæ™ºæ…§èŠ½APIçš„ä»»æ„åŸºå› ä¸“åˆ©æ·±åº¦åˆ†æ\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# ==================== åŸºç¡€é…ç½® ====================\n",
    "\n",
    "class PatentAnalysisSystem:\n",
    "    \"\"\"ä¸“åˆ©åˆ†æç³»ç»Ÿä¸»ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, target_gene: str = None):\n",
    "        # æ™ºæ…§èŠ½APIé…ç½®\n",
    "        self.base_url = \"https://connect.zhihuiya.com\"\n",
    "        self.api_key = \"fh10ixx8marmhm9kbl3cx5676qn8nshcuwtktz0b05ebl7qf\"\n",
    "        self.client_credentials = \"74z26dxne81bnmrbd8vjwt7r8fc6tr6cxxdvapslbz4knycxknv3dnjprap6igjy\"\n",
    "        self.token = None\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # LLMé…ç½®\n",
    "        self.llm_client = OpenAI(\n",
    "            api_key='sk-9b3ad78d6d51431c90091b575072e62f',\n",
    "            base_url=\"https://api.deepseek.com\"\n",
    "        )\n",
    "        \n",
    "        # åˆ†æé…ç½®\n",
    "        self.target_gene = target_gene or \"GENE\"  # é»˜è®¤åŸºå› å\n",
    "        self.initial_patents = 100\n",
    "        self.top_patents = 10\n",
    "        \n",
    "    def set_target_gene(self, gene_name: str):\n",
    "        \"\"\"è®¾ç½®ç›®æ ‡åŸºå› \"\"\"\n",
    "        self.target_gene = gene_name\n",
    "        self.log(f\"ç›®æ ‡åŸºå› è®¾ç½®ä¸º: {gene_name}\", \"INFO\")\n",
    "        \n",
    "    def log(self, message: str, level: str = \"INFO\"):\n",
    "        \"\"\"æ—¥å¿—è¾“å‡º\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        color_map = {\"INFO\": \"blue\", \"SUCCESS\": \"green\", \"ERROR\": \"red\", \"WARN\": \"orange\"}\n",
    "        color = color_map.get(level, \"blue\")\n",
    "        display(HTML(f'<span style=\"color:{color};\">[{timestamp}] {level}: {message}</span>'))\n",
    "    \n",
    "    def llm_call(self, prompt: str) -> str:\n",
    "        \"\"\"è°ƒç”¨LLM\"\"\"\n",
    "        try:\n",
    "            response = self.llm_client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional patent analyst specializing in biotechnology and pharmaceutical patents.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                stream=False\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            self.log(f\"LLMè°ƒç”¨å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return \"\"\n",
    "\n",
    "# ==================== Step 1: æ™ºæ…§èŠ½APIæ¥å£ ====================\n",
    "\n",
    "class ZhihuiyaAPI:\n",
    "    \"\"\"æ™ºæ…§èŠ½APIæ¥å£ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, system: PatentAnalysisSystem):\n",
    "        self.system = system\n",
    "        \n",
    "    def authenticate(self) -> bool:\n",
    "        \"\"\"è·å–è®¿é—®token\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/oauth/token\"\n",
    "            headers = {\"content-type\": \"application/x-www-form-urlencoded\"}\n",
    "            data = f\"grant_type=client_credentials&client_id={self.system.api_key}&client_secret={self.system.client_credentials}\"\n",
    "            \n",
    "            response = self.system.session.post(url, data=data, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            if result.get(\"status\") and \"data\" in result:\n",
    "                self.system.token = result[\"data\"][\"token\"]\n",
    "                self.system.log(\"âœ… Tokenè·å–æˆåŠŸ\", \"SUCCESS\")\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"è®¤è¯å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return False\n",
    "    \n",
    "    def search_patents(self, query: str, limit: int = 100) -> List[Dict]:\n",
    "        \"\"\"P002 - ä¸“åˆ©æ£€ç´¢\"\"\"\n",
    "        if not self.system.token and not self.authenticate():\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/search/patent/query-search-patent/v2\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\"apikey\": self.system.api_key}\n",
    "            \n",
    "            payload = {\n",
    "                \"sort\": [{\"field\": \"SCORE\", \"order\": \"DESC\"}],\n",
    "                \"limit\": limit,\n",
    "                \"offset\": 0,\n",
    "                \"query_text\": query,\n",
    "                \"collapse_by\": \"PBD\",\n",
    "                \"collapse_type\": \"ALL\"\n",
    "            }\n",
    "            \n",
    "            self.system.log(f\"ğŸ” æ£€ç´¢ä¸“åˆ©: {query} (é™åˆ¶{limit}ä»¶)\")\n",
    "            response = self.system.session.post(url, params=params, json=payload, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            if result.get(\"status\") and \"data\" in result:\n",
    "                patents = result[\"data\"].get(\"results\", [])\n",
    "                self.system.log(f\"âœ… æ‰¾åˆ° {len(patents)} ä»¶ä¸“åˆ©\", \"SUCCESS\")\n",
    "                return patents\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æ£€ç´¢å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return []\n",
    "    \n",
    "    def get_simple_bibliography(self, patent_id: str, patent_number: str) -> Optional[Dict]:\n",
    "        \"\"\"P011 - è·å–ç®€è¦è‘—å½•é¡¹ç›®ï¼ˆå«æ‘˜è¦ï¼‰\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/simple-bibliography\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                return result[\"data\"][0] if isinstance(result[\"data\"], list) else result[\"data\"]\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"P011è·å–å¤±è´¥ {patent_number}: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_legal_status(self, patent_id: str, patent_number: str) -> Optional[Dict]:\n",
    "        \"\"\"è·å–æ³•å¾‹çŠ¶æ€\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/legal-status\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            return result.get(\"data\") if result.get(\"status\") else None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æ³•å¾‹çŠ¶æ€è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_claims(self, patent_id: str, patent_number: str) -> Optional[str]:\n",
    "        \"\"\"è·å–æƒåˆ©è¦æ±‚ä¹¦\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/claim-data\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key,\n",
    "                \"replace_by_related\": \"0\"\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                claims_data = result[\"data\"]\n",
    "                if isinstance(claims_data, list) and claims_data:\n",
    "                    claims = claims_data[0].get(\"claims\", [])\n",
    "                    claims_text = \"\\n\\n\".join([\n",
    "                        f\"Claim {c.get('claim_num', '')}: {c.get('claim_text', '')}\"\n",
    "                        for c in claims\n",
    "                    ])\n",
    "                    return claims_text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"æƒåˆ©è¦æ±‚è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def get_description(self, patent_id: str, patent_number: str) -> Optional[str]:\n",
    "        \"\"\"è·å–è¯´æ˜ä¹¦\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.system.base_url}/basic-patent-data/description-data\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"authorization\": f\"Bearer {self.system.token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"patent_id\": patent_id,\n",
    "                \"patent_number\": patent_number,\n",
    "                \"apikey\": self.system.api_key,\n",
    "                \"replace_by_related\": \"0\"\n",
    "            }\n",
    "            \n",
    "            response = self.system.session.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if result.get(\"status\") and result.get(\"data\"):\n",
    "                desc_data = result[\"data\"]\n",
    "                if isinstance(desc_data, list) and desc_data:\n",
    "                    desc_text = desc_data[0].get(\"description\", [{}])[0].get(\"text\", \"\")\n",
    "                    # é™åˆ¶é•¿åº¦\n",
    "                    if len(desc_text) > 50000:\n",
    "                        desc_text = desc_text[:50000] + \"\\n...[å†…å®¹å·²æˆªæ–­]\"\n",
    "                    return desc_text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.system.log(f\"è¯´æ˜ä¹¦è·å–å¤±è´¥: {str(e)}\", \"ERROR\")\n",
    "            return None\n",
    "\n",
    "# ==================== Step 2: ä¸“åˆ©åˆæ­¥åˆ†æä¸ç­›é€‰ ====================\n",
    "\n",
    "class PatentScreener:\n",
    "    \"\"\"ä¸“åˆ©ç­›é€‰ä¸è¯„åˆ†\"\"\"\n",
    "    \n",
    "    def __init__(self, system: PatentAnalysisSystem):\n",
    "        self.system = system\n",
    "        \n",
    "    def process_initial_patents(self, patents: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"å¤„ç†åˆå§‹ä¸“åˆ©æ•°æ®\"\"\"\n",
    "        processed = []\n",
    "        \n",
    "        for i, patent in enumerate(patents, 1):\n",
    "            if i % 20 == 0:\n",
    "                self.system.log(f\"å¤„ç†è¿›åº¦: {i}/{len(patents)}\")\n",
    "            \n",
    "            # æå–åŸºç¡€ä¿¡æ¯\n",
    "            patent_info = {\n",
    "                \"patent_id\": patent.get(\"patent_id\"),\n",
    "                \"patent_number\": patent.get(\"pn\"),\n",
    "                \"title\": self._extract_title(patent),\n",
    "                \"assignee\": patent.get(\"current_assignee\", \"\"),\n",
    "                \"application_date\": str(patent.get(\"apdt\", \"\")),\n",
    "                \"publication_date\": str(patent.get(\"pbdt\", \"\")),\n",
    "                \"abstract\": \"\",\n",
    "                \"legal_status\": \"\",\n",
    "                \"score\": patent.get(\"score\", 0)\n",
    "            }\n",
    "            \n",
    "            processed.append(patent_info)\n",
    "            time.sleep(0.1)  # APIé™æµ\n",
    "        \n",
    "        return pd.DataFrame(processed)\n",
    "    \n",
    "    def _extract_title(self, patent: Dict) -> str:\n",
    "        \"\"\"æå–æ ‡é¢˜\"\"\"\n",
    "        title = patent.get(\"title\", \"\")\n",
    "        if isinstance(title, dict):\n",
    "            title = title.get(\"en\") or title.get(\"zh\", \"\")\n",
    "        return str(title)\n",
    "    \n",
    "    def enrich_with_abstracts(self, df: pd.DataFrame, api: ZhihuiyaAPI) -> pd.DataFrame:\n",
    "        \"\"\"è¡¥å……æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€\"\"\"\n",
    "        self.system.log(\"ğŸ“„ è·å–æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€...\")\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if idx % 10 == 0:\n",
    "                self.system.log(f\"è¿›åº¦: {idx}/{len(df)}\")\n",
    "            \n",
    "            # è·å–æ‘˜è¦\n",
    "            biblio = api.get_simple_bibliography(row[\"patent_id\"], row[\"patent_number\"])\n",
    "            if biblio:\n",
    "                abstracts = biblio.get(\"bibliographic_data\", {}).get(\"abstracts\", [])\n",
    "                if abstracts:\n",
    "                    df.at[idx, \"abstract\"] = abstracts[0].get(\"text\", \"\")[:500]\n",
    "            \n",
    "            # è·å–æ³•å¾‹çŠ¶æ€\n",
    "            legal = api.get_legal_status(row[\"patent_id\"], row[\"patent_number\"])\n",
    "            if legal and isinstance(legal, list) and legal:\n",
    "                legal_info = legal[0].get(\"patent_legal\", {})\n",
    "                status = legal_info.get(\"simple_legal_status\", [])\n",
    "                df.at[idx, \"legal_status\"] = \", \".join(status) if status else \"Unknown\"\n",
    "            \n",
    "            time.sleep(0.2)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def analyze_patent_statistics(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"ç»Ÿè®¡åˆ†æä¸“åˆ© - é€šç”¨ç‰ˆæœ¬\"\"\"\n",
    "        stats = {\n",
    "            \"total_patents\": len(df),\n",
    "            \"assignee_distribution\": df[\"assignee\"].value_counts().to_dict(),\n",
    "            \"year_distribution\": df[\"application_date\"].str[:4].value_counts().to_dict(),\n",
    "            \"legal_status_distribution\": df[\"legal_status\"].value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        # åŸºäºåŸºå› åçš„åŠ¨æ€æŠ€æœ¯ç±»å‹è¯†åˆ«\n",
    "        tech_types = {\n",
    "            \"RNAi/siRNA\": 0,\n",
    "            \"Antibody/mAb\": 0,\n",
    "            \"Small Molecule\": 0,\n",
    "            \"CRISPR/Gene Editing\": 0,\n",
    "            \"Cell Therapy\": 0,\n",
    "            \"Protein/Peptide\": 0,\n",
    "            \"Gene Therapy\": 0,\n",
    "            \"Other\": 0\n",
    "        }\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            text = (str(row[\"title\"]) + \" \" + str(row[\"abstract\"])).lower()\n",
    "            \n",
    "            # æ£€æµ‹æŠ€æœ¯ç±»å‹\n",
    "            if any(kw in text for kw in [\"rnai\", \"sirna\", \"interference\", \"oligonucleotide\", \"antisense\"]):\n",
    "                tech_types[\"RNAi/siRNA\"] += 1\n",
    "            elif any(kw in text for kw in [\"antibody\", \"mab\", \"immunoglobulin\", \"monoclonal\"]):\n",
    "                tech_types[\"Antibody/mAb\"] += 1\n",
    "            elif any(kw in text for kw in [\"compound\", \"inhibitor\", \"small molecule\", \"chemical\"]):\n",
    "                tech_types[\"Small Molecule\"] += 1\n",
    "            elif any(kw in text for kw in [\"crispr\", \"cas9\", \"gene editing\", \"genome editing\"]):\n",
    "                tech_types[\"CRISPR/Gene Editing\"] += 1\n",
    "            elif any(kw in text for kw in [\"car-t\", \"cell therapy\", \"tcr\", \"nk cell\"]):\n",
    "                tech_types[\"Cell Therapy\"] += 1\n",
    "            elif any(kw in text for kw in [\"protein\", \"peptide\", \"fusion protein\", \"recombinant\"]):\n",
    "                tech_types[\"Protein/Peptide\"] += 1\n",
    "            elif any(kw in text for kw in [\"gene therapy\", \"aav\", \"viral vector\", \"lentivirus\"]):\n",
    "                tech_types[\"Gene Therapy\"] += 1\n",
    "            else:\n",
    "                tech_types[\"Other\"] += 1\n",
    "        \n",
    "        stats[\"technology_distribution\"] = tech_types\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def score_and_rank_patents(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"è¯„åˆ†å¹¶æ’åºä¸“åˆ© - é€šç”¨ç‰ˆæœ¬\"\"\"\n",
    "        self.system.log(\"âš–ï¸ ä¸“åˆ©è¯„åˆ†ä¸­...\")\n",
    "        \n",
    "        # æ„å»ºä¸ç›®æ ‡åŸºå› ç›¸å…³çš„å…³é”®è¯åˆ—è¡¨\n",
    "        gene_lower = self.system.target_gene.lower()\n",
    "        gene_keywords = [\n",
    "            gene_lower,\n",
    "            self.system.target_gene.upper(),\n",
    "            # æ·»åŠ å¸¸è§çš„ç–¾ç—…ç›¸å…³å…³é”®è¯\n",
    "            \"therapeutic\", \"treatment\", \"inhibitor\", \"agonist\", \"antagonist\",\n",
    "            \"disease\", \"disorder\", \"cancer\", \"tumor\", \"diabetes\", \"obesity\",\n",
    "            \"inflammation\", \"metabolic\", \"cardiovascular\", \"neurological\"\n",
    "        ]\n",
    "        \n",
    "        # é¡¶çº§åˆ¶è¯å…¬å¸åˆ—è¡¨\n",
    "        top_pharma_companies = [\n",
    "            \"ROCHE\", \"NOVARTIS\", \"PFIZER\", \"MERCK\", \"JOHNSON\", \"SANOFI\", \n",
    "            \"GLAXOSMITHKLINE\", \"GSK\", \"ASTRAZENECA\", \"ABBVIE\", \"BRISTOL\",\n",
    "            \"LILLY\", \"AMGEN\", \"GILEAD\", \"REGENERON\", \"VERTEX\", \"BIOGEN\",\n",
    "            \"ARROWHEAD\", \"ALNYLAM\", \"MODERNA\", \"BIONTECH\", \"WAVE\"\n",
    "        ]\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            score = 0\n",
    "            \n",
    "            # 1. æ‘˜è¦å’Œæ ‡é¢˜ç›¸å…³åº¦ï¼ˆ0-35åˆ†ï¼‰\n",
    "            text = (str(row[\"title\"]) + \" \" + str(row[\"abstract\"])).lower()\n",
    "            \n",
    "            # åŸºå› åç§°å‡ºç°å¾—åˆ†\n",
    "            gene_count = text.count(gene_lower)\n",
    "            score += min(gene_count * 5, 20)\n",
    "            \n",
    "            # å…¶ä»–å…³é”®è¯å¾—åˆ†\n",
    "            keyword_score = sum(2 for kw in gene_keywords[2:] if kw in text)\n",
    "            score += min(keyword_score, 15)\n",
    "            \n",
    "            # 2. ç”³è¯·äººæƒé‡ï¼ˆ0-20åˆ†ï¼‰\n",
    "            assignee = str(row[\"assignee\"]).upper()\n",
    "            if any(comp in assignee for comp in top_pharma_companies):\n",
    "                score += 20\n",
    "            elif assignee and \"UNIVERSITY\" in assignee:\n",
    "                score += 10\n",
    "            elif assignee:\n",
    "                score += 5\n",
    "            \n",
    "            # 3. æ—¶é—´æ–°é²œåº¦ï¼ˆ0-15åˆ†ï¼‰\n",
    "            pub_date = str(row[\"publication_date\"])\n",
    "            if pub_date >= \"20240000\":\n",
    "                score += 15\n",
    "            elif pub_date >= \"20230000\":\n",
    "                score += 12\n",
    "            elif pub_date >= \"20220000\":\n",
    "                score += 8\n",
    "            elif pub_date >= \"20200000\":\n",
    "                score += 5\n",
    "            \n",
    "            # 4. æ³•å¾‹çŠ¶æ€ï¼ˆ0-10åˆ†ï¼‰\n",
    "            legal = str(row[\"legal_status\"]).lower()\n",
    "            if \"grant\" in legal or \"æˆæƒ\" in legal:\n",
    "                score += 10\n",
    "            elif \"pending\" in legal or \"å®¡æŸ¥\" in legal:\n",
    "                score += 5\n",
    "            \n",
    "            # 5. åŸå§‹ç›¸å…³åº¦åˆ†æ•°ï¼ˆ0-20åˆ†ï¼‰\n",
    "            original_score = row[\"score\"]\n",
    "            if original_score > 80:\n",
    "                score += 20\n",
    "            elif original_score > 60:\n",
    "                score += 15\n",
    "            elif original_score > 40:\n",
    "                score += 10\n",
    "            elif original_score > 20:\n",
    "                score += 5\n",
    "            \n",
    "            df.at[idx, \"final_score\"] = score\n",
    "        \n",
    "        # æ’åº\n",
    "        df_sorted = df.sort_values(\"final_score\", ascending=False)\n",
    "        \n",
    "        return df_sorted\n",
    "\n",
    "# ==================== Step 3: æ·±åº¦åˆ†æPrompts ====================\n",
    "\n",
    "class PatentAnalysisPrompts:\n",
    "    \"\"\"ä¸“åˆ©åˆ†æPromptæ¨¡æ¿ - é€šç”¨ç‰ˆæœ¬\"\"\"\n",
    "    \n",
    "    def __init__(self, target_gene: str):\n",
    "        self.target_gene = target_gene\n",
    "    \n",
    "    def description_analysis_prompt(self, description_text: str, patent_info: Dict) -> str:\n",
    "        \"\"\"è¯´æ˜ä¹¦åˆ†æprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½œä¸ºä¸“åˆ©æŠ€æœ¯ä¸“å®¶ï¼Œè¯·æ·±åº¦åˆ†æä»¥ä¸‹{self.target_gene}åŸºå› ç›¸å…³ä¸“åˆ©çš„è¯´æ˜ä¹¦ï¼Œå¹¶ä»¥è¿è´¯çš„æ®µè½å½¢å¼è¾“å‡ºåˆ†æç»“æœã€‚\n",
    "\n",
    "ä¸“åˆ©å·ï¼š{patent_info['patent_number']}\n",
    "ç”³è¯·äººï¼š{patent_info['assignee']}\n",
    "ç”³è¯·æ—¥ï¼š{patent_info['application_date']}\n",
    "\n",
    "è¯´æ˜ä¹¦å†…å®¹ï¼š\n",
    "{description_text}\n",
    "\n",
    "è¯·æŒ‰ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ¯éƒ¨åˆ†ç”¨2-3ä¸ªå®Œæ•´æ®µè½è¡¨è¿°ï¼‰ï¼š\n",
    "\n",
    "## 1. æŠ€æœ¯æ¦‚è¿°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šç®€è¦æè¿°è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„æŠ€æœ¯ï¼ˆRNAi/æŠ—ä½“/å°åˆ†å­/åŸºå› ç¼–è¾‘/ç»†èƒæ²»ç–—ç­‰ï¼‰ï¼Œé’ˆå¯¹{self.target_gene}é¶ç‚¹è¦è§£å†³ä»€ä¹ˆå…·ä½“é—®é¢˜ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯´æ˜æ ¸å¿ƒåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Œä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”çš„ä¸»è¦æ”¹è¿›åœ¨å“ªé‡Œã€‚\n",
    "\n",
    "## 2. æŠ€æœ¯æ–¹æ¡ˆåˆ†æï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯¦ç»†æè¿°å…·ä½“çš„æŠ€æœ¯æ–¹æ¡ˆã€‚æ ¹æ®æŠ€æœ¯ç±»å‹åˆ†æå…³é”®è¦ç´ ï¼ˆåºåˆ—è®¾è®¡ã€åŒ–åˆç‰©ç»“æ„ã€è½½ä½“æ„å»ºç­‰ï¼‰ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æä¼˜åŒ–æˆ–æ”¹è¿›ç­–ç•¥ï¼ˆåŒ–å­¦ä¿®é¥°ã€ç»“æ„ä¼˜åŒ–ã€é€’é€ç³»ç»Ÿç­‰ï¼‰ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šä¸åŒé¢†åŸŸå…¶ä»–ä¸“åˆ©æŠ€æœ¯çš„å¯¹æ¯”ï¼Œçªå‡ºæœ¬ä¸“åˆ©çš„ç‹¬ç‰¹æ€§ã€‚\n",
    "\n",
    "## 3. å®éªŒéªŒè¯ï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæ¦‚è¿°å®éªŒè®¾è®¡çš„æ•´ä½“æ€è·¯ï¼ŒåŒ…æ‹¬ä½“å¤–ã€ä½“å†…å®éªŒçš„å±‚æ¬¡å®‰æ’ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯¦ç»†æè¿°æœ€å…³é”®çš„å®éªŒç»“æœï¼ŒåŒ…æ‹¬å…·ä½“æ•°æ®ï¼ˆIC50ã€EC50ã€æŠ‘åˆ¶ç‡ã€æŒç»­æ—¶é—´ç­‰ï¼‰ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šå®‰å…¨æ€§è¯„ä¼°å’Œä¸´åºŠè½¬åŒ–è€ƒè™‘ã€‚å¦‚æœæœ‰ä¸´åºŠè¯•éªŒè®¾è®¡ï¼Œè¯´æ˜ä¸»è¦ç»ˆç‚¹å’Œç»™è¯æ–¹æ¡ˆã€‚\n",
    "\n",
    "## 4. å•†ä¸šä»·å€¼è¯„ä¼°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯„ä¼°{self.target_gene}ç›¸å…³ç–¾ç—…çš„å¸‚åœºè§„æ¨¡å’Œç«äº‰æ ¼å±€ã€‚è¯¥æŠ€æœ¯çš„ç›®æ ‡é€‚åº”ç—‡æ˜¯ä»€ä¹ˆï¼Ÿå¸‚åœºæ½œåŠ›å¦‚ä½•ï¼Ÿ\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æä¸“åˆ©æŠ€æœ¯çš„å¯å®æ–½æ€§å’Œå•†ä¸šåŒ–å‰æ™¯ã€‚ç”Ÿäº§å·¥è‰ºæ˜¯å¦æˆç†Ÿï¼Ÿæˆæœ¬æ˜¯å¦å¯æ§ï¼Ÿä¸´åºŠå¼€å‘è·¯å¾„æ˜¯å¦æ¸…æ™°ï¼Ÿ\n",
    "\n",
    "## 5. å…³é”®æŠ€æœ¯å‚æ•°æå–\n",
    "è¯·ç‰¹åˆ«æå–ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼š\n",
    "- æ ¸å¿ƒåºåˆ—/åŒ–åˆç‰©ï¼šå…·ä½“åºåˆ—å·æˆ–åŒ–å­¦ç»“æ„\n",
    "- é¶å‘æœºåˆ¶ï¼š{self.target_gene}çš„ä½œç”¨ä½ç‚¹æˆ–æœºåˆ¶\n",
    "- å®éªŒæ•°æ®ï¼šå…³é”®çš„é‡åŒ–æŒ‡æ ‡\n",
    "- æŠ€æœ¯ç‰¹å¾ï¼šç‹¬ç‰¹çš„æŠ€æœ¯ç‰¹ç‚¹\n",
    "- ä¸´åºŠæ–¹æ¡ˆï¼šå‰‚é‡ã€ç»™è¯é€”å¾„ã€é¢‘ç‡ï¼ˆå¦‚æœ‰ï¼‰\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- ä½¿ç”¨å®Œæ•´æµç•…çš„æ®µè½ï¼Œé¿å…ç¢ç‰‡åŒ–åˆ—è¡¨\n",
    "- æ•°æ®è‡ªç„¶èå…¥å™è¿°ä¸­\n",
    "- ä¿æŒä¸“ä¸šä½†æ˜“è¯»çš„æ–‡é£\n",
    "- æ€»å­—æ•°æ§åˆ¶åœ¨1000-1500å­—\n",
    "\"\"\"\n",
    "    \n",
    "    def claims_analysis_prompt(self, claims_text: str, patent_info: Dict) -> str:\n",
    "        \"\"\"æƒåˆ©è¦æ±‚åˆ†æprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½œä¸ºä¸“åˆ©æ³•å¾‹ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹{self.target_gene}åŸºå› ç›¸å…³ä¸“åˆ©çš„æƒåˆ©è¦æ±‚ä¹¦ï¼Œå¹¶ä»¥é€‚åˆä¸“ä¸šæŠ¥å‘Šçš„æ®µè½å½¢å¼è¾“å‡ºã€‚\n",
    "\n",
    "ä¸“åˆ©å·ï¼š{patent_info['patent_number']}\n",
    "ç”³è¯·äººï¼š{patent_info['assignee']}\n",
    "\n",
    "æƒåˆ©è¦æ±‚ä¹¦ï¼š\n",
    "{claims_text}\n",
    "\n",
    "è¯·æŒ‰ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ¯éƒ¨åˆ†ç”¨2-3ä¸ªå®Œæ•´æ®µè½è¡¨è¿°ï¼‰ï¼š\n",
    "\n",
    "## 1. æƒåˆ©è¦æ±‚æ¶æ„æ¦‚è¿°ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæè¿°æƒåˆ©è¦æ±‚çš„æ•´ä½“ç»“æ„ï¼ŒåŒ…æ‹¬æƒåˆ©è¦æ±‚æ•°é‡ã€ç‹¬ç«‹æƒåˆ©è¦æ±‚çš„ç±»å‹åˆ†å¸ƒã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†ææƒåˆ©è¦æ±‚ä¹‹é—´çš„é€»è¾‘å…³ç³»å’Œä¿æŠ¤ç­–ç•¥ã€‚\n",
    "\n",
    "## 2. æ ¸å¿ƒä¿æŠ¤èŒƒå›´åˆ†æï¼ˆ3æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šæ·±å…¥åˆ†æç‹¬ç«‹æƒåˆ©è¦æ±‚çš„ä¿æŠ¤èŒƒå›´ï¼Œç‰¹åˆ«æ˜¯ä¸{self.target_gene}ç›¸å…³çš„å¿…è¦æŠ€æœ¯ç‰¹å¾ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æå…³é”®é™å®šæ¡ä»¶å¯¹ä¿æŠ¤èŒƒå›´çš„å½±å“ã€‚\n",
    "ç¬¬ä¸‰æ®µï¼šè¯„ä¼°å…¶ä»–ç‹¬ç«‹æƒåˆ©è¦æ±‚çš„è¡¥å……ä½œç”¨ã€‚\n",
    "\n",
    "## 3. æŠ€æœ¯ç‰¹å¾é€’è¿›ç­–ç•¥ï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šåˆ†æä»å±æƒåˆ©è¦æ±‚çš„é€’è¿›é€»è¾‘å’Œå±‚æ¬¡ç»“æ„ã€‚\n",
    "ç¬¬äºŒæ®µï¼šè¯„ä»·å…³é”®ä»å±æƒåˆ©è¦æ±‚çš„ä»·å€¼å’Œå•†ä¸šæ„ä¹‰ã€‚\n",
    "\n",
    "## 4. æ³•å¾‹ç¨³å®šæ€§ä¸ä¾µæƒåˆ†æï¼ˆ2æ®µï¼‰\n",
    "ç¬¬ä¸€æ®µï¼šè¯„ä¼°æƒåˆ©è¦æ±‚çš„æ³•å¾‹ç¨³å®šæ€§ï¼ˆæ¸…æ¥šæ€§ã€æ”¯æŒæ€§ã€åˆ›é€ æ€§ï¼‰ã€‚\n",
    "ç¬¬äºŒæ®µï¼šåˆ†æä¾µæƒåˆ¤å®šçš„å…³é”®è¦ç´ å’Œæ½œåœ¨è§„é¿è·¯å¾„ã€‚\n",
    "\n",
    "## 5. ä¸å…¶ä»–{self.target_gene}ä¸“åˆ©çš„å…³ç³»ï¼ˆ1æ®µï¼‰\n",
    "åˆ†æè¯¥ä¸“åˆ©æƒåˆ©è¦æ±‚ä¸å…¶ä»–ä¸»è¦ç”³è¯·äºº{self.target_gene}ä¸“åˆ©çš„æ½œåœ¨å†²çªæˆ–äº’è¡¥å…³ç³»ã€‚\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- ä½¿ç”¨è¿è´¯çš„ä¸“ä¸šæ®µè½\n",
    "- æ³•å¾‹åˆ†æç»“åˆå•†ä¸šè€ƒè™‘\n",
    "- æ€»å­—æ•°æ§åˆ¶åœ¨800-1200å­—\n",
    "\"\"\"\n",
    "    \n",
    "    def final_report_prompt(self, statistics: Dict, detailed_analyses: List[Dict]) -> str:\n",
    "        \"\"\"æœ€ç»ˆç»¼åˆæŠ¥å‘Šprompt\"\"\"\n",
    "        return f\"\"\"\n",
    "ä½ æ˜¯ä¸“ä¸šçš„ä¸“åˆ©åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®æ’°å†™ä¸€ä»½è¯¦ç»†çš„{self.target_gene}åŸºå› ç›¸å…³ä¸“åˆ©æŠ€æœ¯ç»¼è¿°æŠ¥å‘Šã€‚\n",
    "\n",
    "ã€100ç¯‡ä¸“åˆ©ç»Ÿè®¡æ•°æ®ã€‘\n",
    "{json.dumps(statistics, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ã€10ç¯‡æ ¸å¿ƒä¸“åˆ©è¯¦ç»†åˆ†æã€‘\n",
    "{json.dumps(detailed_analyses, ensure_ascii=False, indent=2)}\n",
    "\n",
    "è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ä¸“åˆ©æŠ€æœ¯ç»¼è¿°æŠ¥å‘Šï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "# {self.target_gene}åŸºå› ç›¸å…³å…¨çƒä¸“åˆ©ç«äº‰æ ¼å±€åˆ†æ\n",
    "\n",
    "## ä¸€ã€ä¸“åˆ©æ•°é‡ã€ç±»å‹ä¸åœ°åŸŸåˆ†å¸ƒ\n",
    "\n",
    "### å…¨çƒä¸“åˆ©å…¬å¼€æ•°é‡ä¸ç±»å‹ï¼ˆ400å­—ï¼‰\n",
    "åŸºäºåˆ†æçš„100ç¯‡{self.target_gene}ç›¸å…³ä¸“åˆ©ï¼Œè¯¦ç»†è¯´æ˜ï¼š\n",
    "- ä¸“åˆ©æ€»æ•°å’Œæ—¶é—´åˆ†å¸ƒè¶‹åŠ¿\n",
    "- æŠ€æœ¯ç±»å‹åˆ†å¸ƒï¼ˆå„ç±»æŠ€æœ¯å æ¯”ï¼‰\n",
    "- ä¸»è¦ç”³è¯·äººåˆ†å¸ƒ\n",
    "- æ³•å¾‹çŠ¶æ€ç»Ÿè®¡\n",
    "\n",
    "### åœ°åŸŸåˆ†å¸ƒï¼ˆ300å­—ï¼‰\n",
    "åˆ†æä¸“åˆ©çš„åœ°åŸŸå¸ƒå±€ç‰¹ç‚¹ã€‚\n",
    "\n",
    "## äºŒã€æ ¸å¿ƒä¸“åˆ©æƒåˆ©äººåŠå¸ƒå±€ç­–ç•¥\n",
    "\n",
    "åŸºäº10ç¯‡æ ¸å¿ƒä¸“åˆ©çš„æ·±åº¦åˆ†æï¼Œè¯¦ç»†æè¿°å„ä¸»è¦ç©å®¶çš„æŠ€æœ¯ç­–ç•¥ã€‚\n",
    "[æ ¹æ®å®é™…ç”³è¯·äººæƒ…å†µåŠ¨æ€ç”Ÿæˆå„å…¬å¸åˆ†æ]\n",
    "\n",
    "## ä¸‰ã€æŠ€æœ¯å‘å±•è¶‹åŠ¿ä¸å…³é”®åˆ›æ–°\n",
    "\n",
    "### æŠ€æœ¯è·¯çº¿å¯¹æ¯”ï¼ˆ500å­—ï¼‰\n",
    "è¯¦ç»†å¯¹æ¯”ä¸åŒå…¬å¸é’ˆå¯¹{self.target_gene}çš„æŠ€æœ¯æ–¹æ¡ˆå·®å¼‚ã€‚\n",
    "\n",
    "### å…³é”®æŠ€æœ¯å‚æ•°æ±‡æ€»\n",
    "æ•´ç†æ‰€æœ‰æ ¸å¿ƒä¸“åˆ©çš„å…³é”®å‚æ•°ã€‚\n",
    "\n",
    "## å››ã€ä¸“åˆ©ä¿æŠ¤èŒƒå›´ä¸æ³•å¾‹é£é™©\n",
    "\n",
    "### æƒåˆ©è¦æ±‚ä¿æŠ¤èŒƒå›´å¯¹æ¯”ï¼ˆ400å­—ï¼‰\n",
    "å¯¹æ¯”ä¸åŒä¸“åˆ©çš„ä¿æŠ¤ç­–ç•¥ã€‚\n",
    "\n",
    "### æ½œåœ¨å†²çªåˆ†æï¼ˆ300å­—ï¼‰\n",
    "è¯†åˆ«å¯èƒ½çš„ä¸“åˆ©å†²çªç‚¹ã€‚\n",
    "\n",
    "## äº”ã€å•†ä¸šæœºä¼šä¸æŠ•èµ„å»ºè®®\n",
    "\n",
    "### æŠ€æœ¯ç©ºç™½ä¸æœºä¼šï¼ˆ300å­—ï¼‰\n",
    "åŸºäºä¸“åˆ©åˆ†æè¯†åˆ«çš„{self.target_gene}é¢†åŸŸæœºä¼šã€‚\n",
    "\n",
    "### æŠ•èµ„ä¸ç ”å‘å»ºè®®ï¼ˆ300å­—ï¼‰\n",
    "- æœ€æœ‰å‰æ™¯çš„æŠ€æœ¯è·¯çº¿\n",
    "- éœ€è¦è§„é¿çš„ä¸“åˆ©å£å’\n",
    "- æ½œåœ¨çš„åˆä½œæœºä¼š\n",
    "\n",
    "## å…­ã€ç»“è®ºä¸å±•æœ›\n",
    "\n",
    "æ€»ç»“{self.target_gene}ä¸“åˆ©é¢†åŸŸçš„å‘å±•ç°çŠ¶å’Œæœªæ¥è¶‹åŠ¿ï¼ˆ300å­—ï¼‰ã€‚\n",
    "\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "1. å¿…é¡»åŸºäºæä¾›çš„æ•°æ®ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯\n",
    "2. åŒ…å«å…·ä½“çš„ä¸“åˆ©å·ã€ç”³è¯·äººã€æŠ€æœ¯ç»†èŠ‚\n",
    "3. æ•°æ®å’Œåˆ†æè¦ç›¸äº’å°è¯\n",
    "4. ä¿æŒå®¢è§‚ä¸“ä¸šçš„è¯­æ°”\n",
    "5. æ€»å­—æ•°3000-4000å­—\n",
    "\"\"\"\n",
    "# ==================== Step 4: ä¸»æµç¨‹æ‰§è¡Œ ====================\n",
    "\n",
    "class PatentAnalysisPipeline:\n",
    "    \"\"\"ä¸“åˆ©åˆ†æä¸»æµç¨‹ - é€šç”¨ç‰ˆæœ¬\"\"\"\n",
    "    \n",
    "    def __init__(self, target_gene: str = None):\n",
    "        self.target_gene = target_gene\n",
    "        self.system = PatentAnalysisSystem(target_gene)\n",
    "        self.api = ZhihuiyaAPI(self.system)\n",
    "        self.screener = PatentScreener(self.system)\n",
    "        self.prompts = None  # å°†åœ¨è¿è¡Œæ—¶åˆå§‹åŒ–\n",
    "        \n",
    "    def run_complete_analysis(self, target_gene: str = None) -> Dict:\n",
    "        \"\"\"è¿è¡Œå®Œæ•´åˆ†ææµç¨‹\n",
    "        \n",
    "        Args:\n",
    "            target_gene: ç›®æ ‡åŸºå› åç§°ï¼ˆå¦‚ \"PCSK9\", \"PD-1\", \"EGFR\" ç­‰ï¼‰\n",
    "        \n",
    "        Returns:\n",
    "            åŒ…å«ç»Ÿè®¡æ•°æ®ã€è¯¦ç»†åˆ†æå’Œæœ€ç»ˆæŠ¥å‘Šçš„å­—å…¸\n",
    "        \"\"\"\n",
    "        \n",
    "        # è®¾ç½®ç›®æ ‡åŸºå› \n",
    "        if target_gene:\n",
    "            self.target_gene = target_gene\n",
    "            self.system.set_target_gene(target_gene)\n",
    "        elif not self.target_gene:\n",
    "            raise ValueError(\"è¯·æä¾›ç›®æ ‡åŸºå› åç§°\")\n",
    "        \n",
    "        # åˆå§‹åŒ–Prompts\n",
    "        self.prompts = PatentAnalysisPrompts(self.target_gene)\n",
    "        \n",
    "        # ========== Step 1: è·å–ä¸“åˆ©æ•°æ® ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(f\"ğŸš€ Step 1: è·å–{self.target_gene}ç›¸å…³ä¸“åˆ©æ•°æ®\", \"INFO\")\n",
    "        \n",
    "        # 1.1 æœç´¢ä¸“åˆ©\n",
    "        search_results = self.api.search_patents(self.target_gene, limit=100)\n",
    "        if not search_results:\n",
    "            self.system.log(f\"æœªæ‰¾åˆ°{self.target_gene}ç›¸å…³ä¸“åˆ©\", \"ERROR\")\n",
    "            return {}\n",
    "        \n",
    "        # 1.2 å¤„ç†åŸºç¡€æ•°æ®\n",
    "        df_patents = self.screener.process_initial_patents(search_results)\n",
    "        self.system.log(f\"âœ… å¤„ç†äº† {len(df_patents)} ç¯‡ä¸“åˆ©\", \"SUCCESS\")\n",
    "        \n",
    "        # ========== Step 2: è·å–æ‘˜è¦å’Œç»Ÿè®¡åˆ†æ ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ” Step 2: è·å–æ‘˜è¦å¹¶è¿›è¡Œç»Ÿè®¡åˆ†æ\", \"INFO\")\n",
    "        \n",
    "        # 2.1 è¡¥å……æ‘˜è¦å’Œæ³•å¾‹çŠ¶æ€\n",
    "        df_patents = self.screener.enrich_with_abstracts(df_patents, self.api)\n",
    "        \n",
    "        # 2.2 ç»Ÿè®¡åˆ†æ\n",
    "        statistics = self.screener.analyze_patent_statistics(df_patents)\n",
    "        statistics[\"target_gene\"] = self.target_gene\n",
    "        self.system.log(\"ğŸ“Š ä¸“åˆ©ç»Ÿè®¡åˆ†æå®Œæˆ\", \"SUCCESS\")\n",
    "        \n",
    "        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ\n",
    "        print(f\"\\n{self.target_gene}ç›¸å…³æŠ€æœ¯ç±»å‹åˆ†å¸ƒ:\")\n",
    "        for tech, count in statistics[\"technology_distribution\"].items():\n",
    "            print(f\"  {tech}: {count}ä»¶\")\n",
    "        \n",
    "        print(f\"\\n{self.target_gene}ä¸“åˆ©ä¸»è¦ç”³è¯·äººï¼ˆå‰5ï¼‰:\")\n",
    "        assignee_dist = dict(list(statistics[\"assignee_distribution\"].items())[:5])\n",
    "        for assignee, count in assignee_dist.items():\n",
    "            print(f\"  {assignee}: {count}ä»¶\")\n",
    "        \n",
    "        # 2.3 è¯„åˆ†å’Œæ’åº\n",
    "        df_patents = self.screener.score_and_rank_patents(df_patents)\n",
    "        \n",
    "        # ========== Step 3: é€‰æ‹©Top 10ä¸“åˆ© ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ¯ Step 3: é€‰æ‹©Top 10ä¸“åˆ©è¿›è¡Œæ·±åº¦åˆ†æ\", \"INFO\")\n",
    "        \n",
    "        top10_patents = df_patents.head(10)\n",
    "        \n",
    "        # æ˜¾ç¤ºTop 10\n",
    "        print(f\"\\n{self.target_gene}ç›¸å…³Top 10ä¸“åˆ©:\")\n",
    "        for idx, row in top10_patents.iterrows():\n",
    "            print(f\"{idx+1}. {row['patent_number']} - {row['assignee'][:30]} (Score: {row['final_score']})\")\n",
    "        \n",
    "        # ========== Step 4: æ·±åº¦åˆ†æTop 10ä¸“åˆ© ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ”¬ Step 4: æ·±åº¦åˆ†ææ ¸å¿ƒä¸“åˆ©\", \"INFO\")\n",
    "        \n",
    "        detailed_analyses = []\n",
    "        \n",
    "        for idx, patent in top10_patents.iterrows():\n",
    "            self.system.log(f\"åˆ†æä¸“åˆ© {idx+1}/10: {patent['patent_number']}\")\n",
    "            \n",
    "            # 4.1 è·å–è¯´æ˜ä¹¦\n",
    "            description = self.api.get_description(patent[\"patent_id\"], patent[\"patent_number\"])\n",
    "            \n",
    "            # 4.2 è·å–æƒåˆ©è¦æ±‚\n",
    "            claims = self.api.get_claims(patent[\"patent_id\"], patent[\"patent_number\"])\n",
    "            \n",
    "            if description and claims:\n",
    "                # 4.3 LLMåˆ†æè¯´æ˜ä¹¦\n",
    "                desc_prompt = self.prompts.description_analysis_prompt(description, patent.to_dict())\n",
    "                desc_analysis = self.system.llm_call(desc_prompt)\n",
    "                \n",
    "                # 4.4 LLMåˆ†ææƒåˆ©è¦æ±‚\n",
    "                claims_prompt = self.prompts.claims_analysis_prompt(claims, patent.to_dict())\n",
    "                claims_analysis = self.system.llm_call(claims_prompt)\n",
    "                \n",
    "                detailed_analyses.append({\n",
    "                    \"patent_number\": patent[\"patent_number\"],\n",
    "                    \"assignee\": patent[\"assignee\"],\n",
    "                    \"application_date\": patent[\"application_date\"],\n",
    "                    \"title\": patent[\"title\"],\n",
    "                    \"technical_analysis\": desc_analysis,\n",
    "                    \"legal_analysis\": claims_analysis\n",
    "                })\n",
    "                \n",
    "                self.system.log(f\"âœ… å®Œæˆåˆ†æ: {patent['patent_number']}\", \"SUCCESS\")\n",
    "            else:\n",
    "                self.system.log(f\"âš ï¸ æ— æ³•è·å–å®Œæ•´å†…å®¹: {patent['patent_number']}\", \"WARN\")\n",
    "            \n",
    "            time.sleep(2)  # APIé™æµ\n",
    "        \n",
    "        # ========== Step 5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š ==========\n",
    "        self.system.log(\"=\" * 50)\n",
    "        self.system.log(\"ğŸ“ Step 5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š\", \"INFO\")\n",
    "        \n",
    "        # 5.1 å‡†å¤‡æ•°æ®\n",
    "        statistics[\"top_patents\"] = top10_patents[[\"patent_number\", \"assignee\", \"final_score\"]].to_dict(\"records\")\n",
    "        \n",
    "        # 5.2 ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š\n",
    "        final_prompt = self.prompts.final_report_prompt(statistics, detailed_analyses)\n",
    "        final_report = self.system.llm_call(final_prompt)\n",
    "        \n",
    "        # ========== ä¿å­˜ç»“æœ ==========\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # ä¿å­˜è¯¦ç»†åˆ†æ\n",
    "        with open(f\"patent_detailed_analysis_{self.target_gene}_{timestamp}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\n",
    "                \"target_gene\": self.target_gene,\n",
    "                \"statistics\": statistics,\n",
    "                \"detailed_analyses\": detailed_analyses\n",
    "            }, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š\n",
    "        with open(f\"patent_report_{self.target_gene}_{timestamp}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_report)\n",
    "        \n",
    "        self.system.log(f\"âœ… {self.target_gene}ä¸“åˆ©åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜\", \"SUCCESS\")\n",
    "        \n",
    "        return {\n",
    "            \"target_gene\": self.target_gene,\n",
    "            \"statistics\": statistics,\n",
    "            \"detailed_analyses\": detailed_analyses,\n",
    "            \"final_report\": final_report\n",
    "        }\n",
    "\n",
    "# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================\n",
    "\n",
    "# ç¤ºä¾‹1ï¼šåˆ†æPCSK9åŸºå› \n",
    "def analyze_gene_patents(gene_name: str):\n",
    "    \"\"\"åˆ†ææŒ‡å®šåŸºå› çš„ä¸“åˆ©\"\"\"\n",
    "    pipeline = PatentAnalysisPipeline()\n",
    "    results = pipeline.run_complete_analysis(gene_name)\n",
    "    \n",
    "    if results and \"final_report\" in results:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"ğŸ“„ {gene_name}ä¸“åˆ©æŠ¥å‘Šé¢„è§ˆï¼ˆå‰1000å­—ï¼‰:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(results[\"final_report\"][:1000] + \"...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# è¿è¡Œåˆ†æ - å¯ä»¥æ›¿æ¢ä¸ºä»»ä½•åŸºå› \n",
    "# ç¤ºä¾‹åŸºå› åˆ—è¡¨ï¼š\n",
    "# - \"PCSK9\" (é™è„‚é¶ç‚¹)\n",
    "# - \"PD-1\" æˆ– \"PD-L1\" (å…ç–«æ£€æŸ¥ç‚¹)\n",
    "# - \"EGFR\" (è‚¿ç˜¤é¶ç‚¹)\n",
    "# - \"TNF\" æˆ– \"TNF-alpha\" (ç‚ç—‡é¶ç‚¹)\n",
    "# - \"HER2\" (ä¹³è…ºç™Œé¶ç‚¹)\n",
    "# - \"VEGF\" (è¡€ç®¡ç”Ÿæˆ)\n",
    "# - \"CD19\" (è¡€æ¶²è‚¿ç˜¤CAR-Té¶ç‚¹)\n",
    "# - \"BCMA\" (å¤šå‘æ€§éª¨é«“ç˜¤)\n",
    "# - \"GLP-1\" (ç³–å°¿ç—…/è‚¥èƒ–)\n",
    "# - \"INHBE\" (ä»£è°¢ç–¾ç—…æ–°é¶ç‚¹)\n",
    "\n",
    "# è¿è¡Œåˆ†æ\n",
    "gene_to_analyze = \"PCSK9\"  # ä¿®æ”¹è¿™é‡Œæ¥åˆ†æä¸åŒçš„åŸºå› \n",
    "results = analyze_gene_patents(gene_to_analyze)\n",
    "# æ‰¹é‡åˆ†æå¤šä¸ªåŸºå› ï¼ˆå¯é€‰ï¼‰\n",
    "def batch_analyze_genes(gene_list: List[str]):\n",
    "    \"\"\"æ‰¹é‡åˆ†æå¤šä¸ªåŸºå› \"\"\"\n",
    "    all_results = {}\n",
    "    \n",
    "    for gene in gene_list:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"å¼€å§‹åˆ†æåŸºå› : {gene}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            pipeline = PatentAnalysisPipeline()\n",
    "            results = pipeline.run_complete_analysis(gene)\n",
    "            all_results[gene] = results\n",
    "            \n",
    "            # ä¼‘æ¯ä¸€ä¸‹ï¼Œé¿å…APIé™åˆ¶\n",
    "            time.sleep(30)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"åˆ†æ{gene}æ—¶å‡ºé”™: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# æ‰¹é‡åˆ†æç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥ä½¿ç”¨ï¼‰\n",
    "# genes_to_analyze = [\"PCSK9\", \"PD-1\", \"EGFR\"]\n",
    "# batch_results = batch_analyze_genes(genes_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95547d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æ™ºæ…§èŠ½APIæµ‹è¯•\n",
      "============================================================\n",
      "\n",
      "1. æµ‹è¯•è·å–Token...\n",
      "   API_KEY: fh10ixx8marmhm9kbl3c...\n",
      "   çŠ¶æ€ç : 200\n",
      "   âŒ Tokenè·å–å¤±è´¥: {'status': False, 'error_code': 67200003, 'error_msg': 'Access token expired or authentication error!'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "æ™ºæ…§èŠ½APIæƒé™å’Œæœç´¢åŠŸèƒ½æµ‹è¯•\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# APIé…ç½®\n",
    "BASE_URL = \"https://connect.zhihuiya.com\"\n",
    "API_KEY = \"fh10ixx8marmhm9kbl3cx5676qn8nshcuwtktz0b05ebl7qf\"\n",
    "CLIENT_CREDENTIALS = \"74z26dxne81bnmrbd8vjwt7r8fc6tr6cxxdvapslbz4knycxknv3dnjprap6igjy\"\n",
    "\n",
    "def test_api():\n",
    "    \"\"\"æµ‹è¯•APIæƒé™å’Œæœç´¢åŠŸèƒ½\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"æ™ºæ…§èŠ½APIæµ‹è¯•\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: è·å–Token\n",
    "    print(\"\\n1. æµ‹è¯•è·å–Token...\")\n",
    "    print(f\"   API_KEY: {API_KEY[:20]}...\")\n",
    "    \n",
    "    token_url = f\"{BASE_URL}/oauth/token\"\n",
    "    headers = {\"content-type\": \"application/x-www-form-urlencoded\"}\n",
    "    data = f\"grant_type=client_credentials&client_id={API_KEY}&client_secret={CLIENT_CREDENTIALS}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(token_url, data=data, headers=headers)\n",
    "        print(f\"   çŠ¶æ€ç : {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            if result.get(\"status\") and \"data\" in result:\n",
    "                token = result[\"data\"][\"token\"]\n",
    "                print(f\"   âœ… Tokenè·å–æˆåŠŸ!\")\n",
    "                print(f\"   Tokenå‰20ä½: {token[:20]}...\")\n",
    "            else:\n",
    "                print(f\"   âŒ Tokenè·å–å¤±è´¥: {result}\")\n",
    "                return\n",
    "        else:\n",
    "            print(f\"   âŒ HTTPé”™è¯¯: {response.status_code}\")\n",
    "            print(f\"   å“åº”å†…å®¹: {response.text}\")\n",
    "            return\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ç½‘ç»œé”™è¯¯: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: æµ‹è¯•ç®€å•æœç´¢\n",
    "    print(\"\\n2. æµ‹è¯•æœç´¢åŠŸèƒ½...\")\n",
    "    \n",
    "    test_queries = [\n",
    "        \"CAR-T\",           # ç®€å•æœç´¢\n",
    "        \"PCSK9\",           # åŸºå› æœç´¢\n",
    "        \"antibody\",        # æŠ—ä½“æœç´¢\n",
    "        \"Novartis\",        # å…¬å¸æœç´¢\n",
    "        \"cancer therapy\"   # çŸ­è¯­æœç´¢\n",
    "    ]\n",
    "    \n",
    "    search_url = f\"{BASE_URL}/search/patent/query-search-patent/v2\"\n",
    "    search_headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    params = {\"apikey\": API_KEY}\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n   æµ‹è¯•æœç´¢: '{query}'\")\n",
    "        \n",
    "        payload = {\n",
    "            \"sort\": [{\"field\": \"SCORE\", \"order\": \"DESC\"}],\n",
    "            \"limit\": 5,  # åªå–5ä¸ªç»“æœæµ‹è¯•\n",
    "            \"offset\": 0,\n",
    "            \"query_text\": query,\n",
    "            \"collapse_by\": \"PBD\",\n",
    "            \"collapse_type\": \"ALL\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(search_url, params=params, json=payload, headers=search_headers)\n",
    "            print(f\"   çŠ¶æ€ç : {response.status_code}\")\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                if result.get(\"status\") and \"data\" in result:\n",
    "                    patents = result[\"data\"].get(\"results\", [])\n",
    "                    total = result[\"data\"].get(\"total_hits\", 0)\n",
    "                    print(f\"   âœ… æœç´¢æˆåŠŸ! æ‰¾åˆ° {len(patents)} ä»¶ä¸“åˆ© (æ€»è®¡: {total})\")\n",
    "                    \n",
    "                    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªä¸“åˆ©çš„ä¿¡æ¯\n",
    "                    if patents:\n",
    "                        first_patent = patents[0]\n",
    "                        print(f\"      ç¬¬ä¸€ä¸ªä¸“åˆ©å·: {first_patent.get('pn', 'N/A')}\")\n",
    "                        title = first_patent.get('title', {})\n",
    "                        if isinstance(title, dict):\n",
    "                            title = title.get('en') or title.get('zh', 'N/A')\n",
    "                        print(f\"      æ ‡é¢˜: {str(title)[:50]}...\")\n",
    "                else:\n",
    "                    print(f\"   âš ï¸ æœç´¢è¿”å›å¼‚å¸¸: {result}\")\n",
    "            else:\n",
    "                print(f\"   âŒ æœç´¢å¤±è´¥: HTTP {response.status_code}\")\n",
    "                print(f\"   å“åº”: {response.text[:200]}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ æœç´¢é”™è¯¯: {str(e)}\")\n",
    "    \n",
    "    # Step 3: æµ‹è¯•è·å–ä¸“åˆ©è¯¦æƒ…ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªæœç´¢ç»“æœï¼‰\n",
    "    if patents:\n",
    "        print(\"\\n3. æµ‹è¯•è·å–ä¸“åˆ©è¯¦æƒ…...\")\n",
    "        test_patent = patents[0]\n",
    "        patent_id = test_patent.get(\"patent_id\")\n",
    "        patent_number = test_patent.get(\"pn\")\n",
    "        \n",
    "        print(f\"   æµ‹è¯•ä¸“åˆ©: {patent_number}\")\n",
    "        \n",
    "        # æµ‹è¯•è·å–æ‘˜è¦\n",
    "        biblio_url = f\"{BASE_URL}/basic-patent-data/simple-bibliography\"\n",
    "        detail_params = {\n",
    "            \"patent_id\": patent_id,\n",
    "            \"patent_number\": patent_number,\n",
    "            \"apikey\": API_KEY\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(biblio_url, params=detail_params, headers=search_headers)\n",
    "            print(f\"   è·å–æ‘˜è¦çŠ¶æ€ç : {response.status_code}\")\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                if result.get(\"status\"):\n",
    "                    print(f\"   âœ… æ‘˜è¦è·å–æˆåŠŸ!\")\n",
    "                else:\n",
    "                    print(f\"   âš ï¸ æ‘˜è¦è·å–å¼‚å¸¸: {result}\")\n",
    "            else:\n",
    "                print(f\"   âŒ æ‘˜è¦è·å–å¤±è´¥: HTTP {response.status_code}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ è·å–æ‘˜è¦é”™è¯¯: {str(e)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æµ‹è¯•å®Œæˆ!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # æµ‹è¯•ç»“æœæ€»ç»“\n",
    "    print(\"\\næµ‹è¯•æ€»ç»“:\")\n",
    "    print(f\"âœ… Tokenè·å–: {'æˆåŠŸ' if token else 'å¤±è´¥'}\")\n",
    "    print(f\"âœ… æœç´¢åŠŸèƒ½: æµ‹è¯•äº† {len(test_queries)} ä¸ªæŸ¥è¯¢\")\n",
    "    print(f\"âœ… APIæƒé™: {'æ­£å¸¸' if token else 'å¼‚å¸¸'}\")\n",
    "    \n",
    "    return token\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•\n",
    "if __name__ == \"__main__\":\n",
    "    token = test_api()\n",
    "    \n",
    "    # é¢å¤–æµ‹è¯•ï¼šä¸“é—¨æµ‹è¯•CAR-Tå’Œè‡ªèº«å…ç–«æœç´¢\n",
    "    if token:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"é¢å¤–æµ‹è¯•: CAR-Tå’Œè‡ªèº«å…ç–«ç–¾ç—…æœç´¢\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        cart_queries = [\n",
    "            \"CAR-T autoimmune\",\n",
    "            \"CAR T\",\n",
    "            \"chimeric antigen receptor\", \n",
    "            \"CD19 CAR\",\n",
    "            \"autoimmune disease\",\n",
    "            \"lupus therapy\",\n",
    "            \"cell therapy\"\n",
    "        ]\n",
    "        \n",
    "        search_url = f\"{BASE_URL}/search/patent/query-search-patent/v2\"\n",
    "        search_headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"authorization\": f\"Bearer {token}\"\n",
    "        }\n",
    "        params = {\"apikey\": API_KEY}\n",
    "        \n",
    "        for query in cart_queries:\n",
    "            payload = {\n",
    "                \"sort\": [{\"field\": \"SCORE\", \"order\": \"DESC\"}],\n",
    "                \"limit\": 10,\n",
    "                \"offset\": 0,\n",
    "                \"query_text\": query,\n",
    "                \"collapse_by\": \"PBD\",\n",
    "                \"collapse_type\": \"ALL\"\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.post(search_url, params=params, json=payload, headers=search_headers)\n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()\n",
    "                    if result.get(\"status\") and \"data\" in result:\n",
    "                        total = result[\"data\"].get(\"total_hits\", 0)\n",
    "                        count = len(result[\"data\"].get(\"results\", []))\n",
    "                        print(f\"'{query}': æ‰¾åˆ° {count} ä»¶ (æ€»è®¡: {total})\")\n",
    "                    else:\n",
    "                        print(f\"'{query}': æ— ç»“æœ\")\n",
    "                else:\n",
    "                    print(f\"'{query}': é”™è¯¯ {response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"'{query}': å¼‚å¸¸ {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf98c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
